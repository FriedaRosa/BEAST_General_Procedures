---
title: "Collection_of_general_procedures"
author: "Friederike WÃ¶lke"
format: 
  html:
    code-fold: true
    page-layout: full
editor: visual
---

# 0) Setting Libraries

```{r}
#| label: Clean Environment
# Clear current environment
rm(list=ls())
```

```{r}
#| label: Libraries
#| warning: false
#| echo: false
#| message: false

library(gridExtra)  # plotting
library(sf)         # spatial functions
library(tidyverse)  # plotting & data manipulations (dplyr, ggplot2)
library(tmap)       # mapping
library(rstatix) #stat tests for plotting with ggplot
library(viridis) # color palette
library(ggpubr) # plotting stats
library(scales) # to adjust graph axis
library(tictoc)
```

# 1) Handling one dataset

## 1.1) Variables

This will become useful when all data sets have been merged to the long-file, but for now it also helps to explore the data and some of it's issues more generally.
```{r}
#| label: Variables 1 dataset
#| warning: false
#| echo: false
#| message: false

# folder path to Atlas data
source_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Processed/Atlases/Replicated/Birds_Atlas_EBBA/"

# folder path to output folder
out_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/output/"

# create path to read in data and grids from variables
data_path <- paste0(source_path,"Birds_Atlas_EBBA_beast_data.rds")
grid_path <-  paste0(source_path,"Birds_Atlas_EBBA_grid.gpkg") 

# save names of layers from file (needed to read them in):
layers <- st_layers(grid_path)$name
```


## 1.2) Atlas Presence data

The data has the following columns:

```         
"verbatim_name"      "taxa"               "samp_effort_type"   "dataset"            "start_year"         "end_year"           "license"            "cell_grouping"      "cell_label"         "cell_area_km2"      "cell_perimeter_km2" "cell_leng"          "cell_ns_leng"       "cell_ew_leng"       "cell_long"          "cell_lat"           "samp_effort"        "cell_samp_area"  
```

```{r}
#| label: I. Atlas Presence data

# Bird presence data ============================================================ #
presence_data <- readRDS(data_path)

## re-code columns to factors for correct grouping ====================================================== #

# Define the desired order of factor levels
desired_levels <- c("cell1grid", "cell2grid", "cell4grid", "cell8grid", "cell16grid", "cell32grid", "cell64grid", "cell128grid", "cellfullgrid")

# Reorder the levels in the "cell_grouping" column
presence_data <- presence_data %>%
  mutate(cell_grouping = factor(cell_grouping, levels = desired_levels))

# Re-code some other columns to factor
presence_data$cell_label <- as.factor(presence_data$cell_label)
presence_data$dataset <- as.factor(presence_data$dataset)
presence_data$taxa <- as.factor(presence_data$taxa)

## make variables for time slots =========================================================== #
times <- unique(presence_data$start_year)
time_slot1 <- times[1]
time_slot2 <- times[2]

# some Atlases have 3 sampling periods:
if (length(times) > 2) time_slot3 <- times[3]
```


```{r}
presence_data %>% 
  group_by(start_year, cell_grouping) %>% 
  summarize(n_cells = length(unique(cell_label)),
            n_species = length(unique(verbatim_name)))


presence_data %>% filter(is.na(start_year))
```



## 1.3) Geopackage (Grid files)

```{r}
#| label: II. Geopackage (Grids)

#| warning: false
#| echo: false
#| message: false
#| label: geopackage  

## Read in geopackage file layers  =========================================================== #

# Read in individual grids into list using sapply(), st_read() & character vector with paths and layers

# it's faster than doing it in a loop:
#    loop: 0.15 sec elapsed
#    sapply: 0.14 sec elapsed

tic("sapply")
grid_list <- sapply(layers, function(i) {
  st_read(grid_path, paste(i), quiet = TRUE)
}, simplify = FALSE)
toc() # sapply: 0.14 sec elapsed

```

## 1.4) Exploring the data

### 1.4.1. Species Richness

Explore species richness and how it changes spatially and temporally.

```{r, fig.height = 4, fig.width = 6}
#| label: Species Richness Summary

# Calculate species richness per cell, scale and sampling period:
temp_df <- presence_data %>% filter_all(any_vars(!is.na(.))) %>%
  group_by(dataset, cell_grouping, cell_label, start_year) %>% 
  summarise(
    SR_cell = n()) %>% 
  # Calculate range, mean (+ sd) of SR and mean Difference (+ sd) in SR between years:
  ungroup() %>%
  group_by(dataset, cell_grouping, start_year) %>%  
  mutate (minSR_cell = min(SR_cell),
          maxSR_cell = max(SR_cell),
          meanSR_cell = mean(SR_cell),
          sdSR_cell = sd(SR_cell)) %>% 
  mutate(Diff_SR_meanSR = SR_cell - meanSR_cell) %>% 
  mutate(Diff_SR_meanSR = round(Diff_SR_meanSR, 2),
          sdSR_cell = round(sdSR_cell, 2)) %>% 
   ungroup() 




# How does species richness scale across sampling periods? ====================================== #
min <- min(temp_df$meanSR_cell)
max <- max(temp_df$meanSR_cell)+10

temp_df %>%
   ggplot(aes(
     y = meanSR_cell, 
     x = cell_grouping, 
     col = as.factor(start_year))) +
   geom_point(alpha = 0.6) +
   geom_line(aes(group = start_year))+
   ylab("mean Species Richness") +
   xlab("Scale") +
   theme_light() +
   labs(color = "Start Year of Sampling Period", 
       title = "Mean Species Richness across Scales",
       subtitle = "Number above boxes = mean species richness") +
   scale_y_continuous(breaks = seq(0, max, by = 50), limits = c(0, max)) +
   geom_text(aes(label = round(meanSR_cell, 2), y = meanSR_cell),
            vjust = -3, size = 2, position = position_dodge(width = 1)) + # Adjust position to dodge labels
   scale_color_viridis(discrete = TRUE, alpha = 0.9)
ggsave(plot = last_plot(), filename = paste0(out_path, "Figs/SpeciesRichness.pdf"))

```

### 1.4.2. Sampling Effort

Things to consider:

-   What is the sampling effort and its unit?\
    Note: sampling effort per cell varies among sampling periods!

```{r, fig.width = 8, fig.height = 6}
# What's the unit of sampling effort in this Atlas? =========================================== #
presence_data %>% pull(samp_effort_type) %>% unique()

# How does sampling effort scale? ============================================================= #
presence_data %>% ungroup() %>% group_by(start_year, cell_grouping) %>% select(samp_effort) %>% get_summary_stats(type = "mean_sd")

presence_data %>% 
  ungroup() %>% 
  select(start_year, cell_grouping, samp_effort) %>% 
  unique() %>% 
  group_by(start_year, cell_grouping) %>% 
  summarise(n= n(),
            min_samp_effort = min(samp_effort),
            mean_samp_effort = mean(samp_effort),
            sd_samp_effort = sd(samp_effort),
            max_samp_effort = max(samp_effort))

presence_data %>%
  ungroup() %>%
  select(start_year, cell_grouping, samp_effort) %>%
  filter(cell_grouping != "cell128grid") %>%
  unique() %>%
  group_by(start_year, cell_grouping) %>%
  mutate(mean_samp_effort = mean(samp_effort)) %>%
  
  ggplot(aes(y = samp_effort, x = cell_grouping, fill = as.factor(start_year))) +
  geom_boxplot(alpha = 0.6) +
  ylab("Sampling Effort (N Collectors)") +
  xlab("Scale") +
  theme_light() +
  scale_fill_viridis(discrete = TRUE, alpha = 0.7) +
  labs(fill = "Start Year of Sampling Period", 
       title = "Scaling of Sampling Effort across Sampling Periods",
       subtitle = "Number above boxes = mean sampling effort") +
  scale_y_continuous(breaks = seq(0, max(presence_data$samp_effort), by = 100)) +
  geom_text(aes(label = round(mean_samp_effort, 2), y = mean_samp_effort),
            vjust = -15, size = 2, position = position_dodge(width = 0.75))  # Adjust position to dodge labels

ggsave(plot = last_plot(), filename = paste0(out_path, "Figs/SamplingEffort.pdf"))

```

### 1.4.3. Un-sampled cells

Not all cells that are present in the smallest grid of the map have been sampled. Sometimes this relates to the accessibility of the area (e.g., steep slopes in mountain ranges or large distance from roads and cities).\
Note: this varies among sampling periods!

-   How many cells (and which ones) have been sampled at all?

-   Which have never been visited?

-   What is the proportion?

-   Since often these unsampled cells are clustered spatially, consider cutting the extent of the study area to a part of the atlas where sampling has been more or less complete for more robust results.

-   Could be explored e.g., using sampling curves to find a threshold for cutting the area on scales larger then the original sampling scale.

    -   ? i.e., average sampling effort across cells (sampled and unsampled). Calculate sampling curves for grid cells. If average sampling effort of sampled and unsampled cells in the smallest grid falls below a threshold on the sampling curve for larger grids, this means that sampling was not complete enough in this larger cell and it should be discarded.

    -   Some Resources to check:

        -   iNEXT package: [https://doi.org/10.1111/2041-210X.1261](https://doi.org/10.1111/2041-210X.12613)

        -   Corals and sampling strategy: <https://doi.org/10.1111/1440-1703.12096>

        -   Flo's Github repo: <https://github.com/bienflorencia/Multiple-forms-of-hotspots-of-tetrapod-biodiversity>

```{r, fig.show='hold'}
#| label: unsampled cells

# Detect cells that have not been sampled by finding the difference between the grids and the presence data

# For each scale separately:
grid_list2 <- list()
for (i in 1:length(layers)){
  current_layer <- layers[i]
  current_grid <- grid_list[[i]]
  print(current_layer)
  ## Sampling period 1
  cell_labels1 <- presence_data %>% 
    filter(start_year == "1987", cell_grouping == current_layer) %>% 
    pull(cell_label) %>% unique()
  
  # differences in label names between grid and presence data
  unsampled_cells_time1 <- setdiff(current_grid$cell_label, cell_labels1)
  print(paste0("N cells not sampled in time 1 = ", length(unsampled_cells_time1)))
  
  ## Sampling period 2
  cell_labels2 <- presence_data %>% 
    filter(start_year == "2000", cell_grouping == current_layer) %>% 
    pull(cell_label) %>% unique()
  
  # differences in label names between grid and presence data
  unsampled_cells_time2 <- setdiff(current_grid$cell_label, cell_labels2)
  print(paste0("N cells not sampled in time 2 = ", length(unsampled_cells_time2)))
  
  # add column with dummy variable for each time slot

current_grid <- current_grid %>%
  mutate(sampled_1 = if_else(cell_label %in% unsampled_cells_time1, '0', '1'),
         sampled_2 = if_else(cell_label %in% unsampled_cells_time2, '0', '1')) %>%
  mutate(sampled_1 = as.factor(sampled_1),
         sampled_2 = as.factor(sampled_2)) %>%
  group_by(sampled_1) %>%
  mutate(n_1 = n(), 
         Total_Area_per_scale_time1 = sum(cell_area_km2)) %>% ungroup() %>%
  group_by(sampled_2) %>%
  mutate(n_2 = n(), 
         Total_Area_per_scale_time2 = sum(cell_area_km2))
  

grid_list2[[i]] <- current_grid 
  
}
  
# exclude cells that were not sampled from the analysis:
grid_list_reduced1 <- list()
grid_list_reduced2 <- list()
p_list <- list()
for (i in 1:length(grid_list2)){
  grid_list_reduced1[[i]] <- grid_list2[[i]] %>% filter(!(cell_label %in% unsampled_cells_time1))
  grid_list_reduced2[[i]] <- grid_list2[[i]] %>% filter(!(cell_label %in% unsampled_cells_time2))
if(unique(grid_list_reduced1[[i]]$cell_grouping) != "cell128grid") p1 <- grid_list_reduced1[[i]] %>%
  tm_shape() +
  tm_fill("sampled_1", palette=c("viridis")) +
  tm_borders()  
if (unique(grid_list_reduced2[[i]]$cell_grouping) != "cell128grid") p2 <- grid_list_reduced2[[i]] %>%
  tm_shape() +
  tm_fill("sampled_2", palette=c("viridis")) +
  tm_borders() 
  
p_list[[i]] <- tmap_arrange(p1, p2)
  
}

p_list

rm(p_list, p1, p2)
```

## 1.5) Calculate Species' Occupancy

Notes:

-   even though cells have not been sampled, we assume that the species covers the whole are of the cell (column: cell_area_km2)

-   since the Atlas presence data only has cells that have been sampled, we have to base our calculation on the full grid

-   Formulas:

    -   Occupancy = sum of areas of all cells where a species is present

    -   Relative Occupancy = Occupancy divided by the total Area of the Atlas (sum of all cells at a given scale)

-   This workflow requires **grouping** by:

    -   verbatim_name (as we want to calculate occupancy for each species separately)

    -   cell_grouping (as we want to calculate occupancy for each scale separately)

    -   start_year (as we want to calculate occupancy for each sampling period separately)

```{r}
#| label: AOO calculation across scales and species

occ_data_list <- list()

# We run the loop for each scale (N = 8)
for (i in 1:length(grid_list2)){
  
  # subset the grid_list and work on a single scale:
  map_atlas <- grid_list2[[i]] 
  
# Calculate total area of alberta based on grid1 (original scale):
total_area_Atlas <- map_atlas %>% 
  select(cell_grouping, cell_label, cell_area_km2) %>% 
  mutate(total_area = sum(cell_area_km2)) %>% 
  pull(total_area) %>% 
  unique()

# Create column for total Area:
pres_data <- presence_data %>% filter(cell_grouping == unique(map_atlas$cell_grouping) )

# Merge sampled and unsampled cells for calculations:
pres_data_full <- merge(pres_data, map_atlas, by = intersect(names(pres_data), names(map_atlas)), all = T)
pres_data_full$total_area_Atlas <- total_area_Atlas

# Make subset of the data for the calculations.
pres_data_full_reduced <- pres_data_full %>% 
  ungroup() %>% 
  select(verbatim_name, start_year, cell_grouping, cell_area_km2, cell_label, total_area_Atlas,
         Total_Area_per_scale_time1, Total_Area_per_scale_time2)


## ============================================================================================= ##
##  ================================== Calculate Occupancy ===================================== ##
## ============================================================================================= ##


occ_data <- pres_data_full_reduced %>%
  ungroup() %>%

# Necessary grouping to calculate occupancy:
  group_by(verbatim_name, start_year, cell_grouping) %>%
  
# Calculate Occupancy:

  mutate(occupancy_area = sum(cell_area_km2)) %>%
  
# Calculate relative Occupancy:
  mutate(relative_occupancy = case_when(
    start_year == time_slot1 ~ occupancy_area/Total_Area_per_scale_time1,
    start_year == time_slot2 ~ occupancy_area/Total_Area_per_scale_time2)) %>%
  
# Round values to 2 digits after the comma:
  mutate(relative_occupancy = round(relative_occupancy,2)) %>% 
  filter(!is.na(verbatim_name)) %>%
# Remove duplicated rows:
  unique() 



# save to list:
occ_data_list[[i]] <- occ_data

}


# Bind to one dataframe:
occ_data_full_df <- plyr::rbind.fill(occ_data_list, fill=T)
occ_data_full_df %>%  filter_all(any_vars(is.na(.)))
# create scale column as the average cell_area_km2 per cell_grouping
occ_data_full_df <- occ_data_full_df %>% group_by(cell_grouping, start_year) %>% mutate(Scale_km2 = mean(cell_area_km2))    

occ_data_full_df %>% 
  group_by(cell_grouping, start_year) %>% 
  get_summary_stats(c(relative_occupancy, occupancy_area, Total_Area_per_scale_time1, Total_Area_per_scale_time2, Scale_km2), type="mean_sd")

                                    

cols_n <- intersect(names(presence_data), names(occ_data_full_df))
occ_data_full <- unique(merge(presence_data, occ_data_full_df, by = cols_n, all.y = T))
gc()
```

```{r,  fig.height = 10, fig.width = 8 }
#| label: Occupancy Plots
# Proportional AOO (per sampled area)

plot_data <- occ_data_full_df %>% 
  filter(cell_grouping != "cell128grid") %>% 
  unique() %>%
  select(cell_grouping, start_year, 
         cell_area_km2, Scale_km2,
         verbatim_name, relative_occupancy, occupancy_area) %>% unique() %>% ungroup() 
 
 
gg1 <- ggplot(data = plot_data, 
                aes(y = log10(relative_occupancy+1), 
                    x = log10(Scale_km2), 
                    col = as.factor(verbatim_name), 
                    group = factor(verbatim_name))) +
  geom_point(show.legend = F) +
  ylim(-0.05, 0.35)+
  geom_line() +
  facet_wrap(start_year~.) +
  theme_light() +
  scale_color_viridis(discrete = TRUE, alpha = 0.7) +
  labs(title = "Relative Occupancy [0,1] Across Scales (km2)") +
  theme(legend.position = "none") 


# Absolute AOO (per sampled area)
gg2 <- ggplot(data = plot_data, 
              aes(y = log10(occupancy_area), 
                  x = log10(Scale_km2), 
                  col = as.factor(verbatim_name), 
                  group = factor(verbatim_name))) +
  geom_point(show.legend = F) +
  ylim(1.8, 5.9)+
  geom_line() +
  facet_wrap(start_year~.) +
  theme_light() +
  scale_color_viridis(discrete = TRUE, alpha = 0.7) +
  labs(title = "Absolute Occupancy (km2) Across Scales (km2)")  + 
  theme(legend.position = "none")

gg_grid <- grid.arrange(gg1, gg2, nrow = 2)

ggsave(plot = gg_grid, filename = paste0(out_path, "Figs/OccupancyAcrossScales.pdf"), height = 10, width = 8 )
```

# 2) Handling multiple datasets (not merged together yet)

## 2.1) Variables

```{r}

options(scipen=999) # turn off scientific notations


# folder path to data

source_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Processed/Atlases/Replicated/"
out_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST-Project/R/out/"

data_path <- paste0(source_path, list.files(source_path, pattern="*_beast_data.rds", all.files =  T, recursive = T))


grid_path <-  paste0(source_path, list.files(source_path, pattern="*_grid.gpkg", all.files =  T, recursive = T))



lay <- lapply(grid_path, st_layers)

layers <- list()

for (i in 1:length(lay)) 
  {
layers[[i]] <- c(lay[[i]]$name) # grid resolutions
}


```



## 2.2) Atlas data

```{r}
#| warning: false
#| echo: false
#| message: false
#| label: species data 

# Bird presence data ============================================================ #

presence_data_list <- lapply(paste0(data_path), readRDS) # read datasets to list

# Extract the names of the datasets to a vector ================================================ #
v_data <- list()

for (i in 1:length(presence_data_list))
  {
  v_data[i] <- c(unique(presence_data_list[[i]]$dataset))
}

datasets <- do.call(c, v_data) # make vector of datasets

# Extract time slots from datasets and make dataframe ================================================ #
times <- list()

for (i in 1:length(datasets))
  {
  dd_temp <- presence_data_list[[i]]
  times_temp <- unique(dd_temp$start_year)
  times[[i]] <- data.frame(dataset = datasets[i],
                           time_slot1 = times_temp[1],
                           time_slot2 = times_temp[2],
                           time_slot3 = if (length(times_temp) == 2) NA else times_temp[3])

}

times
names(times) <- datasets # name datasets
times_df <- plyr:::rbind.fill(times) # fills missing with NA


# Merge List of dataframes to one long dataframe ================================================ #

presence_data_df <- plyr:::rbind.fill(presence_data_list) # bind list to data frame and fills with NAs where no data is available (the columns names don't match yet between datasets)


presence_data <- presence_data_df # make working copy 



#### =============================== exclude during test run =================================== #### 
# presence_data <- presence_data %>% 
#   mutate(verbatim_name = coalesce(verbatim_name, scientific_name)) %>%
#   mutate(cell_samp_area = coalesce(cell_samp_area, cell_samp_area1))


# make sure the columns are coded correctly
presence_data$dataset <- as.factor(presence_data$dataset)
presence_data$cell_grouping <- factor(presence_data$cell_grouping, levels = unique(presence_data$cell_grouping))
presence_data$cell_label <- as.factor(presence_data$cell_label)
presence_data$dataset <- as.factor(presence_data$dataset)
presence_data$start_year <- as.factor(presence_data$start_year)
# presence_data$taxa <- as.factor(presence_data$taxa)


# reduce data columns:
presence_data <- presence_data %>% 
  ungroup() %>%
  dplyr::select(c(dataset,
                  verbatim_name,
                  cell_grouping, 
                  cell_label, 
                  cell_area_km2, 
                  cell_samp_area, 
                  cell_perimeter_km2, 
                  cell_long, cell_lat, 
                  samp_effort, samp_effort_type, 
                  start_year)) %>% unique()

presence_data

presence_data %>% select(start_year) %>% pull() %>% unique()

for (i in 1:length(times)){
  
  times_temp <- times[[i]]
  presence_data$time_slot1[presence_data$start_year == times_temp$time_slot1] <- paste(as.factor(times_temp$time_slot1))
  presence_data$time_slot2[presence_data$start_year == times_temp$time_slot2] <- paste(as.factor(times_temp$time_slot2))
  presence_data$time_slot3[presence_data$start_year == times_temp$time_slot3] <- paste(as.factor(times_temp$time_slot3))
  
}

presence_data %>%  filter_all(any_vars(is.na(.))) # only NAs in sampling effort for Catalonia Birds

```


## 2.3) Geopackage loop to list

```{r}
#| warning: false
#| echo: false
#| message: false
#| label: geopackage  


## Read in geopackage file layers

grid_list <- sapply(grid_path, function(current_path) {
  layers_per_dataset <- lapply(layers, function(current_layer_v) {
    current_layer <- st_read(current_path, current_layer_v, quiet = TRUE)
    return(current_layer)
  })
  return(layers_per_dataset)
}, simplify = F, USE.NAMES = T)



names(grid_list) <- datasets
```

## 2.4) Exploring the data

### 2.4.1 Species Richness

```{r}
# quick summary stats about the species data:

temp_df <- presence_data %>% 
  group_by(dataset, cell_grouping, cell_label, start_year) %>% 
  summarise(
    SR_cell = n()
    ) 

 temp_df %>% 
  ungroup() %>% 
  group_by(dataset, cell_grouping, start_year) %>% 
  mutate (meanSR_cell = mean(SR_cell),
          sdSR_cell = sd(SR_cell)) %>% 
  mutate(Diff_SR_meanSR = SR_cell - meanSR_cell) %>% 
  mutate(Diff_SR_meanSR = round(Diff_SR_meanSR, 2),
          sdSR_cell = round(sdSR_cell, 2)) # %>% 
   # ungroup() %>%
   # ggplot(aes(group = cell_label))+ 
   # geom_violin(aes(Diff_SR_meanSR, x =start_year)) 


```