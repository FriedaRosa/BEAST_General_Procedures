---
title: "Scale_Area_Curves"
author: "Friederike Wölke"
format:
  html:
    toc: true
editor: visual        
output:
  html_document:
    code_folding: hide
---

# BEAST: Scale-Area Curves

This script calculates different kinds of occupancy, scale-area relationships, fractal dimensions, telfer-index of change, log-Ratio plots.

This script also does some basic assessment of the atlas data (species richness, effort) across temporal and spatial scales

```{r, sparta package install & load}
#| warning: false
#| echo: false
#| message: false


# # install.packages("devtools")
# # NOTE: If you have not installed devtools before you will need to restart you R
# # session before installing to avoid problems
# 
# library(devtools)
# 
# # Some users have reported issues with devtools not correctly installing
# # dependencies. Run the following lines to avoid these issues
# list.of.packages <- c("minqa", "lme4", "gtools", "gtable", "scales",
#                       "assertthat", "magrittr", "tibble", "stringr")
# new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
# if(length(new.packages)) install.packages(new.packages)
# 
# # Now install sparta
# install_github('BiologicalRecordsCentre/sparta')

# Load sparta
library(sparta)

```

### 1. Reading the necessary libraries

```{r, other libraries}
#| warning: false
#| message: false
#| label: Libraries
gc()
rm(list=ls())

# Spatial packages
library(sf)         # spatial functions
library(tmap)       # mapping

# Data wrangling
# library(tidyverse)  # plotting & data manipulations (dplyr, ggplot2)
library(dplyr)
library(tidyr)  
library(ggplot2)  
library(rstatix)    #stat tests for plotting with ggplot


# Plotting
library(gridExtra)  # plotting
library(viridis)    # color palette
library(ggpubr)     # plotting stats
library(scales)     # to adjust graph axis
library(stringr) 

# library(sjPlot)
library(AICcmodavg) # AICc model selection

# Other packages
# library(tictoc)     # to measure the time it takes to run a code chunk

```

```{r, eval = F}
# load("~/GitHub/BEAST_General_Procedures/Project_Frieda/out/Scale_Area_Curves_full.RData")
```

### 2. Setting path variables

```{r, path variables}
#| warning: false
#| message: false
#| label: Variables

# folder path to atlas data
source_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Processed/Atlases/Replicated/Birds_Atlas_Czechia/"

# folder path to output folder
out_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/Project_Frieda/out/"

# create path to read in data and grids from variables
data_path <- paste0(source_path,"Birds_Atlas_Czechia_beast_data.rds")
grid_path <-  paste0(source_path,"Birds_Atlas_Czechia_grid.gpkg") 

# save names of layers from file (needed to read them in):
layers <- st_layers(grid_path)$name

# Define the desired order of factor levels
desired_levels <- factor(layers, 
                         ordered = T, 
                         levels = c("cell1grid", "cell2grid", 
                                    "cell4grid", "cell8grid", 
                                    "cell16grid", "cellfullgrid")) 

```

### 3. Reading the data

```{r, reading }
# Species data
presence_data <- readRDS(data_path)

## sort the cell groupings ascending
presence_data <- presence_data %>%
  mutate(cell_grouping = factor(cell_grouping, 
                                levels = desired_levels))

## add column for time period (tp)
start_times <- sort(unique(presence_data$start_year))
end_times <- sort(unique(presence_data$end_year))

time_periods <- data.frame(start_year = start_times,
                           end_year = end_times, 
                           tp = seq_along(end_times))

presence_data <- merge(presence_data, time_periods, 
                       by=c("start_year", "end_year"), 
                       all.x=T)

# grid data
grid_list <- sapply(layers, function(i) {
  st_read(grid_path, paste(i), quiet = TRUE)
}, simplify = FALSE)

```

#### Binary matrix:

```{r}
# sites x species matrix for all 3 time periods and all 6 scales.

binary_data <- presence_data %>%
  select(cell_label, verbatim_name, tp, cell_grouping) %>%
  group_by(tp, cell_grouping) %>%
  distinct() %>%
  mutate(value = 1) %>%
  spread(verbatim_name, value, fill = 0)

dim(binary_data) #2690 sites x 240 species

taxa <- unique(presence_data$verbatim_name)

binary_data1 <- binary_data %>% filter(tp == 1)
binary_data2 <- binary_data %>% filter(tp == 2)
binary_data3 <- binary_data %>% filter(tp == 3)
binary_list <- list(binary_data1, binary_data2, binary_data3)


# Convert to matrix:

binary_matrix <-binary_data %>%
  # filter(cell_grouping == "cell1grid") %>%
  # filter(tp == 1) %>%
  as.matrix()

```

### 4.1 Exploring the data: Sampling effort & Species Richness

-   Sampling effort
-   Species richness
-   SR \~ effort

```{r}
# Convert presence data (original resolution) into spatial object
presence_data_sf <- presence_data %>% 
  filter(cell_grouping == "cell1grid") %>% 
  
  # filter records without coordinates:
  filter(!is.na(cell_long) & !is.na(cell_lat)) %>% 
  st_as_sf(coords=c('cell_long', 'cell_lat'),
           crs=st_crs(grid_list[[1]]))

presence_data_sf_allgrains <- presence_data %>% 
  # filter records without coordinates
  filter(!is.na(cell_long) & !is.na(cell_lat)) %>% 
  st_as_sf(coords=c('cell_long', 'cell_lat'),
           crs=st_crs(grid_list[[1]]))

# Add effort and species richness to grid object
grid_data_original <- merge(grid_list[[1]], presence_data) %>% 
  group_by(cell_label, tp, effort) %>% 
  mutate(SR=n_distinct(verbatim_name, na.rm = TRUE)) %>%  
  unique()

# Calculate species richness per cell, scale and sampling period:
temp_df <- presence_data %>% filter_all(any_vars(!is.na(.))) %>%
  group_by(dataset, cell_grouping, cell_label, tp) %>% 
  summarise(
    SR_cell = n()) %>% 
  # Calculate range, mean(+ sd) of SR and mean diff (+ sd) in SR between years:
  ungroup() %>%
  group_by(dataset, cell_grouping, tp) %>%  
  mutate (minSR_cell = min(SR_cell),
          maxSR_cell = max(SR_cell),
          meanSR_cell = mean(SR_cell),
          sdSR_cell = sd(SR_cell)) %>% 
  mutate(Diff_SR_meanSR = SR_cell - meanSR_cell) %>% 
  mutate(Diff_SR_meanSR = round(Diff_SR_meanSR, 2),
          sdSR_cell = round(sdSR_cell, 2)) %>% 
   ungroup() 

# How does species richness scale across sampling periods? ================== #

min <- min(temp_df$meanSR_cell)
max <- max(temp_df$meanSR_cell)+10

sr_pl <- temp_df %>%
   ggplot(aes(
     y = meanSR_cell, 
     x = cell_grouping, 
     col = as.factor(tp))) +
   geom_point(alpha = 0.6) +
   geom_line(aes(group = tp))+
   ylab("mean Species Richness") +
   xlab("Scale") +
   theme_classic() +
   labs(color = "Start Year of Sampling Period", 
       title = "Mean Species Richness across Scales",
       subtitle = "Number above boxes = mean species richness") +
   scale_y_continuous(breaks = seq(0, max, by = 50), limits = c(0, max)) +
   geom_text(aes(label = round(meanSR_cell, 2), y = meanSR_cell),
            vjust = -3, size = 2, position = position_dodge(width = 1)) + 
   scale_color_viridis(discrete = TRUE, alpha = 0.9)


# ================================= Some Plots ============================== #


#  Species Richness map:
srm <- ggplot(data = grid_data_original)+
  geom_sf(aes(fill = SR))+
  theme_void()+
  facet_grid(factor(tp)~.)+
  scale_fill_viridis() 


# Effort map:
em <- ggplot(data = grid_data_original)+
  geom_sf(aes(fill = effort))+
  theme_void()+
  facet_grid(factor(tp)~.)+
  scale_fill_viridis() 

# Panel plot of both: 
sr_em <- grid.arrange(srm, em, ncol=2) 

# Sampling effort ~ time boxplots
means <- aggregate(effort ~  tp, grid_data_original, mean)

ef_bp <- grid_data_original %>%
  ggplot(aes(y = effort, x= factor(tp)))+
  geom_boxplot(fill = "lightgrey", outlier.color = "red")+
  theme_classic()+  
  # Add mean
  stat_summary(fun=mean, colour="darkred", 
               geom="point", shape=18, 
               size=3, show.legend=FALSE) + 
  geom_text(data = means, aes(label = round(effort,2), y = 0))+
  xlab("Time Periods") +
  ylab("Sampling effort (N cards)")


# Species Richness ~ Effort scatter plot
sr_e_sp <- ggplot(data = grid_data_original, aes(x = effort, y = SR, col = factor(tp)))+
  geom_point()+
  geom_smooth(method='lm')+
  theme_classic()+
  scale_color_viridis(discrete = T, alpha = 0.65)


# ////////////// Outlier removal //////////////// #

# Effort Map (without outliers)
em2 <- grid_data_original %>% 
  mutate(effort = case_when(effort > 30 ~ 30,
                            effort < 30 ~ effort)) %>%
  ggplot()+
  geom_sf(aes(fill = effort))+
  theme_void()+
  facet_grid(factor(tp)~.)+
  scale_fill_viridis() 
 
  
  # Panel plot of both: 
sr_em2 <- grid.arrange(srm, em2, ncol=2) 

```

```{r, eval = F}
#|label: save plots to file
ggsave(plot = sr_pl, 
       filename = "SpeciesRichness_PointLine.pdf",
       path = paste0(out_path, "Figs/"),
       width = 8,
       height = 6)

ggsave(plot = srm,
  filename = "SR_map.pdf",
       path = paste0(out_path, "Figs/"),
       device = cairo_pdf,
       width = 210,
       height = 297,
       units = "mm")

ggsave(plot = em,
       filename = "Effort_map.pdf",
       path = paste0(out_path, "Figs/"),
       device = cairo_pdf,
       width = 210,
       height = 297,
       units = "mm")

ggsave(plot = sr_em,
       filename = "SR_Effort_maps_panel.pdf",
       path = paste0(out_path, "Figs/"),
       device = cairo_pdf,
       width = 297,
       height = 210,
       units = "mm") # save as A4 landscape pdf

ggsave(plot = ef_bp,
       filename = "Effort_time_boxplot.pdf",
       path = paste0(out_path, "Figs/"),
       width = 8,
       height = 6)

ggsave(plot = sr_e_sp,
       filename = "SR_effort_plot.pdf",
       path = paste0(out_path, "Figs/"),
       width = 8,
       height = 6)

ggsave(plot = em2,
       filename = "Effort_map_outliers_removed.pdf",
       path = paste0(out_path, "Figs/"),
       device = cairo_pdf,
       width = 210,
       height = 297,
       units = "mm")

ggsave(plot = sr_em2,
       filename = "SR_Effort_maps_panel_outliers_removed.pdf",
       path = paste0(out_path, "Figs/"),
       device = cairo_pdf,
       width = 297,
       height = 210,
       units = "mm") # save as A4 landscape pdf

```

#### Scaling sampling effort (0-1)

```{r}
# Map: scale effort by time periods 
# (between 0 and 1 for comparative reasons between groups)
tp1 <- grid_data_original %>% 
  select(cell_grouping, SR, effort, tp, cell_label) %>% unique() %>%
  filter(cell_grouping == "cell1grid") %>%
  filter(effort > 0) %>% 
  filter(tp == 1 | tp == 2)  %>%
  filter_at(vars(effort), any_vars(!is.na(.))) 
tp1$effort_scaled <- rescale(tp1$effort, to = c(0, 1))

tp2 <- grid_data_original %>% 
  select(cell_grouping, SR, effort, tp, cell_label) %>% unique() %>%
  filter(cell_grouping == "cell1grid") %>%
  filter(effort > 0) %>% 
  filter(tp == 1 | tp == 2)  %>%
  filter_at(vars(effort), any_vars(!is.na(.))) 
tp2$effort_scaled <- rescale(tp2$effort, to = c(0, 1))

tp3 <- grid_data_original %>%   
  select(cell_grouping, SR, effort, tp, cell_label) %>% unique() %>%
  filter(cell_grouping == "cell1grid") %>%
  filter(effort > 0) %>% 
  filter(tp == 3)  %>%
  filter_at(vars(effort), any_vars(!is.na(.))) 
tp3$effort_scaled <- rescale(tp3$effort, to = c(0, 1))
effort_scaled_df <- rbind(tp1, tp2, tp3)

effort_scaled_df %>%
ggplot(aes(x=log(effort_scaled)))+
  geom_density()+
  facet_wrap(tp~.)+
  theme_classic()

## Map the scaled scampling effort:
ef_sc_map <- effort_scaled_df %>% group_by(tp) %>%
  ggplot()+
  geom_sf(aes(fill = log(effort_scaled)))+
  theme_void()+
  facet_grid(factor(tp)~.)+
  scale_fill_viridis() 

# How does sampling effort scale? =========================================== #
presence_data %>% ungroup() %>% 
  group_by(tp, cell_grouping) %>% 
  select(effort) %>% 
  get_summary_stats(type = "mean_sd")

presence_data %>% 
  ungroup() %>% 
  select(tp, cell_grouping, effort) %>% 
  unique() %>% 
  group_by(tp, cell_grouping) %>% 
  summarise(n= n(),
            min_effort = min(effort),
            mean_effort = mean(effort),
            sd_effort = sd(effort),
            max_effort = max(effort))

presence_data %>%
  ungroup() %>%
  select(tp, cell_grouping, effort) %>%
  filter(cell_grouping != "cellfullgrid") %>%
  unique() %>%
  group_by(tp, cell_grouping) %>%
  mutate(mean_effort = mean(effort)) %>% 
  
  ggplot(aes(y = effort, x = cell_grouping, fill = as.factor(tp))) +
  geom_boxplot(alpha = 0.6) +
  ylab("Sampling Effort (N Collectors)") +
  xlab("Scale") +
  theme_classic() +
  scale_fill_viridis(discrete = TRUE, alpha = 0.7) +
  labs(fill = "Start Year of Sampling Period", 
       title = "Scaling of Sampling Effort across Sampling Periods",
       subtitle = "Number above boxes = mean sampling effort") +
  scale_y_continuous(breaks = seq(0, max(presence_data$effort), by = 100)) +
  geom_text(aes(label = round(mean_effort, 2), y = mean_effort),
            vjust = -15, size = 2, position = position_dodge(width = 0.75))  


ef_sc_bp <- effort_scaled_df %>%
  ungroup() %>%
  select(tp, effort_scaled) %>%
  unique() %>%
  group_by(tp) %>%
  mutate(mean_effort_scaled = mean(effort_scaled)) %>% 
  
  ggplot(aes(y = log(effort_scaled), x = factor(tp), fill = factor(tp))) +
  geom_boxplot(alpha = 0.6) +
  ylab("Sampling effort scaled") +
  xlab("Sampling period") +
  theme_classic() +
  scale_fill_viridis(discrete = TRUE, alpha = 0.7) +
  labs(fill = "Sampling Period", 
       title = "Scaling of Sampling Effort across Sampling Periods",
       subtitle = "Number above boxes = mean sampling effort scaled") +
  geom_text(aes(label = round(mean_effort_scaled, 2), y = mean_effort_scaled),
            vjust = 1.15, size = 5, position = position_dodge(width = 0.75))


```

```{r}, eval = F}
ggsave(plot = ef_sc_map,
         filename = "Effort_map_scaled.pdf",
         path = paste0(out_path, "Figs/"),
         device = cairo_pdf,
         width = 210,
         height = 297,
         units = "mm")

ggsave(plot = ef_sc_bp, 
       filename = "SamplingEffort_boxplot.pdf",
       path = paste0(out_path, "Figs/"),
       width = 8, 
       height = 6)
```

### 4.2 Quality checks

Telfer : (quote from Sparta Vignette: https://github.com/BiologicalRecordsCentre/sparta/blob/master/vignettes/sparta_vignette.Rmd)

Telfer's change index is designed to assess the relative change in range size of species between two time periods ([Telfer et al, 2002](http://www.sciencedirect.com/science/article/pii/S0006320702000502#)). This is a simple method that is robust but has low power to detect trends where they exist. While this method is designed to compare two time periods, sparta can take many time periods and will complete all pairwise comparisons.

```{r}
# both unbiased
results <- sparta::dataDiagnostics(taxa = presence_data$verbatim_name,
                           site = presence_data$cell_label,
                           time_period = presence_data$tp,
                           progress_bar = FALSE)

# Telfer:

telfer_results <- sparta::telfer(taxa = presence_data$verbatim_name,
                         site = presence_data$cell_label,
                         time_period = presence_data$tp,
                         minSite = 2)

telfer_results2 <- telfer_results %>% 
  select(taxa, Telfer_1_2, Telfer_2_3, Telfer_1_3) %>% 
  rename(verbatim_name = taxa)

head(telfer_results)

ggp1 <- ggplot(data = telfer_results) +
  geom_histogram(aes(x = Telfer_1_2), bins = 20, 
                 bg = "lightgrey", col = "darkgrey")+
  theme_classic() +
  xlim(-4, 4)+
  ylim(0, 85)+ 
  # Add line for mean:
  geom_vline(xintercept = mean(telfer_results$Telfer_1_2, na.rm=T),
             col = "red",
             lwd = 1) +
  # Add text for mean:
   annotate("text",                        
           x = mean(telfer_results$Telfer_1_2, na.rm=T) -2.5,
           y = mean(telfer_results$Telfer_1_2, na.rm=T) +80,
           label = paste("Mean =", 
                         round(mean(telfer_results$Telfer_1_2, na.rm=T),
                               3)
                         ),
           col = "red",
           size = 6)+
  # Add line for mean:
    geom_vline(xintercept = median(telfer_results$Telfer_1_2, na.rm=T), 
             col = "orange",
             lwd = 1) +
  # Add text for mean:
     annotate("text",                        
           x = mean(telfer_results$Telfer_1_2, na.rm=T) -2.5,
           y = mean(telfer_results$Telfer_1_2, na.rm=T) +70,
           label = paste("Median =", 
                         round(median(telfer_results$Telfer_1_2, na.rm=T),
                               3)
                         ),
           col = "orange",
           size = 6)

ggp2 <- ggplot(data = telfer_results) +
  geom_histogram(aes(x = Telfer_2_3), bins = 20, 
                 bg = "lightgrey", col = "darkgrey")+
  theme_classic() +
   # Add line for mean
  geom_vline(xintercept = mean(telfer_results$Telfer_2_3, na.rm=T),     
             col = "red",
             lwd = 1) +
  xlim(-4, 4)+
  ylim(0, 85)+
  # Add text for mean
   annotate("text",                        
           x = mean(telfer_results$Telfer_2_3, na.rm=T) -2.5,
           y = mean(telfer_results$Telfer_2_3, na.rm=T) +80,
           label = paste("Mean =", 
                         round(
                           mean(telfer_results$Telfer_2_3, na.rm=T),
                           3)
                         ),
           col = "red",
           size = 6)+
  # Add line for mean:
    geom_vline(xintercept = median(telfer_results$Telfer_1_2, na.rm=T),       
             col = "orange",
             lwd = 1) +
  # Add text for mean:
     annotate("text",                        
           x = mean(telfer_results$Telfer_2_3, na.rm=T) -2.5,
           y = mean(telfer_results$Telfer_2_3, na.rm=T) +70,
           label = paste("Median =", 
                         round(median(telfer_results$Telfer_2_3, na.rm=T),
                               3)
                         ),
           col = "orange",
           size = 6)

ggp3 <- ggplot(data = telfer_results) +
  geom_histogram(aes(x = Telfer_1_3), bins = 20, 
                 bg = "lightgrey", col = "darkgrey")+
  theme_classic() +
  # Add line for mean:
  geom_vline(xintercept = mean(telfer_results$Telfer_1_3, na.rm=T),        
             col = "red",
             lwd = 1) +
  xlim(-4, 4)+
  ylim(0, 85)+
   annotate("text",                        # Add text for mean
           x = mean(telfer_results$Telfer_1_3, na.rm=T) -2.5,
           y = mean(telfer_results$Telfer_1_3, na.rm=T) +80,
           label = paste("Mean =", 
                         round(mean(telfer_results$Telfer_1_3, na.rm=T),
                               3)
                         ),
           col = "red",
           size = 6)+
  # Add line for mean:
    geom_vline(xintercept = median(telfer_results$Telfer_1_3, na.rm=T),        
             col = "orange",
             lwd = 1) +
 # Add text for mean:
     annotate("text",                        # Add text for mean
           x = mean(telfer_results$Telfer_1_3, na.rm=T) -2.5,
           y = mean(telfer_results$Telfer_1_3, na.rm=T) +70,
           label = paste("Median =", 
                         round(median(telfer_results$Telfer_1_3, na.rm=T),
                               3)
                         ),
           col = "orange",
           size = 6)

ggp_telfer <- grid.arrange(ggp1, ggp2, ggp3)
#plot(ggp_telfer)
 ggsave(ggp_telfer, filename = paste0(out_path, "Figs/Telfer_hist.pdf"), width = 8, height = 8)
```

### 5. Occupancy calculation

-   There are several ways we could calculate the occupancy.

    1.  counting the number of occupied cells and calculating the proportion of all cells that were sampled

    2.  Summing the areas of all occupied cells and calculating the proportion from the whole sampled area

    3.  AOO based on IUCN standards: $AOO = Nr.ofoccupied cells * area of single a cell$

    4.  Modeling occupancy using occupancy-detection models

-   Question: Do all of these yield the same measure for fractal dimension?

Anyway, here we calculate both (1), (2) and (3). (4) Will be done at a later stage of my PhD

```{r}
#| label: AOO calculation across scales and species

occ_data_list <- list()

# We run the loop for each spatial grain (N = 8)
for (i in seq_along(grid_list)){
  
  # subset the grid_list and work on a single spatial grain:
  map_atlas <- grid_list[[i]] 
  
  # Calculate total sampled area per time period:
  map_atlas <- map_atlas %>% mutate(Total_area1 = sum(map_atlas$area1s),
                       Total_area2 = sum(map_atlas$area2s),
                       Total_area3 = sum(map_atlas$area3s))
  
  # Calculate total number of sampled cells per time period:
  Total_Ncells1 <- map_atlas %>% filter(area1s > 0) %>% 
    mutate(Total_Ncells1 = length(unique(cell_label))) %>%
    pull(Total_Ncells1) %>% unique()
  Total_Ncells2 <- map_atlas %>% filter(area2s > 0) %>% 
    mutate(Total_Ncells2 = length(unique(cell_label))) %>%
    pull(Total_Ncells2) %>% unique()
  Total_Ncells3 <- map_atlas %>% filter(area3s > 0) %>% 
    mutate(Total_Ncells3 = length(unique(cell_label))) %>%
    pull(Total_Ncells3) %>% unique()
  
  Total_Ncells <- data.frame(cell_grouping = unique(map_atlas$cell_grouping), 
                             Total_Ncells1, Total_Ncells2, Total_Ncells3)
  
  map_atlas <- merge(map_atlas, Total_Ncells)
  
  map_atlas %>% 
    pivot_longer(cols=c('Total_Ncells1', 'Total_Ncells2', 'Total_Ncells3'),
                 names_to='year',
                 values_to='Total_N_cells')

  # subset the presence/absence data to the current spatial grain:
  pres_data <- presence_data %>% 
    filter(cell_grouping == unique(map_atlas$cell_grouping))

  # Merge sampled and unsampled cells for calculations:
  pres_data_full <- merge(pres_data, map_atlas, 
                          by = intersect(names(pres_data), names(map_atlas)), 
                          all = T)
  pres_data_full <- unique(pres_data_full)

  # Reduce columns needed for analysis:
  pres_data_full_reduced <- pres_data_full %>% 
  ungroup() %>% 
    mutate(
      area_sampled = case_when(
        tp == 1 ~ area1s,
        tp == 2 ~ area2s,
        tp == 3 ~ area3s),
      area_c = case_when(
        tp == 1 ~ area_cropped,
        tp == 2 ~ area_cropped,
        tp == 3 ~ area_cropped),
      Total_area =case_when(
        tp == 1 ~ Total_area1,
        tp == 2 ~ Total_area2,
        tp == 3 ~ Total_area3),
      Total_Ncells = case_when(
        tp == 1 ~ Total_Ncells1,
        tp == 2 ~ Total_Ncells2,
        tp == 3 ~ Total_Ncells3)) %>% 
    select(verbatim_name, tp, cell_grouping, cell_label,
           area_sampled, area_c, Total_area, Total_Ncells) %>%
    filter_all(any_vars(!is.na(.)))
  
## ========================================================================= ##
##  ========================== Calculate Occupancy ========================= ##
## ========================================================================= ##

occ_data <- pres_data_full_reduced %>%
  ungroup() %>%   
  
# Remove unsampled cells:  
  filter(!is.na(verbatim_name)) %>%

# Necessary grouping to calculate occupancy:
  group_by(verbatim_name, tp, cell_grouping) %>% unique() %>%
  
# Calculate Occupancy:
  mutate(occupancy_area = sum(area_sampled)) %>%
  mutate(occupancy_Ncells = length(unique(cell_label))) %>%
  
# Calculate AOO:
  mutate(AOO = occupancy_Ncells * mean(area_sampled)) %>%
  
# Calculate relative Occupancy:
  mutate(relative_occupancy_area = occupancy_area/Total_area) %>%
  mutate(relative_occupancy_Ncells = occupancy_Ncells/Total_Ncells) %>%
  
# Round values to 2 digits after the comma:
  mutate(relative_occupancy_area = round(relative_occupancy_area, 3)) %>% 
  mutate(relative_occupancy_Ncells = round(relative_occupancy_Ncells, 3)) %>% 

# Remove duplicated rows:
  distinct() 

# save to list:
occ_data_list[[i]] <- occ_data

}

# Bind to one dataframe:
occ_data_full_df <- plyr::rbind.fill(occ_data_list, fill=T)
# occ_data_full_df %>%  filter_all(any_vars(is.na(.)))

# create scale column as a fraction of the full country:
occ_data_full_df2 <- occ_data_full_df %>% mutate(
      scale = case_when(
        cell_grouping == "cell1grid" ~ 1/32,
        cell_grouping == "cell2grid" ~ 1/16,
        cell_grouping == "cell4grid" ~ 1/8,
        cell_grouping == "cell8grid" ~ 1/4,
        cell_grouping == "cell16grid" ~ 1/2 ,
        cell_grouping == "cellfullgrid" ~ 1)) %>% unique()
gc()
# save.image(paste0(out_path, "Scale_Area_Curves_Occu_calc.RData"))


# save reduced version of this to file:

species_data <- occ_data_full_df2 %>% select(-c(cell_label, area_sampled, area_c)) %>% distinct() 
# species_data %>% write.csv(paste0(out_path, "Occupancy_table.csv"))
```

```{r}

## Not helpful plot ###
# occ_data_full_df %>% filter(cell_grouping == "cell1grid") %>%
#   ggplot(aes(y = AOO, x = factor(tp), col = factor(verbatim_name)), 
#          show.legend = F)+
#   geom_point( show.legend = F)+
#   geom_line(aes(group = verbatim_name), show.legend = F, lwd = 1.2)+
#   theme(legend.position = "none")+
#   theme_classic()+
#   scale_color_viridis(discrete = T)
```

```{r, fig.height = 3, fig.width = 4, fig.show='hold'}
## Some checks: ============================================================================= ####

par(mfrow = c(2,2))
species_data %>% 
  filter(cell_grouping == "cell1grid") %>%
  ggplot()+
  geom_point(aes(y = occupancy_area, x = occupancy_Ncells, 
                 col = factor(tp)))+
  theme_classic()+
  scale_color_viridis(discrete = T)

species_data %>% 
  filter(cell_grouping == "cell1grid") %>%
  ggplot()+
  geom_point(aes(y = relative_occupancy_area, x = relative_occupancy_Ncells, 
                 col = factor(tp)))+
  theme_classic()+
  scale_color_viridis(discrete = T)

species_data %>% 
  filter(cell_grouping == "cell1grid") %>%
  ggplot()+
  geom_point(aes(y = occupancy_Ncells, x = relative_occupancy_Ncells, 
                 col = factor(tp)))+
  theme_classic()+
  scale_color_viridis(discrete = T)

occ_data_full_df2 %>% 
  select(area_sampled, scale, tp) %>% 
  distinct() %>%
  ggplot()+
  geom_point(aes(y = log(area_sampled) , x = log(scale), 
                 col = factor(tp)))+
  theme_classic()+
  scale_color_viridis(discrete = T)
```

#### 5.2 Modeling Occupancy

```{r, eval = FALSE, echo = T}
myData <- presence_data %>%
  filter(cell_grouping == "cell1grid") %>%
  select(
    tp, end_year, cell_label,
    verbatim_name, cell_grouping, tp, time_periods,
    effort, years
  ) %>%
  unique()


# in sparta ==================================================================================
# myData <- myDataSubset2
taxa <- unique(myData$verbatim_name)

occ_data <- formatOccData(
  myData$verbatim_name,
  myData$cell_label,
  myData$tp,
  replicate = NULL,
  closure_period = (myData$tp),
  includeJDay = FALSE
)

occ_out <- occDetFunc(
  taxa_name = taxa[1],
  n_iterations = 50,
  burnin = 15,
  occDetdata = occ_data$occDetdata,
  spp_vis = occ_data$spp_vis,
  write_results = FALSE
)


occ_out <- occDetFunc(
  taxa_name = taxa[1],
  occDetdata = occ_data$occDetdata,
  spp_vis = occ_data$spp_vis,
  n_iterations = 50000,
  burnin = 5000,
  n_chains = 2
)
# did not converge:
## Error in x$Version : $ operator is invalid for atomic vectors


# Other options for the model:
occ_out <- NULL




results <- occ_out <- occDetFunc(
  taxa_name = taxa[2],
  occDetdata = occ_data$occDetdata,
  spp_vis = occ_data$spp_vis,
  n_iterations = 200,
  write_results = F,
  burnin = 15,
  n_chains = 3,
  thinning = 3,
  seed = 123
)




occDetFunc(
  taxa_name = taxa[1],
  n_iterations = 50,
  burnin = 15,
  occDetdata = occ_data$occDetdata,
  spp_vis = occ_data$spp_vis,
  write_results = FALSE
)

```

### 6.1 Scale-Area-Curves

$$n = n0 L^-FD$$

(-FD is exponent, Hausdorff dimension)

n0 is constant

number of occupied quadrates n and L (side length of quadrat)

FD=−ln(L)/ln(n0​n​)​\
**FD = - (ln(n/n_0))/(- ln(L))**

n_0 = intercept (b) ?????

n = AOO ??????

L = scale ?????

***Hausdorff dimension:*** --\> decoupled from topological dimension !!

D = lim r-\> 0 (-log N(r)/log r)

N(r) is the smallest number of open balls needed to cover the set X

r -\> 0 smallest radius of a ball needed to cover set X

Box-counting dimension:

$$
N(s) = cs^-.^ D
$$

D = (Log(N~1~) -- Log (N~2~))/ (log (1/s~1~) --  log (1/s~2~))

-   D = - (log(N(s))/(log (s) + log (c) )

-   reformulate to: log(N(s)) = - D log (s) + log(c)

-   which is similar to linear equation: y = mx + b

s = scale where s = 1 is scale at which whole object is covered

We need at least 2 different scales

### How fractal is the data?

The straighter the line, the more fractal it is.

The following analyses all depend on the assumption that species distributions are fractal, therefore we test it first by fitting a linear and a non-linear model and comparing AICc scores to determine which model better fits the data

```{r,fig.height = 3, fig.width = 4}
#| label: Scale-Area-Relationships

# exclude saturated species for all calculations 
# (that require a linear relationship between scale and occupancy.)

dd <- species_data %>%
  filter(relative_occupancy_area != 1 & relative_occupancy_Ncells != 1) %>% # exclude saturated scales
  unique() %>%
  filter_at(vars(c(cell_grouping, scale, 
                   AOO, occupancy_area, occupancy_Ncells, 
                   relative_occupancy_area, relative_occupancy_Ncells)), 
            any_vars(!is.na(.)))





#### Subset the data by at last 3 scales (minimum n needed to calculate 2nd degree poly relationship)
sp_3scales <- dd %>% select(verbatim_name, tp, cell_grouping) %>% distinct() %>% group_by(verbatim_name, tp) %>% summarize(n = n_distinct(cell_grouping)) %>% filter(n >= 3) %>% distinct(verbatim_name) %>% as.vector()

#### Subset the data by at least 2 time points
dd %>% filter(verbatim_name %in% sp_3scales$verbatim_name) %>% select(verbatim_name, tp) %>%distinct() %>% group_by(verbatim_name) %>% summarize(time_points = n())%>% filter(time_points == 2)


## Looks linear for communities !!
dd %>% 
  ggplot(aes(y = log(AOO), x = log(scale)), col = factor(tp))+
  geom_jitter(aes(col = factor(tp)))+
  geom_smooth(aes(col = factor(tp)), method = "lm", formula = y ~ x )+
  scale_color_viridis(discrete=T)+
  theme_classic()

```

```{r}
## Loop through years and species ###

AIC_list <- list()
m_df_all <- list()
m_df_all_years <- list()
m_df1_list <- list()
m_df1_list_years <- list()
AIC_list_years <- list()

for (y in seq_along(unique(dd$tp))) { # //// filter by year //// #

  dd_temp <- dd %>% filter(tp == y)

  for (i in seq_along(unique(dd_temp$verbatim_name))) { # //// filter by taxa //// #
    sp <- unique(dd_temp$verbatim_name)[i]

    model_dd <- dd_temp %>%
      filter(verbatim_name == sp)
      
    # //// Linear Models //// #
    
    # one for each measure of occupancy (N = 5) #
    
    m1_1 <- lm(log(AOO) ~ log(scale), data = model_dd)

    ## For other AOO measures:
    m1_2 <- lm(log(occupancy_area) ~ log(scale), data = model_dd)
    m1_3 <- lm(log(occupancy_Ncells) ~ log(scale), data = model_dd)
    m1_4 <- lm(log(relative_occupancy_area) ~ log(scale), data = model_dd)
    m1_5 <- lm(log(relative_occupancy_Ncells) ~ log(scale), data = model_dd)

    # Make data frame for each species (Linear = m_df1)
    # naming convention follows linear formula: y = mx + b 
    # (i.e., b = intercept, m = slope)
    
    m_df1 <- data.frame(
      row.names = c("linear"),      
      verbatim_name = sp,
      tp = y, 
      
      m_AOO = m1_1$coefficients[2],
      b_AOO = m1_1$coefficients[1],
      r2_AOO = summary(m1_1)$r.squared,
      
      m_occArea = m1_2$coefficients[2],
      b_occArea = m1_2$coefficients[1],
      r2_occArea = summary(m1_2)$r.squared,
      
      m_occNcells = m1_3$coefficients[2],
      b_occNcells = m1_3$coefficients[1],
      r2_occNcells = summary(m1_3)$r.squared,
      
      m_occRelArea = m1_4$coefficients[2],
      b_occRelArea = m1_4$coefficients[1],
      r2_occRelArea = summary(m1_4)$r.squared,
      
      m_occRelNcells = m1_5$coefficients[2],
      b_occRelNcells = m1_5$coefficients[1],
      r2_occRelNcells = summary(m1_5)$r.squared
      )

    m_df1_list[[i]] <- m_df1 #create backup dataframe from linear models so we can save it to file
  ### Break =============
    if(nrow(model_dd) <= 2) {cat("Skipping data", sp[i], "as it doesn't have the required length\n")
      m_df_all[[i]] <- m_df1
      next}
      
    # //// Poly-Models //// #
    
    m2_1 <- lm(log(AOO) ~ poly(scale, 2), data = model_dd)

    ## For other AOO measures:
    m2_2 <- lm(log(occupancy_area) ~ poly(scale, 2), data = model_dd)
    m2_3 <- lm(log(occupancy_Ncells) ~ poly(scale, 2), data = model_dd)
    m2_4 <- lm(log(relative_occupancy_area) ~ poly(scale, 2), data = model_dd)
    m2_5 <- lm(log(relative_occupancy_Ncells) ~ poly(scale, 2), data = model_dd)

    # Make data frame for each species (Poly = m_df2)
    # naming convention follows linear formula: y = mx + b 
    # (i.e., b = intercept, m = slope)

    m_df2 <- data.frame(
      row.names = c("poly"),      
      verbatim_name = sp,
      tp = y, 
      
      m_AOO = m2_1$coefficients[2],
      b_AOO = m2_1$coefficients[1],
      r2_AOO = summary(m2_1)$r.squared,
      
      m_occArea = m2_2$coefficients[2],
      b_occArea = m2_2$coefficients[1],
      r2_occArea = summary(m2_2)$r.squared,
      
      m_occNcells = m2_3$coefficients[2],
      b_occNcells = m2_3$coefficients[1],
      r2_occNcells = summary(m2_3)$r.squared,
      
      m_occRelArea = m2_4$coefficients[2],
      b_occRelArea = m2_4$coefficients[1],
      r2_occRelArea = summary(m2_4)$r.squared,
      
      m_occRelNcells = m2_5$coefficients[2],
      b_occRelNcells = m2_5$coefficients[1],
      r2_occRelNcells = summary(m2_5)$r.squared
      )
    


    #  Model selection based on AICc ===================================== ####
    
    models_list_AOO <- list(m1_1, m2_1)
    models_list_occArea <- list(m1_2, m2_2)
    models_list_occNcells <- list(m1_3, m2_3)
    models_list_occRelArea <- list(m1_4, m2_4)
    models_list_occRelNcells <- list(m1_5, m2_5)
  
    # AIC 1
    AIC_AOO <- data.frame(aictab(models_list_AOO, 
                                 modnames = c("linear", "poly")),
                          verbatim_name = sp,
                          model = "AOO") 
    # AIC 2
    AIC_occArea <- data.frame(aictab(models_list_occArea, 
                                     modnames = c("linear", "poly")),
                              verbatim_name = sp,
                          model = "occArea") 
    # AIC 3
    AIC_occNcells <- data.frame(aictab(models_list_occNcells, 
                                       modnames = c("linear", "poly")),
                                verbatim_name = sp,
                          model = "occNcells") 
    # AIC 4
    AIC_occRelArea <- data.frame(aictab(models_list_occRelArea, 
                                        modnames = c("linear", "poly")),
                                 verbatim_name = sp,
                          model = "occRelArea")
    # AIC 5
    AIC_occRelNcells <- data.frame(aictab(models_list_occRelNcells, 
                                          modnames = c("linear", "poly")),
                                   verbatim_name = sp,
                          model = "occRelNcells")

    AIC_tab <- rbind(AIC_AOO, AIC_occArea, AIC_occNcells, 
                     AIC_occRelArea, AIC_occRelNcells) 
    AIC_list[[i]] <- AIC_tab
    
    
    m_df1$Modnames <- rownames(m_df1)
    m_df2$Modnames <- rownames(m_df2)
    m_df3 <- rbind(m_df1, m_df2)
    m_df3$Modnames <- rownames(m_df3)
    
    
    m_df4 <- merge(m_df3, AIC_tab, by = c("Modnames", "verbatim_name"))
    
    m_df_all[[i]] <- m_df4

    rm(m_df1, m_df2)
  }


  m_df1_list_df <- plyr::rbind.fill(m_df1_list, fill = T)
  m_df_all2 <- plyr::rbind.fill(m_df_all, fill = T)
  AIC_list_taxa <- plyr::rbind.fill(AIC_list, fill = T)
  
  m_df_all_years[[y]] <- m_df_all2
  m_df1_list_years[[y]] <- m_df1_list_df
  AIC_list_years[[y]] <- AIC_list_taxa
  
}

## Bind list elements to dataframe:
m_df_all_years2 <- plyr::rbind.fill(m_df_all_years, fill = T) %>% distinct()
m_df1_list_years2 <- plyr::rbind.fill(m_df1_list_years, fill = T) %>% distinct()
m_df_all_years2$model <- as.factor(m_df_all_years2$model)


```

## why are there so many NAs in it right now??? to do: find error

#### Create final data

```{r}
#|message = F
# Re-format the data =================================================================== ####
# First: Subset to linear and poly species & Reformat to long-format

m_df_all_years2_linear <- m_df_all_years2 %>% 
  filter(Modnames == "linear")
 
m_df_long <- m_df_all_years2_linear %>% 
  # filter(Delta_AICc <= 2 & AICcWt >= 0.60) %>%
  select(-c(K, AICc, ModelLik, LL, Cum.Wt)) %>% distinct() %>% 
  pivot_longer(cols = matches("AOO|occArea|occNcells|occRelArea|occRelNcells"), 
               names_to = "Variable", 
               values_to = "Value") %>%
  mutate(
    model = case_when(
    str_detect(Variable, "AOO") ~ "AOO",
    str_detect(Variable, "occArea") ~ "occupancy_area",
    str_detect(Variable, "occNcells") ~ "occupancy_Ncells",
    str_detect(Variable, "occRelArea") ~ "relative_occupancy_area",
    str_detect(Variable, "occRelNcells") ~ "relative_occupancy_Ncells",
    TRUE ~ NA_character_),
    Variable = case_when(
    str_detect(Variable, "m") ~ "m",
    str_detect(Variable, "b") ~ "b",
    str_detect(Variable, "r2") ~ "r2",
    TRUE ~ NA_character_))


desired_order <- c("occupancy_Ncells", "occupancy_area", "AOO", "relative_occupancy_area", "relative_occupancy_Ncells")
m_df_long$model <- factor(m_df_long$model, levels = desired_order)

m_df_wide <- m_df_long %>% group_by(verbatim_name, tp, Variable, Modnames) %>% distinct() %>%
  #filter(Variable == "m") %>% 
  #select(-Variable) %>% 
  #distinct() %>% 
  pivot_wider(names_from ="Variable", values_from= "Value") 

m_df_wide_AOO <- m_df_wide %>% filter(model == "AOO")

# ======================================================================================= # 

# Add fractal dimensions to the occu data: 
species_data2 <- merge(species_data, m_df_wide_AOO, 
                          by=c("tp", "verbatim_name"), all = T) %>% distinct()
species_data3 <- merge(species_data2, telfer_results2, 
                          by=c("verbatim_name"), all = T) %>% distinct() %>% 
  mutate(across(where(is.numeric), ~ round(., 3))) 

```

```{r}
D_df <- species_data3 %>% 
  filter(Modnames == "linear" & model == "AOO") %>% 
  select(verbatim_name, tp, m) %>% 
  distinct() %>%
  group_by(verbatim_name)
### This looks extremely useful!! Adapt for all species: 


TD_df <- telfer_results2 %>% 
  pivot_longer(cols = c(Telfer_1_2, Telfer_2_3, Telfer_1_3), 
               names_to = "temporal_change", 
               values_to = "Telfer") %>% 
  mutate(tp = case_when(temporal_change == "Telfer_1_2" ~ 1,                                                                            temporal_change == "Telfer_2_3" ~ 2,                                                                            temporal_change == "Telfer_1_3" ~ 3)) %>%
  merge(D_df, by= c("verbatim_name", "tp"))

# plot:
TD_df %>%
  ggplot(aes(y = Telfer, x = m,col = factor(tp)))+
  geom_point(aes(col = factor(tp)))+
  geom_smooth()+
  theme_classic()+
  scale_color_viridis(discrete=T)
```

#### *Summary Table 1: Linear vs. non-linear* (Note: column n includes species \* years)

-   to assess the linear/non-linear relationship between different measures of **occupancy and scale**

-   looks like measures based on NCells do not always fit the linear (fractal) assumption

```{r}
# Summary table: Best fiting models (linear/non-linear) for each occupancy variable
m_df_all_years2 %>% 
  select(Modnames, Delta_AICc, verbatim_name, tp, model, Cum.Wt) %>% distinct(.) %>%
  filter(Delta_AICc <=2) %>%
  # filter(factor(Modnames) == "poly")  %>%
  group_by(verbatim_name, tp, Modnames, model) %>%
    summarize(n= n(),
              Cum.Wt = (Cum.Wt),
              Delta_AICc = Delta_AICc) %>%
    ungroup() %>%
    group_by(Modnames,model) %>%
    summarize(n=n(),
              mean_cumWT = mean(Cum.Wt),
              Delta_AICc = mean(Delta_AICc)) %>%
  mutate(across(where(is.numeric), ~ round(., 3))) 
# %>%
#  write.csv(paste0(out_path, "Linear_Poly_AICc_Summary.csv"))
```

```{r}
#| label: Compare linear vs poly AICc
## Compare linear vs. poly AICc selection
# round to 3 digits:
m_df_all_years2 <- m_df_all_years2 %>%
  mutate(across(where(is.numeric), ~ round(., 3)))



# Model selection based on AICc and weight:
m_df_all_years2 %>% 
  group_by(factor(Modnames), tp, model) %>% 
  filter(Delta_AICc == 0) %>% 
  filter(AICcWt > 0.6) %>% 
  summarize(n=n(),
            meanAICcWt = mean(AICcWt))


m_df_all_years2 %>% 
  filter(Delta_AICc == 0) %>%
  filter(factor(Modnames) == "poly")


m_df_all_years2 %>% filter(Delta_AICc == 0) %>%
  ggplot()+
  geom_jitter(aes(x = Modnames, y = AICcWt, col = model))+
  theme_classic()+
  facet_wrap(tp~.)
  scale_color_viridis()


m_df_all_years2 %>% ggplot()+
  geom_point(aes(x = AICcWt, y = Delta_AICc, col = AICcWt, pch = Modnames), alpha = 0.3)+
  theme_classic()+
  scale_color_viridis()+
  facet_grid(Modnames ~.)
  labs(title = "AICc-based model selectio: Linear vs. Poly", 
       subtitle = "to determine deviation from linear relationship \ni.e. deviation from fractal assumption")

  
# Which are the species that have a poly-relationship? =================== ####

poly_species <- m_df_all_years2 %>% 
  group_by( tp) %>% 
  filter(Delta_AICc == 0) %>% 
  filter(AICcWt > 0.6) %>%
  filter(Modnames == "poly") %>% pull(verbatim_name) %>% unique()

  
presence_data_sf %>% 
  filter(verbatim_name %in% sample(poly_species, 3)) %>% 
  filter(cell_grouping == "cell1grid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[1]], fill = "NA")+
  facet_wrap(verbatim_name+tp~.)+
  theme_void()

# occ_data_full_df %>% 
#   filter(verbatim_name %in% poly_species) %>% 
#   select(-c(cell_label, cell_grouping, area_sampled, area_c, Total_area, Total_Ncells)) %>%
#   ggplot()+
#   geom_point(aes(y = relative_occupancy_Ncells, x = Modnames))


# occ_data_full_df %>% filter(verbatim_name %in% poly_species) %>%
#   ggplot(aes(x = log(scale), y = poly(AOO,2), col = verbatim_name, group=verbatim_name))+
#   geom_point()+
#   geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = T, alpha = 0.5)+
#   scale_color_viridis(discrete = T)+
#   facet_wrap(verbatim_name~.)+
#   theme_classic()+
#   labs(title = "lm(log(AOO) ~ poly(scale, 2), data = model_dd)")
# 
# 
# occ_data_full_df %>% filter(verbatim_name %in% poly_species) %>%
#   ggplot(aes(x = log(scale), y = log(AOO), col = verbatim_name))+
#   geom_point()+
#   geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = T, alpha = 0.5)+
#   scale_color_viridis(discrete = T)+
#   facet_wrap(verbatim_name~.)+
#   theme_classic()+
#   labs(title = "lm(log(AOO) ~ poly(scale, 2), data = model_dd)")

```

#### Summary Table 2: Differences in D between measures of occupancy

2.1) How do the results (slope) of the different ways to calculate occupancy differ?

\--\> keeping only the **linear** model results for **m** (!) (that's why it's called "subset")

```{r}
# First: Reformat the data ! 
m_df_long_subset <- m_df_all_years2 %>% 
  filter(Modnames == "linear") %>%
  select(-c(K, AICc, Delta_AICc, ModelLik, AICcWt, LL, Cum.Wt)) %>% distinct(.) %>% 
  pivot_longer(cols = matches("AOO|occArea|occNcells|occRelArea|occRelNcells"), 
               names_to = "Variable", 
               values_to = "Value") %>%
  mutate(
    model = case_when(
    str_detect(Variable, "AOO") ~ "AOO",
    str_detect(Variable, "occArea") ~ "occupancy_area",
    str_detect(Variable, "occNcells") ~ "occupancy_Ncells",
    str_detect(Variable, "occRelArea") ~ "relative_occupancy_area",
    str_detect(Variable, "occRelNcells") ~ "relative_occupancy_Ncells",
    TRUE ~ NA_character_),
    Variable = case_when(
    str_detect(Variable, "m") ~ "m",
    str_detect(Variable, "b") ~ "b",
    str_detect(Variable, "r2") ~ "r2",
    TRUE ~ NA_character_))

# Quick stats to compare models:
desired_order <- c("occupancy_Ncells", "occupancy_area", "AOO", "relative_occupancy_area", "relative_occupancy_Ncells")
m_df_long_subset$model <- factor(m_df_long_subset$model, levels = desired_order)

library(rstatix)
library(ggpubr)

res.kruskal <- m_df_long_subset %>% filter(Variable == "m") %>% kruskal_test(Value ~ model)
res.kruskal

# Pairwise comparisons
pwc <-  m_df_long_subset %>% filter(Variable == "m") %>%
  dunn_test(Value ~ model, p.adjust.method = "bonferroni") 
pwc <- pwc %>% add_xy_position(x = "model")


m_df_long_subset %>% filter(Variable == "m") %>%
ggboxplot(x = "model", y = "Value", fill = "model", ylab = c("slope of variable~scale"), xlab = c("model variable")) +
  ylim(-2,5)+
  stat_pvalue_manual(pwc, hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(res.kruskal, detailed = TRUE),
    caption = get_pwc_label(pwc)
    )+
  scale_fill_viridis(discrete = T)

m_df_wide_subset <- m_df_long_subset %>% filter(Variable == "m") %>% 
  filter(Modnames == "linear") %>% 
  select(-Variable) %>% distinct() %>% 
  pivot_wider(names_from = "model", values_from= "Value") 

m_df_wide_subset %>% select(-c(verbatim_name, Modnames)) %>%
  GGally::ggpairs(mapping = aes(color = factor(tp), alpha = 0.25), progress = F)


# Summary Table:

summary_df <- m_df_long_subset %>% filter(Variable == "m") %>% select(-Variable) %>% distinct() %>% 
  pivot_wider(names_from = "model", values_from= "Value") %>% ungroup() 

summary_df$occupancy_area_scaled <- rescale(summary_df$occupancy_area)
summary_df$occupancy_Ncells_scaled <- rescale(summary_df$occupancy_Ncells)
summary_df$relative_occupancy_area_scaled <- rescale(summary_df$relative_occupancy_area)
summary_df$relative_occupancy_Ncells_scaled <- rescale(summary_df$relative_occupancy_Ncells)
summary_df$AOO_scaled <- rescale(summary_df$AOO)



summary_df %>% select(-c(verbatim_name, Modnames)) %>%  mutate(across(where(is.numeric), ~ round(., 3))) 
# %>%
  # write.csv(paste0(out_path, "Comparison_slope_different_occuMeasures_Summary.csv"))
```

### 6.2 Example species: Exploring occupancies

```{r}
# Which species have low occupancy at the smallest grid size?
low_occu_sp <- species_data3 %>% filter(cell_grouping == "cell1grid") %>%
  select(verbatim_name, relative_occupancy_area, tp) %>%
  filter(relative_occupancy_area <= 0.15) %>% 
  pull(unique(verbatim_name)) %>% 
  unique()

low_occu <- species_data3 %>% 
  filter(cell_grouping == "cell1grid") %>% 
  filter(verbatim_name %in% low_occu_sp) %>%
  select(verbatim_name, relative_occupancy_area, tp) %>%
  distinct() %>% 
  pivot_wider(names_from = tp, 
              names_prefix = "rel_occu", 
              values_from = relative_occupancy_area)

low_occu_sp_sample <- species_data3 %>% 
   filter(verbatim_name %in% c(sample(low_occu_sp, 9))) %>% 
   pull(verbatim_name) %>% 
   unique()

low_occu_reduced <- species_data3 %>% 
  filter(cell_grouping == "cell1grid") %>% 
  filter(verbatim_name %in% low_occu_sp) %>%
  select(verbatim_name, relative_occupancy_area, tp) %>%
  distinct() %>% 
  pivot_wider(names_from = tp, 
              names_prefix = "rel_occu", 
              values_from = relative_occupancy_area) %>% 
  na.omit() # remove NAs


# Which species have high occupancy at the smallest grid size?
high_occu_sp <- species_data3 %>% 
  filter(cell_grouping == "cell1grid") %>%
  select(verbatim_name, relative_occupancy_area, tp) %>%
  filter(relative_occupancy_area >= 0.99) %>% 
  pull(unique(verbatim_name)) %>% 
  unique()
  
high_occu <- species_data3 %>% 
  filter(cell_grouping == "cell1grid") %>% 
  filter(verbatim_name %in% high_occu_sp) %>%
  select(verbatim_name, relative_occupancy_area, tp) %>%
  distinct() %>% 
  pivot_wider(names_from = tp,
              names_prefix = "rel_occu", 
              values_from = relative_occupancy_area)

high_occu_sp_sample <- species_data3 %>% 
    filter(verbatim_name %in% c(sample(high_occu_sp, 9))) %>% 
    pull(verbatim_name) %>% 
    unique()
spec <- c(low_occu_sp_sample, high_occu_sp_sample)

```

1.1) Which species are very common (\> 0.9 relative occupancy at smallest grain)

```{r}

# Plot the map of some example species:
presence_data_sf %>% 
  filter(verbatim_name %in% high_occu_sp_sample) %>% 
  filter(cell_grouping == "cell1grid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[1]], fill = "NA")+
  facet_wrap(verbatim_name+tp~.)+
  theme_void()

ggsave(filename = "high_occu.pdf",
         path = paste0(out_path, "Figs"),
         device = cairo_pdf,
         height = 210,
         width = 297,
         units = "mm")

```

1.2) Which species are very rare (\< 0.15 relative occupancy at smallest grain)

```{r}

# Plot the map of some example species  ================================== ####
presence_data_sf %>% 
  filter(verbatim_name %in% low_occu_sp_sample) %>%
  filter(cell_grouping == "cell1grid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[1]], fill = "NA")+
  facet_wrap(verbatim_name+tp~., ncol = 6)+
  theme_void()

ggsave(filename = "low_occu.pdf",
         path = paste0(out_path, "Figs"),
         device = cairo_pdf,
         height = 210,
         width = 297,
         units = "mm")

### Other scales:
presence_data_sf_allgrains %>% 
  filter(verbatim_name %in%low_occu_sp_sample) %>% 
  filter(cell_grouping == "cell2grid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[2]], fill = "NA")+
  facet_wrap(verbatim_name+tp~.)+
  theme_void()

presence_data_sf_allgrains %>% 
  filter(verbatim_name %in%low_occu_sp_sample) %>%  
  filter(cell_grouping == "cell4grid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[3]], fill = "NA")+
  facet_wrap(verbatim_name+tp~.)+
  theme_void()

presence_data_sf_allgrains %>%   
  filter(verbatim_name %in%low_occu_sp_sample) %>% 
  filter(cell_grouping == "cell8grid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[4]], fill = "NA")+
  facet_wrap(verbatim_name+tp~.)+
  theme_void()

presence_data_sf_allgrains %>%     
  filter(verbatim_name %in%low_occu_sp_sample) %>% 
  filter(cell_grouping == "cell16grid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[5]], fill = "NA")+
  facet_wrap(verbatim_name+tp~.)+
  theme_void()

presence_data_sf_allgrains %>% 
  filter(verbatim_name %in%low_occu_sp_sample) %>% 
  filter(cell_grouping == "cellfullgrid") %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[6]], fill = "NA")+
  facet_wrap(verbatim_name+tp~.)+
  theme_void()


###
presence_data_sf %>% 
  filter(verbatim_name %in%low_occu_sp_sample) %>% 
  filter(cell_grouping == "cell1grid") %>% filter(tp == 3) %>%
  ggplot()+
  geom_sf()+
  geom_sf(data = grid_list[[1]], fill = "NA")+
  facet_wrap(verbatim_name~., ncol = 3)+
  theme_void()+
  labs(title = "Low occurrence species (tp = 3)")
ggsave(paste0(out_path, "Figs/low_occu_year3.png"))

```

insights from the scale area curves:

```{r}


species_data3 %>% 
  filter(verbatim_name %in% spec) %>% 
  ggplot(aes(y = log(AOO), x = log(scale), col = factor(tp)))+
  geom_point()+
  geom_line()+
  theme_classic()+
  scale_color_viridis(discrete = T)+
  facet_wrap(verbatim_name~.)+
  annotate("text", label = paste(), size = 4, x = 15, y = 5)+
  labs(title = "Low and High occurrence species")

species_data3 %>% 
  filter(verbatim_name %in% low_occu_sp_sample)  %>% 
  ggplot(aes(y = log(AOO), x = log(scale), col = factor(tp)))+
  geom_point()+
  geom_line()+
  theme_classic()+
  facet_wrap(verbatim_name~.)+
  scale_color_viridis(discrete = T)+
  annotate("text", label = paste(), size = 4, x = 15, y = 5)+
  labs(title = "Low occurrence species")

species_data3 %>% 
  filter(verbatim_name %in% unique(high_occu$verbatim_name)[1:9]) %>% 
  ggplot(aes(y = log(AOO), x = log(scale), col = factor(tp)))+
  geom_point()+
  geom_line()+
  theme_classic()+
  scale_color_viridis(discrete = T)+
  facet_wrap(verbatim_name~.)+
  annotate("text", label = paste(), size = 4, x = 15, y = 5)+
  labs(title = "High occurrence species")
  


```

2.1) Summary Table: Occupancy

```{r}
# Some summary stats:
species_data3 %>% 
  group_by(cell_grouping, tp, scale) %>% 
  get_summary_stats(c(relative_occupancy_area, relative_occupancy_Ncells, 
                      occupancy_Ncells, occupancy_area, AOO,
                      Total_area, Total_Ncells), 
                    type="mean_sd")
```

Let's look at two example species that have low occupancy and see if we can translate what's going on from the static patterns. Let's compare with telfer index of change.

Species 1 : Grus grus (AOO between years differs quite a lot, but AOO increases over the years) Species 2 : Falco vespertinus (occurs only in 2 grid cells in tp1 and tp3 and those grid cells differ a lot)

\
***Results:***

-   Grus grus (temporally increasing species) decreases in D (slope) over time in D.

-   Falco vespertinus (temporally decreasing species) increases in D (slope) over time.

```{r}
# Example species: 
# =========================================================================== #
## one that differs quite a lot in AOO between years:
# this one scales nicely between cell_groupings: 1-4 for both time periods. 
# Looks like it is comparable.
# let's see:

s_linear <- c("cell1grid", "cell2grid", "cell4grid", "cell8grid")

species_data3 %>% 
  filter(verbatim_name == "Grus grus") %>% 
  unique() %>%   
  #filter(cell_grouping %in% s_linear) %>% 
  ggplot(aes(x = log(scale), y = log(AOO), color = factor(tp)))+
  geom_point()+
  theme_classic()+
  geom_line()+
  labs(title = "Grus grus")+
  scale_color_viridis(discrete=T)

model_df1<- species_data3 %>% 
  select(verbatim_name, tp, AOO, scale, cell_grouping) %>%
  filter(verbatim_name == "Grus grus") %>% 
  #filter(cell_grouping %in% s_linear) %>%
  filter(tp == 1) %>% 
  unique() 
model_df2<- species_data3 %>% 
  select(verbatim_name, tp, AOO, scale, cell_grouping) %>%
  filter(verbatim_name == "Grus grus") %>% 
  #filter(cell_grouping %in% s_linear) %>%
  filter(tp == 2) %>% 
  unique() 
model_df3<- species_data3 %>% 
  select(verbatim_name, tp, AOO, scale, cell_grouping) %>%
  filter(verbatim_name == "Grus grus") %>% 
  #filter(cell_grouping %in% s_linear) %>%
  filter(tp == 3) %>% 
  unique() 

D_Grusgrus <- c(summary(lm(log(AOO)~log(scale), na.action = na.omit,data = model_df1))$coef[2],
summary(lm(log(AOO)~log(scale), na.action = na.omit,data = model_df2))$coef[2],
summary(lm(log(AOO)~log(scale), na.action = na.omit,data = model_df3))$coef[2])
D_df <- data.frame(D = D_Grusgrus, tp = c(1,2,3)) # 1.2968350; 0.8149176; 0.4023909
plot(D~tp, D_df)

td<- presence_data_sf %>% filter(verbatim_name == "Grus grus")
ggplot()+
  geom_sf(data = td)+  
  geom_sf(data = grid_list[[1]], fill = 'NA') +
  theme_void()+
  facet_wrap(tp~.)+
  labs(title = "Grus grus", subtitle = paste("D =  1.36, D =  1.27, D =  0.71"))

### This looks extremely useful!! Adapt for all species: 
x_df <- telfer_results %>% 
  filter(taxa == "Grus grus") %>% 
  select(Telfer_1_2, Telfer_2_3, Telfer_1_3) %>%
  pivot_longer(cols = c(Telfer_1_2, Telfer_2_3, Telfer_1_3), names_to = "temporal_change", values_to = "Telfer") %>%
  cbind(D_df)

# plot:
x_df %>%
  ggplot(aes(y = Telfer, x = D))+
  geom_point(aes(col = factor(tp)))+
  geom_smooth()+
  theme_classic()+
  scale_color_viridis(discrete=T)


```

```{r}
# =========================================================================== #
telfer_results %>% filter(taxa == "Falco vespertinus") 
# Telfer_1_3 = -0.6534855	


## Another species that has a nice linear relationship until one point
species_data3 %>% 
  filter(verbatim_name == "Falco vespertinus") %>% 
  unique() %>%
  ggplot(aes(x = log(scale), y = log(AOO), color = factor(tp)))+
  geom_point()+
  theme_classic()+
  geom_line()+
  labs(title = "Falco vespertinus")+
  scale_color_viridis(discrete=T)

td<- presence_data_sf %>% 
  filter(verbatim_name == "Falco vespertinus")

ggplot()+
  geom_sf(data = td)+  
  geom_sf(data = grid_list[[1]], fill = 'NA') +
  theme_void()+
  facet_wrap(tp~.)+
  labs(title = "Falco vespertinus")

# this one scales nicely between cell_groupings: 
# 1-4 for both time periods. Looks like it is comparable.
# let's see:

s_linear <- c("cell1grid", "cell2grid", "cell4grid", "cell8grid")

model_df1<- species_data3 %>% 
  select(verbatim_name, tp, AOO, scale, cell_grouping) %>%
  filter(verbatim_name == "Falco vespertinus") %>% 
  filter(cell_grouping %in% s_linear) %>%
  filter(tp == 1) %>% 
  unique() 
model_df3<- species_data3 %>% 
  select(verbatim_name, tp, AOO, scale, cell_grouping) %>%
  filter(verbatim_name == "Falco vespertinus") %>% 
  filter(cell_grouping %in% s_linear) %>%
  filter(tp == 3) %>% 
  unique() 

summary(lm(log(AOO)~log(scale), na.action = na.omit,data = model_df1))$coef # D =  1.76
summary(lm(log(AOO)~log(scale), na.action = na.omit,data = model_df3))$coef # D =  1.87 # a bit more a plane than in first time period.. 

D_Falco <- c(summary(lm(log(AOO)~log(scale), na.action = na.omit,data = model_df1))$coef[2],
summary(lm(log(AOO)~log(scale), na.action = na.omit,data = model_df3))$coef[2])
D_df <- data.frame(D = D_Falco, tp = c(1,3))

plot(D~tp, D_df)

telfer_results %>% filter(taxa == "Falco vespertinus") %>% select(taxa, Nsite_1.y, Nsite_3.x, Telfer_1_3)


# =========================================================================== #
```

```{r}
species_data3 %>%  filter(cell_grouping == "cell1grid") %>%
ggplot() +
  geom_boxplot(aes(y = relative_occupancy_area, fill = factor(tp))) + scale_color_viridis(discrete = T)

                                  
cols_n <- intersect(names(presence_data), names(species_data3))
occ_data_full <- unique(merge(presence_data, species_data3, 
                              by = cols_n, 
                              all.y = T))

# gc()
# save.image("~/GitHub/BEAST_General_Procedures/output/RData/Scale_Area_Curves.RData")

```

#### D \~ Telfer Plot

```{r, fig.width = 3, fig.height = 3, fig.show='hold'}
# D ~ Telfer Plot ==================================== ####
species_data4 <- species_data3
species_data4$D <- c(-species_data4$m)
species_data4 %>% filter(tp == 1) %>%
ggplot() +
  geom_point(aes(x = Telfer_1_2, y = D ))+
  theme_classic()

species_data4 %>% filter(tp == 2) %>%
ggplot() +
  geom_point(aes(x = Telfer_2_3, y = D ))+
  theme_classic()

species_data4 %>% filter(tp == 3) %>%
ggplot() +
  geom_point(aes(x = Telfer_1_3, y = D ))+
  theme_classic()
```

#### D \~ log Ratio of AOO

```{r}
# Re-formating the data.. there is probably a smoother way to do it..
species_data_wide1 <- species_data4 %>% 
  select(verbatim_name, tp, cell_grouping, 
         D, b, AOO, Total_Ncells, 
         occupancy_area, occupancy_Ncells, 
         relative_occupancy_Ncells, relative_occupancy_area) %>% 
  group_by(verbatim_name, tp) %>% 
  distinct() %>% 
  filter(tp == 1) %>% 
  setNames(paste0('tp1_', names(.))) %>% 
  ungroup() %>%
  select(-c(tp1_tp)) %>%
  rename(verbatim_name = tp1_verbatim_name,
         cell_grouping = tp1_cell_grouping)

species_data_wide2 <- species_data4 %>% 
  select(verbatim_name, tp, cell_grouping, 
         D, b, AOO, Total_Ncells, 
         occupancy_area, occupancy_Ncells, 
         relative_occupancy_Ncells, relative_occupancy_area) %>% 
  group_by(verbatim_name, tp) %>% 
  distinct() %>% 
  filter(tp == 2) %>% 
  setNames(paste0('tp2_', names(.))) %>% 
  ungroup() %>%
  select(-c(tp2_tp)) %>%
  rename(verbatim_name = tp2_verbatim_name,
         cell_grouping = tp2_cell_grouping)

species_data_wide3 <- species_data4 %>% 
  select(verbatim_name, tp, cell_grouping, 
         D, b, AOO, Total_Ncells, 
         occupancy_area, occupancy_Ncells, 
         relative_occupancy_Ncells, relative_occupancy_area) %>% 
  group_by(verbatim_name, tp) %>% 
  distinct() %>% 
  filter(tp == 3) %>% 
  setNames(paste0('tp3_', names(.))) %>% 
  ungroup() %>%
  select(-c(tp3_tp)) %>%
  rename(verbatim_name = tp3_verbatim_name,
         cell_grouping = tp3_cell_grouping)

# merge back together:
temp <- merge(species_data_wide1, species_data_wide2, 
              by=intersect(names(species_data_wide1), names(species_data_wide2)))
temp2 <- merge(temp, species_data_wide3,
               by=intersect(names(temp), names(species_data_wide3)))
names_v <- names(temp2[-(1:2)])

# Transform to wide format by cell_grouping
species_data_wide <- temp2 %>% 
  pivot_wider(names_from = cell_grouping,
              values_from = all_of(names_v))

species_data_wide <- species_data_wide %>% 
  mutate(log_R1 = log(tp2_AOO_cell1grid/tp1_AOO_cell1grid),
         log_R2 = tp2_AOO_cell1grid-tp1_AOO_cell1grid, 
         log_R1_3 = log(tp3_AOO_cell1grid/tp1_AOO_cell1grid),
         log_R2_3 = tp3_AOO_cell1grid-tp1_AOO_cell1grid, 
         .before = 1) # sort columns to the beginning of the table


# Plots =================================================================== #
species_data_wide %>% 
  ggplot(aes(y = log_R1, x =-tp1_D_cell1grid))+
  geom_point()+
  ylab(expression("log"~ frac("tp2_AOO_cell1grid", "tp1_AOO_cell1grid")))+
  xlab("tp1_D")+
 geom_smooth(method = "lm", formula = y ~ x, se = T, alpha = 0.5)+
  theme_classic()

species_data_wide %>% 
  ggplot(aes(y = log_R2, x =-tp1_D_cell1grid))+
  geom_point()+
  xlab("tp1_D")+
  ylab("log(tp2_AOO_cell1grid - tp1_AOO_cell1grid)")+
  geom_smooth(method = "lm", formula = y ~ x, se = T, alpha = 0.5)+
  theme_classic()


species_data_wide %>% 
  ggplot(aes(y = log_R1_3, x =-tp1_D_cell1grid))+
  geom_point()+
  ylab(expression("log"~ frac("tp2_AOO_cell1grid", "tp1_AOO_cell1grid")))+
  xlab("tp1_D")+
 geom_smooth(method = "lm", formula = y ~ x, se = T, alpha = 0.5)+
  theme_classic()

species_data_wide %>% 
  ggplot(aes(y = log_R2_3, x =-tp1_D_cell1grid))+
  geom_point()+
  xlab("tp1_D")+
  ylab("log(tp2_AOO_cell1grid - tp1_AOO_cell1grid)")+
  geom_smooth(method = "lm", formula = y ~ x, se = T, alpha = 0.5)+
  theme_classic()
```

### Correlograms

```{r, fig.width = 12, fig.height = 14, fig.show='hold', message = F, warning = F}
# Correlation plots =================================== ##

# library("PerformanceAnalytics")
my_data <- species_data4 %>%
  select(tp, scale,
         occupancy_area, occupancy_Ncells, 
         AOO, relative_occupancy_area, relative_occupancy_Ncells, 
         D, m, b, r2, 
         Telfer_1_2, Telfer_2_3, Telfer_1_3) %>%
  distinct(D, .keep_all = T)

# with GGally ========
library(GGally)

#pdf(paste0(out_path, "Figs/Corrplot_D_Telfer.pdf"), width = "117", height = "165")
my_data$tp <- as.factor(my_data$tp)
my_data_1cell <-my_data %>% filter(scale == 0.031 ) 
ggpairs(my_data_1cell, mapping = aes(color = tp, alpha = 0.25), 
        columns = c("occupancy_area", "occupancy_Ncells",
                    "AOO", "relative_occupancy_area",
                    "m", "b", 
                    "Telfer_1_2", "Telfer_2_3", "Telfer_1_3"))+
  scale_color_viridis(discrete = T)+
  scale_fill_viridis(discrete = T)
#dev.off()


```

```{r}
#par(mfrow=c(4,4))
# p_list[1:16]
# Plots =============================================== ####
# 
species_data %>% 
  filter(verbatim_name %in% high_occu$verbatim_name) %>% 
  ggplot(aes(y=log(AOO), x = log(scale), color = verbatim_name)) +
  geom_point(show.legend = F)+
  geom_line(aes(group = verbatim_name), show.legend = F)+
  facet_wrap(tp~.)+
  theme(legend.position = "none") +
  theme_classic()

# dd %>% filter(cell_grouping == "cell1grid") %>%
# ggplot(aes(x = occupancy_Ncells)) +
#   geom_histogram(bins = 20, bg = "lightgrey", col = "darkgrey")+
#   facet_wrap(tp~.)+
#   theme_classic()

 save.image("~/GitHub/BEAST_General_Procedures/output/RData/Scale_Area_Curves_full.RData")

```
