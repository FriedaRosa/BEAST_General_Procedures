---
title: "0_2_Atlas_Predictors_prep"
author: "Friederike WÃ¶lke"
date: "2024-03-15"
output:
  html_document:
    code_folding: hide
format:
  html:
    toc: true
    number-sections: true
    colorlinks: true
---

# Predictors from the Atlas data

#### Part 1: Predicting future change: can data from the 80s predict the temporal change that took place between the 80s and 00s?

#### Part 2: Predicting past change: can data from the 00s predict the temporal change that took place between the 80s and 00s?

## Libraries

```{r, message = F}
rm(list=ls())
gc()

# Essential data wrangling packages
library(dplyr); # Data wrangling
library(rstatix); # Reorder levels function
library(tidyr);
library(tibble);
library(readxl);

# Plotting: 
library(ggplot2); # Plotting
library(ggthemes); # Map theme
library(cowplot);  # Gridding plots together
library(gridExtra); # Gridding plots together and printing for pdf 

# Phylogenetic stuff:
library(ape);

# Spatial stuff:
library(sf); # Spatial stuff 1
library(terra); # Spatial stuff 2 
library(rnaturalearth)

# SAC:
# library(spdep);
# library(sfdep)
library(ncf)

#load("~/GitHub/BEAST_General_Procedures/Project_Frieda/StaticPredictors/out/RData/AtlasPredictors_1.RDataTmp")

```

## Data paths

```{r}
### The paths ===
source_atlas <- c("c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Processed/Atlases/Replicated/")
source_predictors <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/PhD_Projects/StaticPredictors/Data/")
source_Git <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/Project_Frieda/StaticPredictors/")

# folder path to output folder
out_path <- c(paste0(source_Git, "out/"))



# folder path to atlas data
source_paths <- c(
  paste0(source_atlas, "Birds_Atlas_Czechia/"),
  paste0(source_atlas, "Birds_Atlas_New_York/"),
  paste0(source_atlas, "Birds_atlas_Japan/"),
  paste0(source_atlas, "Birds_atlas_EBBA/")
)

# create path to read in data and grids from variables
data_paths <- c(
  paste0(source_paths[1], "Birds_Atlas_Czechia_beast_data.rds"),
  paste0(source_paths[2], "Birds_Atlas_New_York_beast_data.rds"),
  paste0(source_paths[3], "Birds_atlas_Japan_beast_data.rds"),
  paste0(source_paths[4], "Birds_atlas_EBBA_beast_data.rds")
)

grid_paths <- c(
  paste0(source_paths[1], "Birds_Atlas_Czechia_grid.gpkg"),
  paste0(source_paths[2], "Birds_Atlas_New_York_grid.gpkg"),
  paste0(source_paths[3], "Birds_atlas_Japan_grid.gpkg"),
  paste0(source_paths[4], "Birds_atlas_EBBA_grid.gpkg")
)

atlas_names <- c("Birds_Atlas_Czechia", "Birds_Atlas_New_York", "Birds_atlas_Japan", "Birds_atlas_EBBA")

# Define the desired order of factor levels
desired_levels <- factor(c("1", "2", "4", "8", "16", "32", "64", "128"),
  ordered = T,
  levels = c("1", "2", "4", "8", "16", "32", "64", "128")
)

# grid_paths # list of atlas grids
# data_paths # list of beast occ data

big_tab_path <- paste0(out_path, "csv/Big_table_CZ_JP_NY_EU.csv") # Created in 0_1_Atlas_prep.qmd
tree_path <- paste0(source_predictors, "Weeks_et_at_2022/singe_bird_phylo.tre")
# sac_path <- paste0(out_path, "SAC_data.csv") # Created in this script (code runs a long time ~ 2h, so here is the object)

AVONET_path_raw <- paste0(source_predictors, "AVONET/ELEData/TraitData/AVONET_Raw_Data.csv")
tree_path <- paste0(source_predictors, "Weeks_et_at_2022/singe_bird_phylo.tre")
avonet_birdlife <- paste0(source_predictors, "AVONET/ELEData/TraitData/AVONET1_Birdlife.csv")
avonet_birdtree <- paste0(source_predictors, "AVONET/ELEData/TraitData/AVONET3_BirdTree.xlsx")


```

```{r}

## Read Processed Data from 0_1_Atlas_prep.qmd script =========================================== ##

pres_dat_final <- readRDS(paste0(out_path, "rds/presence_data_final.rds")) # species data per cell
presence_sf_list <- readRDS(paste0(out_path, "rds/presence_sf_list.rds"))
big_tab <- read.csv(file = paste0(out_path, "csv/Big_table_CZ_JP_NY_EU.csv")) %>%
  reorder_levels(cell_grouping, desired_levels)
avonet_raw <- read.csv(AVONET_path_raw)
avonet_bt <- read_excel(avonet_birdtree, sheet = 2)
avonet_bl <- read.csv(avonet_birdlife)
Niches_df <- readRDS(paste0(out_path, "rds/Niches_df.rds"))


```

## Taxonomic Homogenization

skip this

```{r, taxonomic lookup frame, eval = F, include = T}

sp_names_atlas <- unique(pres_dat_final$verbatim_name)
# taxonomy_BirdLife <- read.csv(paste0(source_predictors, "AVONET/ELEData/TraitData/AVONET_Extant_Species_list.csv"))
tree <- ladderize(read.tree(tree_path))
sp_names_BirdTree <- gsub("_", " ", tree$tip.label)

avo_raw <- avonet_raw %>% distinct(Species1_BirdLife, Species2_eBird, eBird.species.group, Species3_BirdTree)
avo_bl <- avonet_bl %>% distinct(Species1, Family1, Order1)
avo_bt <- avonet_bt %>% distinct(Species3, Family3, Order3)

# 9 species in data not in taxonomy (Snyonyms)
## 1. "Delichon urbica"  == "Delichon urbicum"
## 2. "Regulus ignicapillus" == "Regulus ignicapilla"
## 3. "Saxicola torquata" == "Saxicola torquatus"
## 4. "Hydropogne caspia" == "Hydroprogne caspia"
## 5. "Egretta intermedia" == "Ardea intermedia"
## 6. "Luscinia akahige" == "Larvivora akahige"
## 7. "Luscinia komadori" == "Larvivora komadori"
## 8. "Poecile varius" == "Sittiparus varius"
## 9. "Sapheopipo noguchii" == "Dendrocopos noguchii"

## Taxon Lookup frame:
tax_frame <- as.data.frame(sp_names_atlas)
tax_frame2 <- tax_frame %>%
  mutate(
    sp_names_atlas_adapted = case_when(
      sp_names_atlas == "Delichon urbica" ~ "Delichon urbicum",
      sp_names_atlas == "Regulus ignicapillus" ~ "Regulus ignicapilla",
      sp_names_atlas == "Saxicola torquata" ~ "Saxicola torquatus",
      sp_names_atlas == "Hydropogne caspia" ~ "Hydroprogne caspia",
      sp_names_atlas == "Egretta intermedia" ~ "Ardea intermedia",
      sp_names_atlas == "Luscinia akahige" ~ "Larvivora akahige",
      sp_names_atlas == "Luscinia komadori" ~ "Larvivora komadori",
      sp_names_atlas == "Poecile varius" ~ "Sittiparus varius",
      sp_names_atlas == "Sapheopipo noguchii" ~ "Dendrocopos noguchii",
      .default = sp_names_atlas
    )
  ) %>%
  rename("verbatim_name" = "sp_names_atlas")

not_inBL <- setdiff(tax_frame2$sp_names_atlas_adapted, avo_raw$Species1_BirdLife)
not_inBL_and_BT <- setdiff(not_inBL, avo_raw$Species3_BirdTree) 

tax_frame2$sp_names_atlas_adapted_keep <- tax_frame2$sp_names_atlas_adapted

tax_frame3 <- merge(tax_frame2, avo_raw, by.x=c("sp_names_atlas_adapted"), by.y=c("Species1_BirdLife"), all.x = T)
tax_frame4 <- merge(tax_frame3, avo_raw, by.x=c("sp_names_atlas_adapted"), by.y=c("Species3_BirdTree"), all.x = T)
tax_frame5 <- tax_frame4 %>% mutate(
  Species2_eBird = coalesce(Species2_eBird.x, Species2_eBird.y),
  eBird.species.group = coalesce(eBird.species.group.x, eBird.species.group.y)
) %>% select(-eBird.species.group.x, -eBird.species.group.y, -Species2_eBird.x, -Species2_eBird.y) %>%
  rename("sp_BirdTree" = "Species3_BirdTree", 
         "sp_eBird" = "Species2_eBird", 
         "sp_group_eBird" = "eBird.species.group",
         "sp_BirdLife" = "Species1_BirdLife",
         "sp_atlas_adapted" = "sp_names_atlas_adapted") %>% distinct(.) #select(sp_atlas, Genus.name, Family.name, Order.name) %>% unique()

write.csv(tax_frame5, paste0(out_path, "csv/Tax_lookup_BirdLife_eBird_BirdTree_Atlas.csv"))

rm(sp_names_atlas, avo_bl, tree, avo_raw, avo_bt, tax_frame, tax_frame2, tax_frame3, tax_frame4)


```

## The Data

```{r, read and process data, message = F}
## We need the highest resolution data = cell_grouping = 1

# phylogenetic tree --------------------------------------------------------------------------- #
tree <- ladderize(read.tree(tree_path))

# grid data
grids <- list()
for (a in seq_along(grid_paths)) {
    grids_a <-sapply("cell1grid", function(i) {
      st_read(grid_paths[[a]], paste(i), quiet = TRUE)  %>% 
        st_transform(crs = 4326) %>% 
        reorder_levels( cell_grouping, order=desired_levels)
      }, simplify = FALSE)
    grids[[a]] <- grids_a$cell1grid
}

# Raw species occurrence data
# Species data  =====================
presence_data_all <- list()
for (i in seq_along(data_paths)) {
  pres_dat <- readRDS(data_paths[i])
  sy <- sort(unique(pres_dat$start_year)) # sy = start_year

  ## Add time-period column
  pres_dat2 <- pres_dat %>% 
    mutate(tp = case_when(start_year == sy[1] ~ 1,
                          start_year == sy[2] ~ 2)) %>% 
    filter(tp %in% c(1,2)) %>%
    reorder_levels(cell_grouping, order=desired_levels)

  ## Cells sampled twice (column: repeated)
  common_cells <- pres_dat2 %>%
    ungroup() %>%
    group_by(dataset, cell_grouping, cell_label) %>%
    mutate(num_periods_cells = n_distinct(tp)) %>%
    mutate(repeated = case_when(
      num_periods_cells == 2 ~ 1,
      num_periods_cells %in% c(1, 2) ~ 0
    )) %>%
    ungroup() %>%
    group_by(dataset) %>%
    select(dataset, cell_grouping, cell_label, num_periods_cells, repeated) %>%
    unique()

  common_cells %>%
    group_by(dataset, cell_grouping, repeated, num_periods_cells) %>%
    summarise(n = n())

  presence_data_rep <- full_join(pres_dat2, common_cells)

  # Species sampled twice in the remaining cells
  common_sp <- presence_data_rep %>%
    filter(repeated == 1 & cell_grouping == 1) %>%
    group_by(dataset, verbatim_name) %>%
    summarise(num_periods_sp = n_distinct(tp)) %>%
    ungroup() 
  presence_data3 <- full_join(presence_data_rep, common_sp) 

  presence_data_all[[i]] <- presence_data3
}

```

# Predictors

```{r, atlas predictors}
# Extent
# Shape
# Center of Gravity (of all species together) (COG)
# Total Species Richness (Gamma)
# Grain
# Start & End Years
# Sampling period length (End years - Start years)
# Fractal dimension of the landscape !! That would be cool !!


atlas_predictors_df2 <- big_tab %>% 
  select(dataset, Total_area, tp, grain) %>% 
  distinct()



```

```{r, species predictors}

# Log Ratio
# Start & End Years
# Telfer
# AOO
# Relative Occupancy
# Slope of OAR
# D
# Co-Occurrence
# Autocorrelation of the distribution (thanks Carmen!)
# Mean Diversity Measures per species: mean(cell_richness), Total atlas SR / mean(cell_richness)
# Geometric attributes of the distribution (thanks Gabriel!)
# HWI
# Phylogenetic Distinctness
# Family, Order, Genus
# Climatic Niche
# Mean Land use type
# Life Strategy
# Insectivorous ? 
# Threat status: National, Global ?
# Global Range Size
# Migration Status
# Human Association ? 
# NDVI ? 
# Occurrence outside of the arena ?
# Topology/Elevation ?

# tax_frame3
species_data_bigtable <- big_tab %>% 
  filter(cell_grouping == 1) %>% 
  select(-cell_grouping, -X, -scale) %>% 
  left_join(tax_lookup %>% distinct(verbatim_name, sp_atlas_adapted,sp_BirdTree, sp_BirdLife))




# ##### Climate Niche Taxonomic Match: ####
setdiff(Niches_df$verbatim_name, species_data_bigtable$sp_BirdLife) %>% length() # 0
setdiff(species_data_bigtable$sp_BirdLife,Niches_df$verbatim_name) %>% length() # 22

species_data_bigtable2 <- species_data_bigtable %>% filter_at(vars(log_R2_1), any_vars(!is.na(.)))
sp_df_big <- species_data_bigtable2

Niches_df <- Niches_df %>% rename("sp_BirdLife" = "verbatim_name")

sp_df_big <- full_join(species_data_bigtable, Niches_df) %>% select(-sp_atlas_adapted) %>% unique()

########################################



# Make dataframe with predictors ======================
names(species_data_bigtable2)

predictors_df <- sp_df_big%>% 
  select(
    verbatim_name, dataset, tp, sp_BirdTree,sp_BirdLife, # Grouping variables
    log_R2_1, Telfer_1_2, # Response variables
    Total_area,
    Total_Ncells_samp, # Extent of the Arena
    relative_occupancy_Ncells, # Relative Occupancy
    D_AOO_a, # D of AOO based on mean area
    total_SR_atlas, #GammaRichness of Atlas
    sd_PC1, sd_PC2) 

sp_names_predictors <- predictors_df %>% distinct(verbatim_name) %>% as.vector()
write.csv(sp_names_predictors, paste0(out_path, "csv/sp_names_predictors.csv"))




save.image(paste0(out_path, "RData/AtlasPredictors_1.RData"))


```

================ RUN COMPLETELY UNTIL HERE AND THEN ONLY RUN CHUNKS WHERE OBJECTS ARE READ BACK IN ======================

## Diversity Metrics

```{r, eval = F}
## Calculate Diversity Measures ======================
GammaAlphaBeta_Atlas <- pres_dat_final %>%
  filter(cell_grouping == 1) %>%
  select(dataset, tp, cell_label, verbatim_name) %>% distinct() %>%
  group_by(dataset,tp) %>%
  mutate(GammaSR = sum(n_distinct(verbatim_name))) %>% ungroup() %>%
  group_by(dataset, tp, cell_label) %>%
  mutate(AlphaSR = sum(n_distinct(verbatim_name))) %>%
  mutate(BetaSR = GammaSR/AlphaSR)

GammaAlphaBeta_Species <- GammaAlphaBeta_Atlas %>%   
  ungroup() %>%
  group_by(dataset, tp, verbatim_name) %>%
  mutate(AlphaSR_sp = mean(AlphaSR)) %>%
  mutate(BetaSR_sp = GammaSR/AlphaSR_sp) %>%
  select(dataset, tp, verbatim_name, AlphaSR_sp, BetaSR_sp, GammaSR) %>% distinct()

## Calculate Mean Sampling Effort  ======================
AvgEffort <- pres_dat_final %>%
  filter(cell_grouping == 1) %>%
  select(dataset, tp, cell_label, verbatim_name, samp_effort_type, effort) %>% 
  distinct() %>%
  group_by(dataset, tp, verbatim_name) %>%
  summarize(avgEffort = mean(effort))


Diversity_Effort <- full_join(GammaAlphaBeta_Species, AvgEffort)
saveRDS(Diversity_Effort, paste0(out_path, "rds/Diversity_AvgEffort.rds"))
```

#### Diversity_Effort: Read back in

```{r}
Diversity_Effort <- readRDS(paste0(out_path, "rds/Diversity_AvgEffort.rds"))
predictors_df2 <- full_join(predictors_df, Diversity_Effort); rm(Diversity_Effort)

```

## Spatial Autocorrelation

```{r, eval = F}
## autocorrelation loop

sf_use_s2(FALSE)
out_list <- list()
time_periods <- c(1,2)
atlas_names <- c("Birds_Atlas_Czechia", "Birds_Atlas_New_York","Birds_atlas_Japan", "Birds_atlas_EBBA")

presence_sf_list <- list()
for (a in seq_along(atlas_names)){
  grid <- grids[[a]]
  presence_data <- presence_data_all[[a]]


  presence_sf <- left_join(grid, presence_data)
  dd <- presence_sf %>% filter(dataset == atlas_names[a])
  presence_sf_list[[a]] <- dd}

saveRDS(presence_sf_list, paste0(out_path, "rds/presence_sf_list.rds"))

```

### NCF package (my try - Takes \> 1 day)

```{r, ncf package SAC, message = F}
pacman::p_load("ncf")

sf_use_s2(FALSE)

time_periods <- c(1,2)
atlas_names <- c("Birds_Atlas_Czechia", "Birds_Atlas_New_York","Birds_atlas_Japan", "Birds_atlas_EBBA")

morans_list <- list()
out_list <- list()

for (a in seq_along(atlas_names)){
  dd <- presence_sf_list[[a]] %>% 
    mutate(increment = 
      case_when(
        dataset == atlas_names[1] ~ 15,
        dataset == atlas_names[2] ~ 7.5,
        dataset == atlas_names[3] ~ 30, 
        dataset == atlas_names[4] ~ 75))

  
  for (y in seq_along(time_periods)){
    
    dd1 <- dd %>% filter(tp == time_periods[y])
    
    ## From Carmen ===============================
    
    sp_list <- unique(dd1$verbatim_name)
  
    # Output columns
    columns_df <- c("tp", "dataset", "mean_area", "mean_area_cropped", "increment", "mean_cellside")
    spmor_cols <- c("verbatim_name", "global_moran", "x_intercept", columns_df)
    spmoran_df <- data.frame(matrix(nrow = length(sp_list), ncol = length(spmor_cols)))
    colnames(spmoran_df) <- spmor_cols

    row_id <- 1
    for (s in seq_along(sp_list)) {
      dd_sp <- dd1 %>% select(verbatim_name, cell_lat, cell_long, cell_label, area, area_cropped, increment) %>% st_drop_geometry()
    
      print(paste("atlas =", atlas_names[a], "tp =", time_periods[y], "sp = ", sp_list[s], "N = ", s, "/", length(sp_list)))
      
      # Obtain a df for each species that indicates the presence (1) or absence (0) of the species
      data_species <- dd_sp %>%
        mutate(verbatim_name = ifelse(verbatim_name != sp_list[s], NA, verbatim_name)) %>%
        group_by(across(-verbatim_name)) %>%
        slice(which.max(!is.na(verbatim_name))) %>%
        mutate(presence = ifelse(!is.na(verbatim_name), 1, 0))
      
      # Filling in the data
      spmoran_df$verbatim_name[row_id] <- sp_list[s]
      spmoran_df$dataset[row_id] <- atlas_names[a]
      spmoran_df$tp[row_id] <- time_periods[y]
      spmoran_df$mean_area[row_id] <- mean(data_species$area, na.rm = TRUE)
      spmoran_df$mean_area_cropped[row_id] <- mean(data_species$area_cropped, na.rm = TRUE)
      spmoran_df$increment[row_id] <- unique(data_species$increment)
      spmoran_df$mean_cellside[row_id] <- sqrt(spmoran_df$mean_area[row_id])
      spmoran_df$increment2[row_id] <- spmoran_df$mean_cellside[row_id] + (spmoran_df$mean_cellside[row_id] / 2)

      
      tryCatch({
    
        morans_cor <- correlog(x = data_species$cell_long, y = data_species$cell_lat, z = data_species$presence, 
                               latlon=T, increment = spmoran_df$increment2[row_id], resamp=0)
        # plot(morans_cor)
        morans_list[[length(morans_list) + 1]] <- morans_cor 
        
        
        spmoran_df[row_id, "global_moran"] <- as.numeric(morans_cor$correlation[1])
        spmoran_df[row_id, "x_intercept"] <- morans_cor$x.intercept
        
      }, error = function(e) {
        # Handle the case where Moran's I cannot be calculated
        spmoran_df[row_id, c("global_moran", "x_intercept")] <- NA
      })
      
    }
     out_list[[length(out_list) + 1]] <- spmoran_df
  }
}

SAC_df_ncf <- plyr::rbind.fill(out_list, fill = T) %>% unique()
write.csv(SAC_df_ncf, paste0(out_path, "SAC_data_ncf.csv"))
saveRDS(SAC_df_ncf, paste0(out_path, "SAC_data_ncf.rds"))





```

### Carmens code:

This takes quite some time (\~ 2.5h). Read the SAC_df back in instead of re-running the code.

```{r, eval = F}


for (a in seq_along(atlas_names)){
  dd <- presence_sf_list[[a]]
  
  for (y in seq_along(time_periods)){
    
    dd1 <- dd %>% filter(tp == time_periods[y])
    
    ## From Carmen ===============================
    
    sp_list <- unique(dd1$verbatim_name)

    # Output columns
    columns_df <- c("tp", "dataset", "mean_area", "mean_area_cropped")
    spmor_cols <- c("verbatim_name", "global_moran", "p_value", columns_df)
    spmoran_df <- data.frame(matrix(nrow = length(sp_list), ncol = length(spmor_cols)))
    colnames(spmoran_df) <- spmor_cols

    row_id <- 1
    
    for (s in seq_along(sp_list)) {
      
      print(paste("atlas =", atlas_names[a], "tp =", time_periods[y], "sp = ", sp_list[s]))
      # Obtain a df for each species that indicates the presence (1) or absence (0) of the species
      data_species <- dd1 %>%
        mutate(verbatim_name = ifelse(verbatim_name != sp_list[s], NA, verbatim_name)) %>%
        group_by(across(-verbatim_name)) %>%
        slice(which.max(!is.na(verbatim_name))) %>%
        mutate(presence = ifelse(!is.na(verbatim_name), 1, 0))
      
      # Filling in the data
      spmoran_df$verbatim_name[row_id] <- sp_list[s]
      spmoran_df$dataset[row_id] <- atlas_names[a]
      spmoran_df$tp[row_id] <- unique(data_species$tp)
      spmoran_df$mean_area[row_id] <- mean(data_species$area, na.rm = TRUE)
      spmoran_df$mean_area_cropped[row_id] <- mean(data_species$area_cropped, na.rm = TRUE)

      tryCatch({
      # Creating neighbors
      nb <- poly2nb(data_species, queen = TRUE)
      # Spatial weights for the neighbors
      listw <- nb2listw(nb, style = "W", zero.policy = TRUE)
      # Moran's I
      moran_res <- moran.test(data_species$presence, listw, zero.policy = TRUE)
      spmoran_df[row_id, "global_moran"] <- as.numeric(moran_res$estimate)[1]
      spmoran_df[row_id, "p_value"] <- moran_res$p.value
      }, error = function(e) {
        # Handle the case where Moran's I cannot be calculated
        spmoran_df[row_id, c("global_moran", "p_value")] <- NA
      })

      row_id <- row_id + 1  # Update row_id for the next entry
    
      }
    
    out_list[[length(out_list) + 1]] <- spmoran_df
  
  }
  
}
saveRDS(presence_sf_list, paste0(out_path, "presence_sf_list.rds"))
SAC_df <- plyr::rbind.fill(out_list, fill = T) %>% unique()
write.csv(SAC_df, paste0(out_path, "SAC_data.csv"))
saveRDS(SAC_df, paste0(out_path, "SAC_data.rds"))

```

#### SAC_df: Read back in

```{r}
SAC_df <- readRDS(paste0(out_path, "SAC_data.rds"))

predictors_df4 <- full_join(predictors_df2, SAC_df); rm(predictors_df2)
predictors_df4

```

## Characterize Geometries

(Function by Dr. Gabriel Ortega: requires terra & tidyverse)

```{r, geometries function from Gabriel}
pacman::p_load(geosphere, geodata, terra, tidyverse, tidyterra)

# Function to get the max elongation per polygon, north-south length or east-west length, circularity, etc...
poly_attr <- function(x, type = NULL) {
  # Convert "sf" to SpatVector
  if (inherits(x, "sf") == T) {
    x <- vect(x)
  }
  # Reproject to WGS84. Currently, "terra" calculate distance in meters when given latitude and longitude points.
  x <- project(x, "epsg:4326")
  # Get East-West distance (longitudinal extension)
  if (type == "ewDist") {
    vert <- crds(as.points(ext(x)), df = T)
    dimNames <- list(c("point"),c("x","y"))
    sw <- matrix(c(min(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    se <- matrix(c(max(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    res <- distance(sw, se, lonlat = T)[[1]]
  }
  # Get South-North distance (latitudinal extension)
  if (type == "nsDist") {
    vert <- crds(as.points(ext(x)), df = T)
    dimNames <- list(c("point"),c("x","y"))
    sw <- matrix(c(min(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    nw <- matrix(c(min(vert[["x"]]), max(vert[["y"]])), ncol = 2, dimnames = dimNames)
    res <- distance(sw, nw, lonlat = T)[[1]]
  }
  # Get max distance between opposite vertices
  if (type == "maxDist") {
    vert <- crds(as.points(convHull(x)))
    res <- distance(vert, lonlat = T) %>% max()
  }
  # Get elongation ratio along longest axis
  if (type == "elonRatio") {
    convexHull <- convHull(x)
    vert <- crds(as.points(convexHull), df = T)
    dist <- as.data.frame.table(as.matrix(distance(vert, lonlat = T)), responseName = "distance") %>%
      slice_max(., distance)
    axisPoints <- vert[c(dist[[1]][[1]],dist[[2]][[1]]),]
    axisPoints <- arrange(axisPoints, desc(y))
    rotation <- -1*bearing(axisPoints[2,],axisPoints[1,])
    rotHull <- spin(convexHull, rotation)
    ext <- ext(convexHull)
    df <- as.vector(distance(crds(as.points(ext)), lonlat = T))
    df <- sort(df)
    length <- mean(df[[3]], df[[4]])
    width <- mean(df[[1]], df[[2]])
    res <- 1 - (width / length)
    # res <- list()
    # res[["vert"]] <- vert
    # res[["dist"]] <- dist
    # res[["axispoints"]] <- axisPoints
    # res[["bearing"]] <- rotation
    # res[["rotHull"]] <- rotHull
  }
  # Circularity
  if (type == "circ") {
    perimeter <- perim(x)
    area <- expanse(x)
    res <- (perimeter^2) / area
  }
  # Normalized circularity
  if (type == "circNorm") {
    perimeter <- perim(x)
    area <- expanse(x)
    res <- (perimeter^2) / (4 * pi * area)
  }
  # Major length of the minimum rectangle
  if (type == "lengthMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle), df = T), lonlat = T))
    df <- sort(df)
    res <- mean(df[[3]], df[[4]])
  }
  # Width of the minimum rectangle
  if (type == "widthMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle), df = T), lonlat = T))
    df <- sort(df)
    res <- mean(df[[1]], df[[2]])
  }
  # Elongation ratio of minimal encasing rectangle (from here: DraÅ¾iÄ, S., RaleviÄ, N., & Å½uniÄ, J. (2010). Shape elongation from optimal encasing rectangles. Computers & Mathematics with Applications, 60(7), 2035â2042. https://doi.org/10.1016/j.camwa.2010.07.043)
  if (type == "elonMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle)), lonlat = T))
    df <- sort(df)
    length <- mean(df[[3]], df[[4]])
    width <- mean(df[[1]], df[[2]])
    res <- 1 - (width / length)
  }
  # Related circumscribing circle
  if (type == "relCirc") {
    circle <- minCircle(x)
    areaCircle <- expanse(circle)
    area <- expanse(x)
    res <- 1-(area/areaCircle)
  }
  # Linearity index
  if (type == "lin") {
    hull <- convHull(x)
    df <- crds(as.points(hull), df = T)
    lm <- lm(y ~ x, data = df)
    res <- summary(lm)$r.squared
  }
  # North bearing of the minimum rectangle
  if (type == "bearingMinRect") {
    minRectangle <- minRect(x)
    df <- crds(as.points(minRectangle), df = T)
    cor <- cor(df[["x"]],df[["y"]])
    point1 <- slice_min(df, y)
    if (cor > 0){
      point2 <-slice_max(df, x)
    } else{
      point2 <-slice_min(df, x)
    }
    res <- bearing(point1, point2)
  }
    # Get bearing along longest axis
  if (type == "bearing") {
    convexHull <- convHull(x)
    vert <- crds(as.points(convexHull), df = T)
    dist <- as.data.frame.table(as.matrix(distance(vert, lonlat = T)), responseName = "distance") %>%
      slice_max(., distance)
    axisPoints <- vert[c(dist[[1]][[1]],dist[[2]][[1]]),]
    axisPoints <- arrange(axisPoints, desc(y))
    res <- bearing(axisPoints[2,],axisPoints[1,])
  }
  res <- as.numeric(res)
  return(res)
}
```

# *Read Workspace*

```{r}
save.image(paste0(out_path, "Atlas_predictors.RData"))


```

### Calculate Geometries:

This takes quite some time (\~3-4h). Better read the objects back in below.

```         
10311.01 sec elapsed
```

```{r, calculate geometries, message = F}
tictoc::tic()


# Atlas Geometries ==============================================================
geom_ls <- list()
for (i in seq_along(grids)){
  
  Atlas_Geom <- grids[[i]] %>% 
    select(geom, cell_label) %>%
    summarise() %>% 
    terra::vect()
  
  Geom_attributes_atlas <- data_frame(dataset = atlas_names[i],
           atlas_nsDist = poly_attr(Atlas_Geom, "nsDist"),
           atlas_ewDist = poly_attr(Atlas_Geom, "ewDist"),
           atlas_maxDist = poly_attr(Atlas_Geom, "maxDist"),
           atlas_lengthMinRect = poly_attr(Atlas_Geom, "lengthMinRect"),
           atlas_widthMinRect = poly_attr(Atlas_Geom, "widthMinRect"),
           atlas_elonMinRect = poly_attr(Atlas_Geom, "elonMinRect"),
           atlas_elonRatio = poly_attr(Atlas_Geom, "elonRatio"),
           atlas_circ = poly_attr(Atlas_Geom, "circ"),
           atlas_circNorm = poly_attr(Atlas_Geom, "circNorm"),
           atlas_relCirc = poly_attr(Atlas_Geom, "relCirc"),
           atlas_lin = poly_attr(Atlas_Geom, "lin"),
           atlas_bearingMinRect = poly_attr(Atlas_Geom, "bearingMinRect"), 
           atlas_bearing = poly_attr(Atlas_Geom, "bearing"))
           
  ## Southernness/Westernness
  atlas_xmin <- st_bbox(Atlas_Geom)[1]
  atlas_ymin <- st_bbox(Atlas_Geom)[2]
  atlas_xmax <- st_bbox(Atlas_Geom)[3]
  atlas_ymax <- st_bbox(Atlas_Geom)[4]
  atlas_xhalf <- atlas_xmax+(atlas_xmin-atlas_xmax)/2
  atlas_yhalf <- atlas_ymax+(atlas_ymin-atlas_ymax)/2
  
  atlas_bbox <- data.frame(atlas_xmin, atlas_xmax, atlas_xhalf, atlas_ymin, atlas_ymax, atlas_yhalf)
  atlas_bbox$dataset <- atlas_names[i] 
  
  geom_ls[[i]] <- full_join(atlas_bbox, Geom_attributes_atlas)
  
}

countries_geom_attributes <- plyr::rbind.fill(geom_ls) 


# Transform country-borders to lines
lines_l <- list()
for (a in seq_along(grids)){
  lines <- grids[[a]] %>% 
    summarise() %>% 
    vect() %>% 
    as.lines()
  lines_l[[a]] <- lines
}

### For each species separately:
tictoc::tic()
species_geom <- list()
year_species_geom <- list()
atlas_all_sp_geom <-list()
COG_all <- list()
COG_a <- list()
for (a in seq_along(presence_sf_list)){
  atlas <- presence_sf_list[[a]]
  
  
  for (y in seq_along(time_periods)){
    atlas_y <- atlas %>% filter(tp == time_periods[y])
    sp <- unique(atlas_y$verbatim_name)
    
    # Calculate Center of Gravity of all species per atlas
    COG <- atlas_y %>% st_drop_geometry() %>% summarise(CenterOfGravity_Atlas_long = mean(cell_long),
                                 CenterOfGravity_Atlas_lat = mean(cell_lat),
                                 dataset = unique(dataset))
    COG_all[[y]] <- COG

    points_COG_atlas <- COG %>% 
      dplyr::select(CenterOfGravity_Atlas_long, CenterOfGravity_Atlas_lat, dataset) %>%
      rename("x" = "CenterOfGravity_Atlas_long", "y" = "CenterOfGravity_Atlas_lat") %>% 
      na.omit() %>% 
      distinct()
    
    points_atlas <- points_COG_atlas %>% vect(geom = c("x", "y"), crs = "epsg:4326")
    
    for (s in seq_along(sp)){
      print(paste(atlas_names[a], time_periods[y], sp[s]))
      atlas_sp <- atlas_y %>% filter(verbatim_name == sp[s])
      
 
      ## Maybe I have to summarize here ! Not sure - let's try this and compare.
      COG_sp <- atlas_sp %>% 
        select(cell_long, cell_lat, verbatim_name, dataset, tp) %>%
        mutate(sp_COG_long = mean(cell_long), 
               sp_COG_lat = mean(cell_lat)) %>% 
        st_drop_geometry() %>% 
        select(-cell_long, -cell_lat) %>% 
        unique()
      
      points_COG_sp <- COG_sp %>%
        group_by(dataset, tp, verbatim_name) %>% 
        dplyr::select(sp_COG_long, sp_COG_lat, dataset, tp, verbatim_name) %>%
        rename("x" = "sp_COG_long", "y" = "sp_COG_lat") %>% na.omit() %>% ungroup()

      points2 <- points_COG_sp %>%
        vect(geom = c("x", "y"), crs = "epsg:4326")
            
      test <- atlas_sp %>% 
        select(geom, cell_label)%>% 
        summarise() %>% 
        vect() 
      

    
      ## Calculate distance 
      atlas_lines <- lines_l[[a]]
      Dist_toCOG <- terra::distance(crds(points2), crds(points_atlas), lonlat = T)
      minDist_toBorder_centr <- min(distance(crds(points2), crds(atlas_lines), lonlat=T))
      maxDist_toBorder_centr <- max(distance(crds(points2), crds(atlas_lines), lonlat=T))
      minDist_toBorder <- min(distance(crds(test), crds(atlas_lines), lonlat=T))
      maxDist_toBorder <- max(distance(crds(test), crds(atlas_lines), lonlat=T))
    
      Geom_attributes <- data_frame(dataset = atlas_names[a],
                                    tp = time_periods[y],
                                    verbatim_name = sp[s],
                                    nsDist = poly_attr(test, "nsDist"),
                                    ewDist = poly_attr(test, "ewDist"),
                                    maxDist = poly_attr(test, "maxDist"),
                                    lengthMinRect = poly_attr(test, "lengthMinRect"),
                                    widthMinRect = poly_attr(test, "widthMinRect"),
                                    elonMinRect = poly_attr(test, "elonMinRect"),
                                    elonRatio = poly_attr(test, "elonRatio"),
                                    circ = poly_attr(test, "circ"),
                                    circNorm = poly_attr(test, "circNorm"),
                                    relCirc = poly_attr(test, "relCirc"),
                                    lin = poly_attr(test, "lin"),
                                    bearingMinRect = poly_attr(test, "bearingMinRect"), 
                                    bearing = poly_attr(test, "bearing"),
                                    Dist_toCOD = Dist_toCOG,
                                    minDist_toBorder = minDist_toBorder,
                                    maxDist_toBorder = maxDist_toBorder,
                                    minDist_toBorder_centr = minDist_toBorder_centr,
                                    maxDist_toBorder_centr = maxDist_toBorder_centr)
        
        Geom_attributes2 <- full_join(Geom_attributes, COG_sp) %>% unique()
        
        species_geom[[s]] <- Geom_attributes2
        }
    
    species_geom_df <- plyr::rbind.fill(species_geom)  
    year_species_geom[[y]] <- species_geom_df  
    }
  COG_a[[a]] <- plyr::rbind.fill(COG_all)
  year_species_geom_df <- plyr::rbind.fill(year_species_geom) 
  atlas_all_sp_geom[[a]] <- year_species_geom_df
  }
tictoc::toc()

COG_df <- plyr::rbind.fill(COG_a)
Species_geom_attributes <- plyr::rbind.fill(atlas_all_sp_geom) 

Atlas_geom <- full_join(countries_geom_attributes, COG_df) %>% group_by(dataset) %>% distinct(dataset, .keep_all=T)
Geometries <- full_join(Species_geom_attributes, Atlas_geom, relationship = "many-to-many") %>% distinct()



# Southerness/Westerness =================================
Southernness_Westernness <- Geometries %>% 
  group_by(dataset, tp, verbatim_name) %>% 
  select(dataset, tp, verbatim_name, sp_COG_long, sp_COG_lat, atlas_xmin, atlas_xmax, atlas_xhalf, atlas_ymin, atlas_ymax, atlas_yhalf) %>% 
  unique() %>%
  summarize(Southernness = 1-((sp_COG_lat - atlas_ymin)/((atlas_ymax -atlas_ymin))),
            Westernness = 1-((sp_COG_long - atlas_xmin)/((atlas_xmax-atlas_xmin)))) %>% ungroup() 

Geometries_final <- left_join(Geometries, Southernness_Westernness, relationship = "many-to-many") %>% distinct(dataset, tp, verbatim_name, .keep_all = T)

saveRDS(Geometries_final, paste0(out_path, "Geometries.rds"))


```

### PCA on Geometries

```{r}

## Summary Stats ========================================

Geometries %>% group_by(dataset, tp) %>% 
  rstatix::get_summary_stats(type="common")

Geometries %>% mutate_at(c('dataset', 'tp', 'verbatim_name'), as.factor)%>% group_by(dataset, tp) %>% 
  rstatix::get_summary_stats(type="common")


##
str(Atlas_geom)
str(sp_pca_points)
atlas_pca_points <- Atlas_geom %>% ungroup() %>% select(-dataset) %>% as.data.frame()
sp_pca_points <- Species_geom_attributes %>% ungroup() %>% select(-dataset, -verbatim_name, -tp)
pca <- prcomp(atlas_pca_points,  scale.=T)
pca2 <- prcomp(sp_pca_points, scale.=T)

autoplot(prcomp(Atlas_geom %>% ungroup() %>% select(-dataset) %>% as.data.frame()))
autoplot(prcomp(Geometries %>% select(-verbatim_name, -tp, -dataset),  scale.=T, center=T))
autoplot(pca2)
autoplot(pca, loadings = TRUE, loadings.label = TRUE)

autoplot(pca2, loadings = TRUE, loadings.label = TRUE,
         data = Species_geom_attributes, colour = 'dataset')



#####

pca_points <- 
  # first convert the pca results to a tibble
  as_tibble(pca2$x) %>% 
  # now we'll add the penguins data
  bind_cols(Species_geom_attributes)

basic_plot <- 
  ggplot(pca_points, aes(x = PC1, y = PC2)) +
  geom_point(aes(colour = dataset)) +
  theme_light()

# first create a dataframe to extract the convex hull points
pca_hull <- 
  pca_points %>% 
  group_by(dataset) %>% 
  slice(chull(PC1, PC2))

# now, we'll just continue to build on our ggplot object
chull_plot <- 
  basic_plot +
  geom_polygon(data = pca_hull,
               aes(fill = dataset,
                   colour = dataset),
               alpha = 0.3,
               show.legend = FALSE)

chull_plot



```

#### Geometries: Read back in

```{r}
Geometries <- readRDS( paste0(out_path, "Geometries.rds"))

predictors_df5 <- full_join(Geometries_final, predictors_df4) 
predictors_df5 %>% filter_all(any_vars(is.na(.)))
```

## Co-Occurrence

```{r, eval = F}

species_data <- pres_dat_final %>% filter(cell_grouping == 1) %>% select(dataset, tp, verbatim_name, cell_label) %>% distinct()

# ----------------------------------------------------------- #
co_occ_list1<- list()
for (a in seq_along(atlas_names)){
  
  # create community dataframe
  species_data_a <- species_data %>% filter(dataset == atlas_names[a])
  comm_dat <- species_data_a %>% 
    group_by(tp) %>% 
    dplyr::select(tp, verbatim_name, cell_label) %>%
    ungroup() %>% 
    distinct()
  comm_dat <- as.data.frame(comm_dat)
  
  # Convert data frame to Species X sites matrix
  comm_matrix_tp1 <- fossil::create.matrix(comm_dat, 
                                           tax.name = "verbatim_name", 
                                           locality = "cell_label", 
                                           time.col = "tp", 
                                           time = "1", 
                                           abund = F)
  comm_matrix_tp2 <- fossil::create.matrix(comm_dat, 
                                           tax.name = "verbatim_name", 
                                           locality = "cell_label", 
                                           time.col = "tp", 
                                           time = "2", 
                                           abund = F)
  
  # Calculate probability of pairwise co-occurrence of species: ----------- #
  co_occurrence_tp1 <- cooccur::cooccur(comm_matrix_tp1, spp_names = T)
  print(length(unique(co_occurrence_tp1$spp.names))) # 206 species 
  co_occurrence_tp2 <- cooccur::cooccur(comm_matrix_tp2, spp_names = T)
  print(length(unique(co_occurrence_tp2$spp.names))) # 213 species
  
  co_occ_list1[[a]] <- list(co_occurrence_tp1, co_occurrence_tp2)
  
  
}

co_occ_list2 <-list()
for (a in seq_along(atlas_names)){
  species_data_a <- species_data %>% filter(dataset == atlas_names[a])
  species_data_a1 <- species_data_a %>% select(-cell_label) %>% distinct()

  res1 <- data.frame(co_occ_list1[[a]][[1]]$results) #205 species
  res1 <- res1 %>% group_by(sp1_name) %>%
    mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "1") %>% 
    dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
    distinct()

  res2 <- data.frame(co_occ_list1[[a]][[2]]$results) #212 species
  res2 <- res2 %>% group_by(sp1_name) %>%
    mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "2") %>% 
    dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
    distinct()
  
  results <- full_join(res1,res2)
  
  species_data_a1_2 <- merge(species_data_a1, results, by.x=c("verbatim_name", "tp"), by.y = c("sp1_name", "tp"), all = T)
  
  co_occ_list2[[a]] <- species_data_a1_2

}
 
Co_Occ_df_final <- plyr::rbind.fill(co_occ_list2)
saveRDS(Co_Occ_df_final, paste0(out_path, "rds/Coocc_df_final.rds"))


# Some summaries -------------------------------------------------------- #

# summary(co_occurrence_tp1)
# prob.table(co_occurrence_tp1)
# plot(co_occurrence_tp1, cex.axis = 0.5)
# pair.profile(co_occurrence_tp1)
# obs.v.exp(co_occurrence_tp1)




```

#### Co_Occ_df_final: Read back in

```{r}

Co_Occ_df_final <- readRDS(paste0(out_path, "rds/Coocc_df_final.rds"))

predictors_df6 <- full_join(Co_Occ_df_final, predictors_df2) 
# predictors_df6 <- full_join(Co_Occ_df_final, predictors_df5) 
predictors_df6

```

## AVONET Traits

```{r}

tax_frame6<- tax_frame5 %>% 
  distinct(verbatim_name, sp_BirdLife, sp_BirdTree, .keep_all = T)

#-------------------------------------------------------------------------------------------------------------#
avonet_final <- read.csv2(paste0(out_path, "csv/AVONET_final.csv"), na.strings = c("#N/A", "<NA>", "NA"))
avonet_final[avonet_final=="<NA>"] = NA
avonet_final[avonet_final=="#NA>"] = NA


avonet_coalesced <- avonet_final %>% mutate(
  Family = coalesce(Family_BL, Family_BT),
  Order = coalesce(Order_BL, Order_BT),
  HWI = coalesce(Hand.Wing.Index_BL, Hand.Wing.Index_BT),
  Mass = coalesce(Mass_BL, Mass_BT),
  Habitat = coalesce(Habitat_BL, Habitat_BT),
  Habitat.Density = coalesce(Habitat.Density_BL, Habitat.Density_BT),
  Migration = coalesce(Migration_BL, Migration_BT),
  Trophic.Level = coalesce(Trophic.Level_BL, Trophic.Level_BT),
  Trophic.Niche = coalesce(Trophic.Niche_BL, Trophic.Niche_BT),
  Primary.Lifestyle = coalesce(Primary.Lifestyle_BL, Primary.Lifestyle_BT),
  Range.Size = coalesce(Range.Size_BL, Range.Size_BT))

avonet_final <- avonet_coalesced[,c(1:2, 26:36)] %>% distinct(sp_atlas, .keep_all=T) %>% rename("verbatim_name" = "sp_atlas")
avonet_final %>% filter_all(any_vars(is.na(.))) # 6 Species without range size (and other data)
avonet_final %>% filter_all(any_vars(!is.na(.))) %>% distinct(sp_atlas) %>% nrow() #841 species have data


predictors_df7 <- left_join(predictors_df6, avonet_final) %>% 
  distinct(verbatim_name, tp, dataset, .keep_all=T) 
predictors_df7

predictors_df7 %>% filter_all(all_vars(!is.na(.))) %>% distinct(verbatim_name, dataset, tp) %>% group_by(dataset, tp) %>% summarise(n=n())



```

## Phylogenetic Distinctness

```{r}
predictors_df7$tip.label <- gsub(" ", "_", predictors_df7$sp_BirdTree)

FP <- phyloregion::evol_distinct(tree, "fair.proportion") # phylogenetic distinctness (Isaac et al., 2007).
FP <- data.frame(FP)
FP$tip.label <- rownames(FP)
rownames(FP) <- NULL

setdiff(predictors_df7$tip.label, FP$tip.label) %>% length()

predictors_df8 <- left_join(predictors_df7, FP) %>% 
  select(-tip.label, -sp_BirdLife, -sp_BirdTree)


```

#### Merging Atlas + Species predictors

```{r}
all_predictors0 <- full_join(predictors_df8, atlas_predictors_df2) 
str(all_predictors0)

rownames(all_predictors0) <- NULL
all_predictors0 <- all_predictors0 %>% distinct(verbatim_name, tp, dataset, .keep_all = T) %>%  filter(!is.na(verbatim_name))



saveRDS(all_predictors0, paste0(out_path, "All_predictors.rds"))

```
