---
title: "0_2_Atlas_Predictors_prep"
author: "Friederike Wölke"
date: "2024-03-15"
output:
  html_document:
    code_folding: hide
format:
  html:
    toc: true
    number-sections: true
    colorlinks: true
---

# Predictors from the Atlas data

#### Part 1: Predicting future change: can data from the 80s predict the temporal change that took place between the 80s and 00s?

#### Part 2: Predicting past change: can data from the 00s predict the temporal change that took place between the 80s and 00s?

## Libraries

```{r, message = F}
rm(list=ls())
gc()

# Essential data wrangling packages:
library(dplyr) # Data wrangling
library(rstatix) # Reorder levels function
# library(plyr) (required but will be called individually for each function because of incompatibilities with dpylr functions)

# Phylogenetic stuff:
library(ape);library(phyloregion)
library(fossil) # Co occurrence

# Spatial stuff:
library(sf); sf_use_s2(FALSE) # Spatial stuff 1

# SAC:
library(ncf) # new SAC script

```

## Data paths

```{r, Data paths}
### The paths =================================================
source_atlas <- c("c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Processed/Atlases/Replicated/")
source_predictors <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/PhD_Projects/StaticPredictors/Data/")
source_Git <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/Project_Frieda/StaticPredictors/")
out_path <- c(paste0(source_Git, "out/"))

# folder path to atlas data
source_paths <- c(
  paste0(source_atlas, "Birds_Atlas_Czechia/"),
  paste0(source_atlas, "Birds_Atlas_New_York/"),
  paste0(source_atlas, "Birds_atlas_Japan/"),
  paste0(source_atlas, "Birds_atlas_EBBA/")
)

# create path to read in data and grids from variables
data_paths <- c(paste0(source_paths[1],"Birds_Atlas_Czechia_beast_data.rds"), 
                paste0(source_paths[2], "Birds_Atlas_New_York_beast_data.rds"), 
                paste0(source_paths[3], "Birds_atlas_Japan_beast_data.rds"),
                paste0(source_paths[4], "2Birds_atlas_EBBA_beast_data.rds"))

grid_paths <- c(
  paste0(source_paths[1], "Birds_Atlas_Czechia_grid.gpkg"),
  paste0(source_paths[2], "Birds_Atlas_New_York_grid.gpkg"),
  paste0(source_paths[3], "Birds_atlas_Japan_grid.gpkg"),
  paste0(source_paths[4], "Birds_atlas_EBBA_grid.gpkg")
)

# Important vectors  =================================================
time_periods <- c(1,2)
atlas_names <- c("Birds_Atlas_Czechia", "Birds_Atlas_New_York","Birds_atlas_Japan", "Birds_atlas_EBBA")
desired_levels <- factor(c("1", "2", "4", "8", "16", "32", "64", "128"), ordered = T,
  levels = c("1", "2", "4", "8", "16", "32", "64", "128"))

# list of crs in order of atlas_names
# Define CRS for each region
crs_list <- list( "EPSG:5514", # CZ
                  "EPSG:32118", # NY
                  "EPSG:6668", # JP
                  "EPSG:3035") # EU
names(crs_list) <- c("CZ", "NY", "JP", "EU")

```

```{r, Read data}
## Read Processed Data from 0_1_Atlas_prep.qmd script =========================================== ##

pres_dat_final <- readRDS(paste0(out_path, "rds/presence_data_final.rds")) # species data per cell
big_tab <- read.csv(paste0(out_path, "csv/Big_table_CZ_JP_NY_EU.csv")) %>% 
  reorder_levels(cell_grouping, desired_levels)

# Other external data ============================================================================ ##
Niches_df <- readRDS(paste0(out_path, "rds/Niches_df_v3.rds")) %>% filter(!is.na(data_names)) #734 sp
tax_lookup <- read.csv("Taxonomic/Sp_in_data_GBIF_normalized.csv")
BirdTree_tax_lookup <- read.csv2("Taxonomic/sp_birdtree_normalized_all.csv")
Tax <- read.csv2("out/csv/Tax_lookup_BirdLife_eBird_BirdTree_AtlasBOTW.csv")

RangeSizeNew <- readRDS(paste0(out_path, "rds/RangeSizeBOTW_df.rds"))
# avonet_final <- read.csv2(paste0(out_path, "csv/AVONET_final.csv"), na.strings = c("#N/A", "<NA>", "NA"))
# BOTW_RL <- read.csv2(paste0(out_path, "csv/BOTW_RedList.csv"), na.strings = c("#N/A"))
# avonet <- read.csv(paste0(source_predictors, "AVONET/ELEData/TraitData/AVONET1_BirdLife.csv"))





# %>% group_by(dataset, tp) %>% summarize(n = n_distinct(verbatim_name))

big_tab %>% 
  group_by(dataset, tp) %>% 
  summarize(n = n_distinct(verbatim_name)) %>% 
  merge(big_tab %>% na.omit() %>% 
          group_by(dataset, tp) %>% 
          summarize(n2 = n_distinct(verbatim_name)))


Bird_Life <- right_join(RangeSizeNew, Niches_df %>% rename("sci_name" = "verbatim_name")) %>% 
  #na.omit() %>% 
  rename("sp_BirdLife" = "sci_name") 

colSums(is.na(Bird_Life))
length(unique(Bird_Life$data_names)) #733 speces

```

## The Data

```{r, read and process data, message = F}
## We need the highest resolution data = cell_grouping = 1

# grid data =====================
grids <- list()
for (a in seq_along(grid_paths)) {
    grids_a <-sapply("cell1grid", function(i) {
      st_read(grid_paths[[a]], paste(i), quiet = TRUE)  %>% 
        st_transform(crs = crs_list[[a]]) %>% 
        reorder_levels( cell_grouping, order=desired_levels)
      }, simplify = FALSE)
    grids[[a]] <- grids_a$cell1grid
}

# Species data  =====================
presence_data_all <- list()
for (i in seq_along(data_paths)) {
  pres_dat <- readRDS(data_paths[i])
  sy <- sort(unique(pres_dat$start_year)) # sy = start_year

  ## Add time-period column
  pres_dat2 <- pres_dat %>% 
    mutate(tp = case_when(start_year == sy[1] ~ 1,
                          start_year == sy[2] ~ 2)) %>% 
    filter(tp %in% c(1,2)) %>%
    filter(!is.na(cell_label)) %>%
    reorder_levels(cell_grouping, order=desired_levels)

  ## Cells sampled twice (column: repeated)
  common_cells <- pres_dat2 %>%
    ungroup() %>%
    group_by(dataset, cell_grouping, cell_label) %>%
    mutate(num_periods_cells = n_distinct(tp)) %>%
    mutate(repeated = case_when(
      num_periods_cells == 2 ~ 1,
      num_periods_cells %in% c(1, 2) ~ 0
    )) %>%
    ungroup() %>%
    group_by(dataset) %>%
    select(dataset, cell_grouping, cell_label, num_periods_cells, repeated) %>%
    unique()

  common_cells %>%
    group_by(dataset, cell_grouping, repeated, num_periods_cells) %>%
    summarise(n = n())

  presence_data_rep <- full_join(pres_dat2, common_cells)

  # Species sampled twice in the remaining cells
  common_sp <- presence_data_rep %>%
    filter(repeated == 1 & cell_grouping == 1) %>%
    group_by(dataset, verbatim_name) %>%
    summarise(num_periods_sp = n_distinct(tp)) %>%
    ungroup() 
  presence_data3 <- full_join(presence_data_rep, common_sp) 

  presence_data_all[[i]] <- presence_data3
}

saveRDS(presence_data_all, paste0(out_path, "rds/presence_data_all.rds"))


## Save EBBA subset ## (for spatial autocorrelation parallelization)
# EBBA_df_all <- presence_data_all[[4]] %>% filter(cell_grouping == 1 & num_periods_cells == 2 & num_periods_sp == 2) %>% select(dataset, tp, verbatim_name, cell_long, cell_lat, cell_label, area, area_cropped) %>% filter(!is.na(cell_label))
# 
# saveRDS(EBBA_df_all, paste0(out_path, "rds/EBBA_df_all.rds"))

# Create list of spatial objects ==========================
presence_sf_list <- list()
for (a in seq_along(atlas_names)){
  grid <- grids[[a]]
  presence_data <- presence_data_all[[a]]
  presence_sf <- left_join(grid, presence_data) 
  dd <- presence_sf %>% filter(dataset == atlas_names[a]) %>% # remove unsampled cells
    group_by(dataset,tp) %>%
    mutate(GammaSR = sum(n_distinct(verbatim_name))) %>% 
    ungroup()
  presence_sf_list[[a]] <- dd 
  }
names(presence_sf_list) <- atlas_names
saveRDS(presence_sf_list, paste0(out_path, "rds/presence_sf_list.rds"))


# Big Table ================================
sp_df_big <- big_tab %>% 
  filter(cell_grouping == 1) %>% 
  select(-cell_grouping, -X, -scale) %>% 
  left_join(tax_lookup  %>% rename("verbatim_name" = "verbatimScientificName")) %>%
  left_join(Tax) %>%
  #left_join(RangeSizeNew %>% rename("sp_BirdLife" = "sci_name")) %>% #exclude BirdLife data for now here
  filter_at(vars(log_R2_1), any_vars(!is.na(.))) %>% 
  #full_join(Niches_df %>% rename("sp_BirdLife" = "verbatim_name")) %>%  #exclude BirdLife data for now here
  distinct(verbatim_name, .keep_all=T) %>%
  filter(!is.na(dataset)) %>%
  select(-acceptedUsageKey, -usageKey, -authorship, -species, -class, -phylum, -kingdom, -rank, -status, -confidence, -matchType, -key, -occurrenceId)

sp_df_big %>% distinct(verbatim_name) %>% nrow() # 774 species 
colSums(is.na(sp_df_big)) #103 species without climate data


# sp_wo_clim <- sp_df_big %>% filter(is.na(sd_PC1))
# sp_wo_clim %>% group_by(dataset, tp) %>% summarise(n = n())

# sp_df_big %>% distinct(verbatim_name)%>% rename("scientificName" = "verbatim_name") %>% 
# write.csv("out/csv/sp_names_data.csv")
# this vector was matched against the GBIF backbone

```

```{r}
plot(presence_sf_list[[1]][,"verbatim_name"])
plot(presence_sf_list[[2]][,"verbatim_name"])
plot(presence_sf_list[[3]][,"verbatim_name"])
plot(presence_sf_list[[4]][,"verbatim_name"])


plot(presence_sf_list[[3]][,"GammaSR"])

```

# Predictors

```{r, predictors}
# Make dataframes with predictors ======================
atlas_predictors_df2 <- big_tab %>% 
  select(dataset, Total_area, tp, grain) %>% 
  distinct()

predictors_df <- sp_df_big%>% 
  select(
    verbatim_name, dataset, tp, scientificName, order, family, genus, 
    canonicalName, sp_BirdLife, BirdTree_tip.labels, # Grouping variables
    log_R2_1, Telfer_1_2, # Response variables
    Total_area, Total_Ncells_samp, # Extent of the Arena
    relative_occupancy_Ncells, # Relative Occupancy
    D_AOO_a, # D of AOO based on mean area
    total_SR_atlas_AOOcalc) #GammaRichness of Atlas
    # 101 NAs in Climate Niche, 99 NA in RangeSize

colSums(is.na(predictors_df))

# Vector with species names in predictor data ==================
sp_names_predictors <- predictors_df %>% #841 species
  distinct(verbatim_name) %>%  
  pull(verbatim_name) %>% 
  as.vector()
# write.csv(sp_names_predictors, paste0(out_path, "csv/sp_names_predictors_v2.csv")) 

```

# Save Environment until here

```{r}
# Save Environment until here
gc()
save.image(paste0(out_path, "RData/AtlasPredictors_1_v2.RData"))
load(paste0(out_path, "RData/AtlasPredictors_1_v2.RData"))

```

================ RUN COMPLETELY UNTIL HERE AND THEN ONLY RUN CHUNKS WHERE OBJECTS ARE READ BACK IN ======================

## Diversity Metrics

```{r, eval = F, include = T}
## Calculate Diversity Measures ======================
GammaAlphaBeta_Atlas <- pres_dat_final %>%
  filter(cell_grouping == 1) %>%
  select(dataset, tp, cell_label, verbatim_name) %>% distinct() %>%
  group_by(dataset,tp) %>%
  mutate(GammaSR = sum(n_distinct(verbatim_name))) %>% ungroup() %>%
  group_by(dataset, tp, cell_label) %>%
  mutate(AlphaSR = sum(n_distinct(verbatim_name))) %>%
  mutate(BetaSR = GammaSR/AlphaSR)

GammaAlphaBeta_Species <- GammaAlphaBeta_Atlas %>%   
  ungroup() %>%
  group_by(dataset, tp, verbatim_name) %>%
  mutate(AlphaSR_sp = mean(AlphaSR)) %>%
  mutate(BetaSR_sp = GammaSR/AlphaSR_sp) %>%
  select(dataset, tp, verbatim_name, AlphaSR_sp, BetaSR_sp, GammaSR) %>% distinct()

## Calculate Mean Sampling Effort  ======================
AvgEffort <- pres_dat_final %>%
  filter(cell_grouping == 1) %>%
  select(dataset, tp, cell_label, verbatim_name, samp_effort_type, effort) %>% 
  distinct() %>%
  group_by(dataset, tp, verbatim_name) %>%
  summarize(avgEffort = mean(effort))

Diversity_Effort <- full_join(GammaAlphaBeta_Species, AvgEffort)
saveRDS(Diversity_Effort, paste0(out_path, "rds/Diversity_AvgEffort.rds"))
colSums(is.na(Diversity_Effort)) #NA: avgEffort = 1660



```

## Spatial Autocorrelation

This script takes several days to run for all atlases. Therefore I split the script and ran the calculations in parallel for all atlases at the same time. Output objects are merged in a separate script.

```{r, eval = F, include = T}
sf_use_s2(FALSE)
presence_data_all <- readRDS(paste0(out_path, "rds/presence_data_all.rds"))
# pacman::p_load("ncf")

morans_list <- list()
data_list <- list()

morans_list2 <- list()
data_list2 <- list()

morans_list3 <- list()
data_list3 <- list()


for (a in seq_along(atlas_names)){

  dd <- presence_data_all[[a]] %>% 
  ungroup() %>% 
  filter(cell_grouping == 1) %>% 
  select(dataset, tp, verbatim_name, area, area_cropped, cell_lat, cell_long, cell_label)
  
  for (y in seq_along(time_periods)){
    
    dd1 <- dd %>% filter(tp == time_periods[y]) %>% ungroup() %>% distinct() 
    sp_list <- unique(dd1$verbatim_name)
    
    for (s in seq_along(sp_list)){  
      print(paste("atlas =", unique(dd1$dataset), "tp =", unique(dd1$tp), "sp = ", sp_list[s], "N = ", s, "/", length(sp_list)))
      
      # Obtain a df for each species that indicates the presence (1) or absence (0) of the species
      
      data_species <- dd1 %>% 
        distinct(verbatim_name, cell_label, cell_lat, cell_long) %>% 
        ungroup() %>% unique() %>%
        mutate(
          verbatim_name = ifelse(verbatim_name != sp_list[s], NA, verbatim_name)) %>%
        group_by(across(-verbatim_name)) %>%
        slice(which.max(!is.na(verbatim_name))) %>% 
        distinct(verbatim_name, cell_label, .keep_all=T) %>%
        mutate(
          presence = ifelse(!is.na(verbatim_name), 1, 0)) %>% ungroup()
    

      data_reduced <- dd1 %>% 
        filter(verbatim_name == sp_list[s]) %>% 
        select(verbatim_name, dataset, tp, area, area_cropped) %>% 
        distinct() %>% 
        mutate(mean_area = mean(area),
          mean_area_cropped = mean(area_cropped),
          mean_cell_length = sqrt(mean_area)) %>% 
        mutate(
          increment2 = mean_cell_length * 1.75) %>% 
        ungroup() %>% 
        distinct(verbatim_name, .keep_all = T)
      
      data_species$increment <- data_reduced$increment2
          
        
      tryCatch({
        print("Attempting to calculate Moran's I")
        morans_cor <- correlog(x = data_species$cell_long, 
                         y = data_species$cell_lat, 
                         z = data_species$presence, 
                         latlon = TRUE, 
                         increment = unique(data_species$increment), 
                         resamp = 0)
  
        data_reduced$moran <- morans_cor$correlation[1]
        data_reduced$x_intercept <- morans_cor$x.intercept
  
        print("Moran's I calculated successfully")
        }, 
        error = function(e) {
          print("Error occurred while calculating Moran's I")
          print(paste("Error message:", e))
          morans_cor <- NA
          data_reduced$moran <- NA
          data_reduced$x_intercept <- NA
          })
      
      data_list[[s]] <- data_reduced
      morans_list[[s]] <- morans_cor 
      

    } # species loop closing
    
    morans_list2[[y]] <- morans_list
    
    data_df <- plyr::rbind.fill(data_list)
    data_list2[[y]] <- data_df
  
  } # year loop closing
  
    morans_list3[[a]] <- morans_list2
    
    data_df2 <- plyr::rbind.fill(data_list2)
    data_list3[[a]] <- data_df2
    
    } # atlas loop closing

data_df_all <- plyr::rbind.fill(data_list3) 
saveRDS(data_df_all, paste0(out_path, "rds/SAC_final.rds"))

```

## Characterize Geometries

(Function by Dr. Gabriel Ortega: requires terra & tidyverse)

```{r, geometries function from Gabriel, eval = F, include = T}
pacman::p_load(geosphere, geodata, terra, tidyverse, tidyterra)

# Function to get the max elongation per polygon, north-south length or east-west length, circularity, etc...
poly_attr <- function(x, type = NULL) {
  # Convert "sf" to SpatVector
  if (inherits(x, "sf") == T) {
    x <- vect(x)
  }
  # Reproject to WGS84. Currently, "terra" calculate distance in meters when given latitude and longitude points.
  x <- project(x, "epsg:4326")
  # Get East-West distance (longitudinal extension)
  if (type == "ewDist") {
    vert <- crds(as.points(ext(x)), df = T)
    dimNames <- list(c("point"),c("x","y"))
    sw <- matrix(c(min(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    se <- matrix(c(max(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    res <- distance(sw, se, lonlat = T)[[1]]
  }
  # Get South-North distance (latitudinal extension)
  if (type == "nsDist") {
    vert <- crds(as.points(ext(x)), df = T)
    dimNames <- list(c("point"),c("x","y"))
    sw <- matrix(c(min(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    nw <- matrix(c(min(vert[["x"]]), max(vert[["y"]])), ncol = 2, dimnames = dimNames)
    res <- distance(sw, nw, lonlat = T)[[1]]
  }
  # Get max distance between opposite vertices
  if (type == "maxDist") {
    vert <- crds(as.points(convHull(x)))
    res <- distance(vert, lonlat = T) %>% max()
  }
  # Get elongation ratio along longest axis
  if (type == "elonRatio") {
    convexHull <- convHull(x)
    vert <- crds(as.points(convexHull), df = T)
    dist <- as.data.frame.table(as.matrix(distance(vert, lonlat = T)), responseName = "distance") %>%
      slice_max(., distance)
    axisPoints <- vert[c(dist[[1]][[1]],dist[[2]][[1]]),]
    axisPoints <- arrange(axisPoints, desc(y))
    rotation <- -1*bearing(axisPoints[2,],axisPoints[1,])
    rotHull <- spin(convexHull, rotation)
    ext <- ext(convexHull)
    df <- as.vector(distance(crds(as.points(ext)), lonlat = T))
    df <- sort(df)
    length <- mean(df[[3]], df[[4]])
    width <- mean(df[[1]], df[[2]])
    res <- 1 - (width / length)
    # res <- list()
    # res[["vert"]] <- vert
    # res[["dist"]] <- dist
    # res[["axispoints"]] <- axisPoints
    # res[["bearing"]] <- rotation
    # res[["rotHull"]] <- rotHull
  }
  # Circularity
  if (type == "circ") {
    perimeter <- perim(x)
    area <- expanse(x)
    res <- (perimeter^2) / area
  }
  # Normalized circularity
  if (type == "circNorm") {
    perimeter <- perim(x)
    area <- expanse(x)
    res <- (perimeter^2) / (4 * pi * area)
  }
  # Major length of the minimum rectangle
  if (type == "lengthMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle), df = T), lonlat = T))
    df <- sort(df)
    res <- mean(df[[3]], df[[4]])
  }
  # Width of the minimum rectangle
  if (type == "widthMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle), df = T), lonlat = T))
    df <- sort(df)
    res <- mean(df[[1]], df[[2]])
  }
  # Elongation ratio of minimal encasing rectangle (from here: Dražić, S., Ralević, N., & Žunić, J. (2010). Shape elongation from optimal encasing rectangles. Computers & Mathematics with Applications, 60(7), 2035–2042. https://doi.org/10.1016/j.camwa.2010.07.043)
  if (type == "elonMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle)), lonlat = T))
    df <- sort(df)
    length <- mean(df[[3]], df[[4]])
    width <- mean(df[[1]], df[[2]])
    res <- 1 - (width / length)
  }
  # Related circumscribing circle
  if (type == "relCirc") {
    circle <- minCircle(x)
    areaCircle <- expanse(circle)
    area <- expanse(x)
    res <- 1-(area/areaCircle)
  }
  # Linearity index
  if (type == "lin") {
    hull <- convHull(x)
    df <- crds(as.points(hull), df = T)
    lm <- lm(y ~ x, data = df)
    res <- summary(lm)$r.squared
  }
  # North bearing of the minimum rectangle
  if (type == "bearingMinRect") {
    minRectangle <- minRect(x)
    df <- crds(as.points(minRectangle), df = T)
    cor <- cor(df[["x"]],df[["y"]])
    point1 <- slice_min(df, y)
    if (cor > 0){
      point2 <-slice_max(df, x)
    } else{
      point2 <-slice_min(df, x)
    }
    res <- bearing(point1, point2)
  }
    # Get bearing along longest axis
  if (type == "bearing") {
    convexHull <- convHull(x)
    vert <- crds(as.points(convexHull), df = T)
    dist <- as.data.frame.table(as.matrix(distance(vert, lonlat = T)), responseName = "distance") %>%
      slice_max(., distance)
    axisPoints <- vert[c(dist[[1]][[1]],dist[[2]][[1]]),]
    axisPoints <- arrange(axisPoints, desc(y))
    res <- bearing(axisPoints[2,],axisPoints[1,])
  }
  res <- as.numeric(res)
  return(res)
}
```

### Calculate Geometries:

This takes quite some time. Better read the objects back in below.

```         
10311.01 sec elapsed 
```

```{r, calculate geometries, message = F, eval = F, include = T}
tictoc::tic()
# Atlas Geometries ==============================================================
geom_ls <- list()

for (i in seq_along(grids)){
  
  Atlas_Geom <- grids[[i]] %>% 
    select(geom, cell_label) %>%
    summarise() %>% 
    terra::vect()
  
  Geom_attributes_atlas <- data_frame(dataset = atlas_names[i],
           atlas_nsDist = poly_attr(Atlas_Geom, "nsDist"),
           atlas_ewDist = poly_attr(Atlas_Geom, "ewDist"),
           atlas_maxDist = poly_attr(Atlas_Geom, "maxDist"),
           atlas_lengthMinRect = poly_attr(Atlas_Geom, "lengthMinRect"),
           atlas_widthMinRect = poly_attr(Atlas_Geom, "widthMinRect"),
           atlas_elonMinRect = poly_attr(Atlas_Geom, "elonMinRect"),
           atlas_elonRatio = poly_attr(Atlas_Geom, "elonRatio"),
           atlas_circ = poly_attr(Atlas_Geom, "circ"),
           atlas_circNorm = poly_attr(Atlas_Geom, "circNorm"),
           atlas_relCirc = poly_attr(Atlas_Geom, "relCirc"),
           atlas_lin = poly_attr(Atlas_Geom, "lin"),
           atlas_bearingMinRect = poly_attr(Atlas_Geom, "bearingMinRect"), 
           atlas_bearing = poly_attr(Atlas_Geom, "bearing"))
           
  ## Southernness/Westernness
  atlas_xmin <- st_bbox(Atlas_Geom)[1]
  atlas_ymin <- st_bbox(Atlas_Geom)[2]
  atlas_xmax <- st_bbox(Atlas_Geom)[3]
  atlas_ymax <- st_bbox(Atlas_Geom)[4]
  atlas_xhalf <- atlas_xmax+(atlas_xmin-atlas_xmax)/2
  atlas_yhalf <- atlas_ymax+(atlas_ymin-atlas_ymax)/2
  
  atlas_bbox <- data.frame(atlas_xmin, atlas_xmax, atlas_xhalf, atlas_ymin, atlas_ymax, atlas_yhalf)
  atlas_bbox$dataset <- atlas_names[i] 
  
  geom_ls[[i]] <- full_join(atlas_bbox, Geom_attributes_atlas)
  
}

countries_geom_attributes <- plyr::rbind.fill(geom_ls) 

# Transform country-borders to lines
lines_l <- list()

for (a in seq_along(grids)){
  lines <- grids[[a]] %>% 
    summarise() %>% 
    vect() %>% 
    as.lines()
  lines_l[[a]] <- lines
}

### For each species separately:

species_geom <- list()
year_species_geom <- list()
atlas_all_sp_geom <-list()
COG_all <- list()
COG_a <- list()

for (a in seq_along(presence_sf_list)){
  atlas <- presence_sf_list[[a]]
  
  for (y in seq_along(time_periods)){
    atlas_y <- atlas %>% filter(tp == time_periods[y])
    sp <- unique(atlas_y$verbatim_name)
    
    # Calculate Center of Gravity of all species per atlas
    COG <- atlas_y %>% st_drop_geometry() %>% summarise(CenterOfGravity_Atlas_long = mean(cell_long),
                                 CenterOfGravity_Atlas_lat = mean(cell_lat),
                                 dataset = unique(dataset))
    COG_all[[y]] <- COG

    points_COG_atlas <- COG %>% 
      dplyr::select(CenterOfGravity_Atlas_long, CenterOfGravity_Atlas_lat, dataset) %>%
      rename("x" = "CenterOfGravity_Atlas_long", "y" = "CenterOfGravity_Atlas_lat") %>% 
      na.omit() %>% 
      distinct()
    
    points_atlas <- points_COG_atlas %>% vect(geom = c("x", "y"), crs = "epsg:4326")
    
    for (s in seq_along(sp)){
      print(paste(atlas_names[a], time_periods[y], sp[s]))
      atlas_sp <- atlas_y %>% filter(verbatim_name == sp[s])
      
      ## Maybe I have to summarize here ! Not sure - let's try this and compare.
      COG_sp <- atlas_sp %>% 
        select(cell_long, cell_lat, verbatim_name, dataset, tp) %>%
        mutate(sp_COG_long = mean(cell_long), 
               sp_COG_lat = mean(cell_lat)) %>% 
        st_drop_geometry() %>% 
        select(-cell_long, -cell_lat) %>% 
        unique()
      
      points_COG_sp <- COG_sp %>%
        group_by(dataset, tp, verbatim_name) %>% 
        dplyr::select(sp_COG_long, sp_COG_lat, dataset, tp, verbatim_name) %>%
        rename("x" = "sp_COG_long", "y" = "sp_COG_lat") %>% na.omit() %>% ungroup()

      points2 <- points_COG_sp %>%
        vect(geom = c("x", "y"), crs = "epsg:4326")
            
      test <- atlas_sp %>% 
        select(geom, cell_label)%>% 
        summarise() %>% 
        vect() 
    
      ## Calculate distance 
      atlas_lines <- lines_l[[a]]
      Dist_toCOG <- terra::distance(crds(points2), crds(points_atlas), lonlat = T)
      minDist_toBorder_centr <- min(distance(crds(points2), crds(atlas_lines), lonlat=T))
      maxDist_toBorder_centr <- max(distance(crds(points2), crds(atlas_lines), lonlat=T))
      minDist_toBorder <- min(distance(crds(test), crds(atlas_lines), lonlat=T))
      maxDist_toBorder <- max(distance(crds(test), crds(atlas_lines), lonlat=T))
    
      Geom_attributes <- data_frame(dataset = atlas_names[a],
                                    tp = time_periods[y],
                                    verbatim_name = sp[s],
                                    nsDist = poly_attr(test, "nsDist"),
                                    ewDist = poly_attr(test, "ewDist"),
                                    maxDist = poly_attr(test, "maxDist"),
                                    lengthMinRect = poly_attr(test, "lengthMinRect"),
                                    widthMinRect = poly_attr(test, "widthMinRect"),
                                    elonMinRect = poly_attr(test, "elonMinRect"),
                                    elonRatio = poly_attr(test, "elonRatio"),
                                    circ = poly_attr(test, "circ"),
                                    circNorm = poly_attr(test, "circNorm"),
                                    relCirc = poly_attr(test, "relCirc"),
                                    lin = poly_attr(test, "lin"),
                                    bearingMinRect = poly_attr(test, "bearingMinRect"), 
                                    bearing = poly_attr(test, "bearing"),
                                    Dist_toCOD = Dist_toCOG,
                                    minDist_toBorder = minDist_toBorder,
                                    maxDist_toBorder = maxDist_toBorder,
                                    minDist_toBorder_centr = minDist_toBorder_centr,
                                    maxDist_toBorder_centr = maxDist_toBorder_centr)
        
        Geom_attributes2 <- full_join(Geom_attributes, COG_sp) %>% unique()
        
        species_geom[[s]] <- Geom_attributes2
        }
    
    species_geom_df <- plyr::rbind.fill(species_geom)  
    year_species_geom[[y]] <- species_geom_df  
    }
  COG_a[[a]] <- plyr::rbind.fill(COG_all)
  year_species_geom_df <- plyr::rbind.fill(year_species_geom) 
  atlas_all_sp_geom[[a]] <- year_species_geom_df
  }
COG_df <- plyr::rbind.fill(COG_a)
Species_geom_attributes <- plyr::rbind.fill(atlas_all_sp_geom) 

Atlas_geom <- full_join(countries_geom_attributes, COG_df) %>% group_by(dataset) %>% distinct(dataset, .keep_all=T)
Geometries <- full_join(Species_geom_attributes, Atlas_geom, relationship = "many-to-many") %>% distinct()

# Southerness/Westerness =================================
Southernness_Westernness <- Geometries %>% 
  group_by(dataset, tp, verbatim_name) %>% 
  select(dataset, tp, verbatim_name, sp_COG_long, sp_COG_lat, atlas_xmin, atlas_xmax, atlas_xhalf, atlas_ymin, atlas_ymax, atlas_yhalf) %>% 
  unique() %>%
  summarize(Southernness = 1-((sp_COG_lat - atlas_ymin)/((atlas_ymax -atlas_ymin))),
            Westernness = 1-((sp_COG_long - atlas_xmin)/((atlas_xmax-atlas_xmin)))) %>% ungroup() 

Geometries_final <- left_join(Geometries, Southernness_Westernness, relationship = "many-to-many") %>% distinct(dataset, tp, verbatim_name, .keep_all = T)

saveRDS(Geometries_final, paste0(out_path, "rds/Geometries.rds"))

```

## Co-Occurrence

Takes quite a while..

```{r, eval = F, include = T}
species_data <- pres_dat_final %>% 
  filter(cell_grouping == 1) %>% 
  select(dataset, tp, verbatim_name, cell_label) %>% 
  distinct()

# ----------------------------------------------------------- #
co_occ_list1<- list()
for (a in seq_along(atlas_names)){
  
  # create community dataframe
  species_data_a <- species_data %>% filter(dataset == atlas_names[a])
  comm_dat <- species_data_a %>% 
    group_by(tp) %>% 
    dplyr::select(tp, verbatim_name, cell_label) %>%
    ungroup() %>% 
    distinct()
  comm_dat <- as.data.frame(comm_dat)
  
  # Convert data frame to Species X sites matrix
  comm_matrix_tp1 <- fossil::create.matrix(comm_dat, 
                                           tax.name = "verbatim_name", 
                                           locality = "cell_label", 
                                           time.col = "tp", 
                                           time = "1", 
                                           abund = F)
  comm_matrix_tp2 <- fossil::create.matrix(comm_dat, 
                                           tax.name = "verbatim_name", 
                                           locality = "cell_label", 
                                           time.col = "tp", 
                                           time = "2", 
                                           abund = F)
  
  # Calculate probability of pairwise co-occurrence of species: ----------- #
  co_occurrence_tp1 <- cooccur::cooccur(comm_matrix_tp1, spp_names = T)
  print(length(unique(co_occurrence_tp1$spp.names))) # 206 species 
  co_occurrence_tp2 <- cooccur::cooccur(comm_matrix_tp2, spp_names = T)
  print(length(unique(co_occurrence_tp2$spp.names))) # 213 species
  
  co_occ_list1[[a]] <- list(co_occurrence_tp1, co_occurrence_tp2)
}

co_occ_list2 <-list()
for (a in seq_along(atlas_names)){
  species_data_a <- species_data %>% filter(dataset == atlas_names[a])
  species_data_a1 <- species_data_a %>% select(-cell_label) %>% distinct()

  res1 <- data.frame(co_occ_list1[[a]][[1]]$results) 
  res1 <- res1 %>% group_by(sp1_name) %>%
    mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "1") %>% 
    dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
    distinct()

  res2 <- data.frame(co_occ_list1[[a]][[2]]$results) 
  res2 <- res2 %>% group_by(sp1_name) %>%
    mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "2") %>% 
    dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
    distinct()
  
  results <- full_join(res1,res2)
  species_data_a1_2 <- merge(species_data_a1, results, by.x=c("verbatim_name", "tp"), by.y = c("sp1_name", "tp"), all = T)
  co_occ_list2[[a]] <- species_data_a1_2
}
 
Co_Occ_df_final <- plyr::rbind.fill(co_occ_list2)
saveRDS(Co_Occ_df_final, paste0(out_path, "rds/Coocc_df_final.rds"))

```

## AVONET Traits

```{r}

avonet <- read.csv("out/csv/Avonet_FP_Matched_UTaxonstand.csv") %>% rename("verbatim_name" = "sp_atlas")

### For Avonet Raw data:
# avonet <- avonet %>% select(Species1, Mass, Hand.Wing.Index, Migration, Trophic.Level, Trophic.Niche, Primary.Lifestyle, Range.Size) %>% distinct(Species1, .keep_all=T)

# avonet_sl <- unique(avonet$Species1)
# names(avonet_sl) <- "scientificName"
# avonet_sl[1:5999] %>% write.csv("Taxonomic/Avonet_species_list1.csv")
# avonet_sl[6000:11009] %>% write.csv("Taxonomic/Avonet_species_list2.csv")
# ## these were matched to GBIF backbone
# AVO_tax <- read.csv2("Taxonomic/Avonet_species_list_all_normalized.csv") %>% select(verbatimScientificName, canonicalName)

# avonet[avonet=="<NA>"] <- NA
# avonet2 <- avonet %>% filter(Species1 %in% sp_names_predictors )
# avonet3 <- merge(avonet2, AVO_tax, by.x="Species1", by.y="verbatimScientificName", all.x = T)
# 
# saveRDS(avonet3, paste0(out_path, "rds/AVONET_final_v2.rds"))

```

## Phylogenetic Distinctness

```{r}

# phylogenetic tree =====================
tree <- ladderize(read.tree(paste0(source_predictors, "Weeks_et_at_2022/singe_bird_phylo.tre")))

FP <- phyloregion::evol_distinct(tree, "fair.proportion") # phylogenetic distinctness (Isaac et al., 2007).
FP <- data.frame(FP)
FP$tip.label <- rownames(FP)
rownames(FP) <- NULL
unique(FP$tip.label) %>% length() # 9993 species 
FP$sp_BirdTree <- gsub("_", " ", FP$tip.label)

write.csv(FP, paste0(out_path, "csv/EvolDistinctness.csv"))

BT_tax <- BirdTree_tax_lookup %>% 
  select(sp_BirdTree, canonicalName) %>% 
  na.omit()


BT_tax2 <- Tax %>% select(verbatim_name, sp_BirdTree,sp_names_atlas_adapted_keep)

FP2 <- left_join(FP, BT_tax) # 9993

FP3 <- left_join(FP, BT_tax2) # 10184
write.csv(FP2, paste0(out_path, "csv/EvolDistinctness.csv"))

colSums(is.na(FP3))

### Tax Match ####
intersect(Bird_Life$sp_BirdLife, FP2$sp_BirdTree) %>% length() # 670
setdiff(Bird_Life$sp_BirdTree, FP3$sp_BirdTree) %>% length() # 1 (NA)

Bird_Life2 <- left_join(Bird_Life, FP3) %>% 
  distinct(verbatim_name, GlobRangeSize_m2, sd_PC1, sd_PC2, FP) 
colSums(is.na(Bird_Life2))

saveRDS(Bird_Life2, "out/rds/Bird_Life_predictors.rds")


unique(Bird_Life2$verbatim_name)

```

```{r, IUCN status}

library(taxize)
IUCN_data <- get_iucn(sp_names_predictors, key = "0f6be312676213695155e240c5d79f183f67c1ea9bfa012e20c1d427f5c8dab3")

IUCN_status <- synonyms(tax_lookup$canonicalName, db = "iucn", key = "0f6be312676213695155e240c5d79f183f67c1ea9bfa012e20c1d427f5c8dab3")
synonyms_df(IUCN_status)
```

# Merging Predictors together

## Species predictors

```{r}

colSums(is.na(predictors_df))
# predictors_df_clean <- predictors_df %>%
#   filter(if_any(c(verbatim_name, dataset, tp,
#                   log_R2_1, Telfer_1_2,
#                   Total_area, Total_Ncells_samp,
#                   relative_occupancy_Ncells, D_AOO_a,
#                   total_SR_atlas),
#                 ~ !is.na(.))) %>% 
#   filter(!is.na(D_AOO_a))
# saveRDS(predictors_df_clean, paste0(out_path, "rds/predictors_df1_clean.rds"))
# 
# predictors_df_clean <- readRDS(paste0(out_path, "rds/predictors_df1_clean.rds"))
# colSums(is.na(predictors_df_clean))
# 
# predictors_df_clean <- predictors_df_clean %>% 
#   filter(if_any(c(verbatim_name, dataset, tp, 
#                   log_R2_1, Telfer_1_2, 
#                   Total_area, Total_Ncells_samp, 
#                   relative_occupancy_Ncells, D_AOO_a, 
#                   total_SR_atlas), 
#                 ~ !is.na(.))) %>% filter(!is.na(D_AOO_a))

predictors_df %>% group_by(dataset, tp) %>% summarise(n = n_distinct(verbatim_name))

# Diversity
Diversity_Effort <- readRDS(paste0(out_path, "rds/Diversity_AvgEffort.rds"))
predictors_df2 <- left_join(predictors_df, Diversity_Effort); rm(Diversity_Effort)
colSums(is.na(predictors_df2))

#Geometries
Geometries <- readRDS( paste0(out_path, "rds/Geometries.rds")) %>% filter(dataset != "Birds_atlas_EBBA")
Geometries_EBBA_v2 <- readRDS( paste0(out_path, "rds/Geometries_EBBA_v2.rds"))

Geometries_full <- rbind(Geometries, Geometries_EBBA_v2)
Geometries_full %>% na.omit() %>% group_by(dataset, tp) %>% summarize(n= n_distinct(verbatim_name))
colSums(is.na(Geometries_full))

predictors_df3 <- left_join(predictors_df2, Geometries_full) 
colSums(is.na(predictors_df3))

# Co-Occurrence index
Co_Occ_df_final <- readRDS(paste0(out_path, "rds/Coocc_df_final.rds"))
predictors_df4 <- left_join(predictors_df3,Co_Occ_df_final) 
colSums(is.na(predictors_df4))

# Avonet
#avonet_final <- readRDS(paste0(out_path, "rds/AVONET_final_v2.rds"))

predictors_df5 <- left_join(predictors_df4, avonet) %>% 
  distinct(verbatim_name, tp, dataset, .keep_all=T) 
colSums(is.na(predictors_df5))

# Evol. distinctness
# FP <- read.csv(paste0(out_path, "csv/EvolDistinctness.csv"))
# FP2 <- FP %>% filter(tip.label %in% tax_lookup$TipLabel) %>% rename("TipLabel" = "tip.label") %>% select(-verbatim_name)
# 
# FP3 <- left_join(FP2, tax_lookup %>% distinct(TipLabel, name_in_data)) %>% rename("verbatim_name" = "name_in_data")
# predictors_df6 <- left_join(predictors_df5, FP3 %>% select(verbatim_name, FP)) %>% 
#   select(-sp_BirdLife, -sp_BirdTree) %>% distinct(verbatim_name, dataset, tp, .keep_all=T)
# colSums(is.na(predictors_df6))


# BirdLife predictors
# BL <- readRDS("out/rds/Bird_Life_predictors.rds")
# 
# predictors_df6 <- left_join(predictors_df5, BL)


# SAC
SAC_df <- readRDS(paste0(out_path, "rds/SAC_final.rds")) %>% filter(dataset != "Birds_atlas_EBBA")
colSums(is.na(SAC_df)) # 9 NAs
SAC_df_EU <- readRDS("out/rds/SAC_EU_v3.rds")
SAC_df2 <- full_join(SAC_df, SAC_df_EU)
colSums(is.na(SAC_df2))

SAC_df2 %>% filter(is.na(moran)) #9 rows with NAs in Moran: all in Czechia (both time periods)
SAC_df3 <- SAC_df2 %>% distinct(verbatim_name, dataset, tp, moran, x_intercept, increment2)
colSums(is.na(SAC_df3))
SAC_df3 %>% na.omit() %>% group_by(dataset, tp) %>% summarize(n= n_distinct(verbatim_name))


predictors_df7 <- left_join(predictors_df6, SAC_df3) %>% distinct(dataset, tp, verbatim_name, .keep_all = T)


colSums(is.na(predictors_df7))



predictors_df7_clean <- predictors_df7 %>% 
  select(verbatim_name, dataset, tp, log_R2_1, Telfer_1_2, Total_area, Total_Ncells_samp, total_SR_atlas,
         relative_occupancy_Ncells, D_AOO_a, AlphaSR_sp, BetaSR_sp, GammaSR,
         nsDist, ewDist, maxDist, lengthMinRect, widthMinRect, elonMinRect, 
         elonRatio, circ, circNorm, relCirc, lin, bearingMinRect, bearing, 
         minDist_toBorder, maxDist_toBorder, minDist_toBorder_centr, maxDist_toBorder_centr, 
         sp_COG_long, sp_COG_lat, 
         atlas_nsDist, atlas_ewDist, atlas_maxDist, atlas_lengthMinRect, atlas_widthMinRect, atlas_elonMinRect, 
         atlas_elonRatio, atlas_circ, atlas_circNorm, atlas_relCirc, atlas_lin, atlas_bearingMinRect, atlas_bearing, 
         CenterOfGravity_Atlas_long, CenterOfGravity_Atlas_lat, 
         Southernness, Westernness,
         mean_prob_cooccur,
         HWI, Mass, Habitat, Habitat.Density, Migration, Trophic.Level, Trophic.Niche, Primary.Lifestyle, 
         Range.Size, GlobRangeSize_m2, 
         moran, x_intercept, increment2, 
         sd_PC1, sd_PC2, FP) %>% 
  distinct(verbatim_name, dataset, tp, .keep_all = T)
```

## Atlas Predictors

```{r}
all_predictors0 <- full_join(predictors_df7_clean, atlas_predictors_df2) 
str(all_predictors0)

rownames(all_predictors0) <- NULL
all_predictors0 <- all_predictors0 %>% 
distinct(verbatim_name, tp, dataset, .keep_all = T) %>%  filter(!is.na(verbatim_name))




saveRDS(all_predictors0, paste0(out_path, "rds/All_predictors.rds"))
save.image(paste0(out_path, "RData/Atlas_predictors_2.RData"))

```

## Calc relative Geometry measures

```{r}

df <- readRDS("out/rds/All_predictors.rds")

df <- all_predictors0
df <- df %>% 
  mutate(HWI = as.numeric(as.character(HWI)),
         Mass = as.numeric(as.character(Mass)),
         Range.Size = as.numeric(as.character(Range.Size)),
         FP = as.numeric(FP),
         tp = as.integer(tp),
         dataset = as.factor(dataset),
         Habitat = as.factor(Habitat),
         #RL_Category = as.factor(RL_Category),
         Habitat.Density = as.factor(Habitat.Density),
         Migration = as.factor(Migration),
         Trophic.Level = as.factor(Trophic.Level),
         Trophic.Niche = as.factor(Trophic.Niche),
         Primary.Lifestyle = as.factor(Primary.Lifestyle),
         grain = as.integer(grain)) %>%
  select(-Total_Ncells_samp, -atlas_bearing, -atlas_bearingMinRect, -atlas_circ, -atlas_elonMinRect, -atlas_widthMinRect, -atlas_lengthMinRect, -bearing, -bearingMinRect, -circ, -elonMinRect, -widthMinRect, -lengthMinRect, -increment2, -grain, -total_SR_atlas)

head(df)
df2 <- df %>% mutate(
  rel_maxDist = maxDist / atlas_maxDist,
  rel_ewDist = ewDist / atlas_ewDist,
  rel_nsDist = nsDist / atlas_nsDist,
  rel_elonRatio = elonRatio / atlas_elonRatio,
  rel_relCirc = relCirc / atlas_relCirc,
  rel_lin = lin / atlas_lin,
  rel_circNorm = circNorm / atlas_circNorm) %>% 
  select(-maxDist, -atlas_maxDist, 
         -ewDist, -atlas_ewDist, 
         -nsDist, -atlas_nsDist, 
         -elonRatio, -atlas_elonRatio, 
         -relCirc, -atlas_relCirc,
         -lin, -atlas_lin, 
         -circNorm, -atlas_circNorm)

saveRDS(df2, paste0(out_path, "rds/All_predictors_relativeGeom.rds"))

```
