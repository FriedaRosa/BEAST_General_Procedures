---
title: "0_2_Atlas_Predictors_prep"
author: "Friederike Wölke"
date: "2024-03-15"
output:
  html_document:
    code_folding: hide
format:
  html:
    toc: true
    number-sections: true
    colorlinks: true
---

# Predictors from the Atlas data

#### Part 1: Predicting future change: can data from the 80s predict the temporal change that took place between the 80s and 00s?

#### Part 2: Predicting past change: can data from the 00s predict the temporal change that took place between the 80s and 00s?

## Libraries

```{r, message = F}
rm(list=ls())
gc()

# Essential data wrangling packages:
library(dplyr) # Data wrangling
library(rstatix) # Reorder levels function
# library(plyr) (required but will be called individually for each function because of incompatibilities with dpylr functions)

# Phylogenetic stuff:
library(ape);library(phyloregion)
library(fossil) # Co occurrence

# Spatial stuff:
library(sf); sf_use_s2(FALSE) # Spatial stuff 1

# SAC:
library(ncf) # new SAC script

```

## Data paths

```{r, Data paths}
### The paths =================================================
source_atlas <- c("c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Processed/Atlases/Replicated/")
source_predictors <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/PhD_Projects/StaticPredictors/Data/")
source_Git <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/Project_Frieda/StaticPredictors/")
out_path <- c(paste0(source_Git, "out/"))

# folder path to atlas data
source_paths <- c(
  paste0(source_atlas, "Birds_Atlas_Czechia/"),
  paste0(source_atlas, "Birds_Atlas_New_York/"),
  paste0(source_atlas, "Birds_atlas_Japan/"),
  paste0(source_atlas, "Birds_atlas_EBBA/")
)

# create path to read in data and grids from variables
data_paths <- c(paste0(source_paths[1],"Birds_Atlas_Czechia_beast_data.rds"), 
                paste0(source_paths[2], "Birds_Atlas_New_York_beast_data.rds"), 
                paste0(source_paths[3], "Birds_atlas_Japan_beast_data.rds"),
                paste0(out_path, "rds/EBBA_change_new.rds"))

grid_paths <- c(
  paste0(source_paths[1], "Birds_Atlas_Czechia_grid.gpkg"),
  paste0(source_paths[2], "Birds_Atlas_New_York_grid.gpkg"),
  paste0(source_paths[3], "Birds_atlas_Japan_grid.gpkg"),
  paste0(source_paths[4], "Birds_atlas_EBBA_grid.gpkg")
)

# Important vectors  =================================================
time_periods <- c(1,2)
atlas_names <- c("Birds_Atlas_Czechia", "Birds_Atlas_New_York","Birds_atlas_Japan", "Birds_atlas_EBBA")
desired_levels <- factor(c("1", "2", "4", "8", "16", "32", "64", "128"), ordered = T,
  levels = c("1", "2", "4", "8", "16", "32", "64", "128"))

```

```{r, Read data}
## Read Processed Data from 0_1_Atlas_prep.qmd script =========================================== ##

pres_dat_final <- readRDS(paste0(out_path, "rds/presence_data_final.rds")) # species data per cell
big_tab <- read.csv(paste0(out_path, "csv/Big_table_CZ_JP_NY_EU.csv")) %>% reorder_levels(cell_grouping, desired_levels)

# Other external data ============================================================================ ##
Niches_df <- readRDS(paste0(out_path, "rds/Niches_df_v2.rds"))
tax_lookup <- read.csv(paste0(out_path, "csv/TaxLookUp_final_v2.csv"))
RangeSizeNew <- readRDS(paste0(out_path, "rds/RangeSizeBOTW_df.rds"))
avonet_final <- read.csv2(paste0(out_path, "csv/AVONET_final.csv"), na.strings = c("#N/A", "<NA>", "NA"))
BOTW_RL <- read.csv2(paste0(out_path, "csv/BOTW_RedList.csv"), na.strings = c("#N/A"))

```

## The Data

```{r, read and process data, message = F}
## We need the highest resolution data = cell_grouping = 1

# phylogenetic tree =====================
tree <- ladderize(read.tree(paste0(source_predictors, "Weeks_et_at_2022/singe_bird_phylo.tre")))

# grid data =====================
grids <- list()
for (a in seq_along(grid_paths)) {
    grids_a <-sapply("cell1grid", function(i) {
      st_read(grid_paths[[a]], paste(i), quiet = TRUE)  %>% 
        st_transform(crs = 4326) %>% 
        reorder_levels( cell_grouping, order=desired_levels)
      }, simplify = FALSE)
    grids[[a]] <- grids_a$cell1grid
}

# Species data  =====================
presence_data_all <- list()
for (i in seq_along(data_paths)) {
  pres_dat <- readRDS(data_paths[i])
  sy <- sort(unique(pres_dat$start_year)) # sy = start_year

  ## Add time-period column
  pres_dat2 <- pres_dat %>% 
    mutate(tp = case_when(start_year == sy[1] ~ 1,
                          start_year == sy[2] ~ 2)) %>% 
    filter(tp %in% c(1,2)) %>%
    reorder_levels(cell_grouping, order=desired_levels)

  ## Cells sampled twice (column: repeated)
  common_cells <- pres_dat2 %>%
    ungroup() %>%
    group_by(dataset, cell_grouping, cell_label) %>%
    mutate(num_periods_cells = n_distinct(tp)) %>%
    mutate(repeated = case_when(
      num_periods_cells == 2 ~ 1,
      num_periods_cells %in% c(1, 2) ~ 0
    )) %>%
    ungroup() %>%
    group_by(dataset) %>%
    select(dataset, cell_grouping, cell_label, num_periods_cells, repeated) %>%
    unique()

  common_cells %>%
    group_by(dataset, cell_grouping, repeated, num_periods_cells) %>%
    summarise(n = n())

  presence_data_rep <- full_join(pres_dat2, common_cells)

  # Species sampled twice in the remaining cells
  common_sp <- presence_data_rep %>%
    filter(repeated == 1 & cell_grouping == 1) %>%
    group_by(dataset, verbatim_name) %>%
    summarise(num_periods_sp = n_distinct(tp)) %>%
    ungroup() 
  presence_data3 <- full_join(presence_data_rep, common_sp) 

  presence_data_all[[i]] <- presence_data3
}

saveRDS(presence_data_all, paste0(out_path, "rds/presence_data_all.rds"))

# Create list of spatial objects ==========================
presence_sf_list <- list()
for (a in seq_along(atlas_names)){
  grid <- grids[[a]]
  presence_data <- presence_data_all[[a]]
  presence_sf <- left_join(grid, presence_data)
  dd <- presence_sf %>% filter(dataset == atlas_names[a])
  presence_sf_list[[a]] <- dd 
  }

saveRDS(presence_sf_list, paste0(out_path, "rds/presence_sf_list.rds"))

# Big Table ================================
sp_df_big <- big_tab %>% 
  filter(cell_grouping == 1) %>% 
  select(-cell_grouping, -X, -scale) %>% 
  left_join(tax_lookup  %>% rename("verbatim_name" = "name_in_data") %>% distinct(verbatim_name, sp_BirdTree, sp_BirdLife, Birds.of.the.World))%>%
  left_join(RangeSizeNew %>% rename("verbatim_name" = "sci_name")) %>%
  filter_at(vars(log_R2_1), any_vars(!is.na(.))) %>% 
  full_join(Niches_df) %>% 
  distinct(verbatim_name, .keep_all=T) %>%
  filter(!is.na(verbatim_name))

sp_df_big %>% distinct(verbatim_name) %>% nrow() # 841 species 
colSums(is.na(sp_df_big)) #172 species without climate data


sp_wo_clim <- sp_df_big %>% filter(is.na(sd_PC1))

```

# Predictors

```{r, predictors}
# Make dataframes with predictors ======================
atlas_predictors_df2 <- big_tab %>% 
  select(dataset, Total_area, tp, grain) %>% 
  distinct()

predictors_df <- sp_df_big%>% 
  select(
    verbatim_name, dataset, tp, sp_BirdTree, sp_BirdLife, # Grouping variables
    log_R2_1, Telfer_1_2, # Response variables
    Total_area, Total_Ncells_samp, # Extent of the Arena
    relative_occupancy_Ncells, # Relative Occupancy
    D_AOO_a, # D of AOO based on mean area
    total_SR_atlas, #GammaRichness of Atlas
    sd_PC1, sd_PC2) 

# Vector with species names in predictor data ==================
sp_names_predictors <- predictors_df %>% distinct(verbatim_name) %>%  pull(verbatim_name) %>% as.vector()
write.csv(sp_names_predictors, paste0(out_path, "csv/sp_names_predictors_v2.csv")) 

```

# Save Environment until here

```{r}
# Save Environment until here
save.image(paste0(out_path, "RData/AtlasPredictors_1_v2.RData"))

```

================ RUN COMPLETELY UNTIL HERE AND THEN ONLY RUN CHUNKS WHERE OBJECTS ARE READ BACK IN ======================

## Diversity Metrics

```{r, eval = F, include = T}
## Calculate Diversity Measures ======================
GammaAlphaBeta_Atlas <- pres_dat_final %>%
  filter(cell_grouping == 1) %>%
  select(dataset, tp, cell_label, verbatim_name) %>% distinct() %>%
  group_by(dataset,tp) %>%
  mutate(GammaSR = sum(n_distinct(verbatim_name))) %>% ungroup() %>%
  group_by(dataset, tp, cell_label) %>%
  mutate(AlphaSR = sum(n_distinct(verbatim_name))) %>%
  mutate(BetaSR = GammaSR/AlphaSR)

GammaAlphaBeta_Species <- GammaAlphaBeta_Atlas %>%   
  ungroup() %>%
  group_by(dataset, tp, verbatim_name) %>%
  mutate(AlphaSR_sp = mean(AlphaSR)) %>%
  mutate(BetaSR_sp = GammaSR/AlphaSR_sp) %>%
  select(dataset, tp, verbatim_name, AlphaSR_sp, BetaSR_sp, GammaSR) %>% distinct()

## Calculate Mean Sampling Effort  ======================
AvgEffort <- pres_dat_final %>%
  filter(cell_grouping == 1) %>%
  select(dataset, tp, cell_label, verbatim_name, samp_effort_type, effort) %>% 
  distinct() %>%
  group_by(dataset, tp, verbatim_name) %>%
  summarize(avgEffort = mean(effort))

Diversity_Effort <- full_join(GammaAlphaBeta_Species, AvgEffort)
saveRDS(Diversity_Effort, paste0(out_path, "rds/Diversity_AvgEffort.rds"))

```

## Spatial Autocorrelation

This script takes several days to run for all atlases. Therefore I split the script and ran the calculations in parallel for all atlases at the same time. Output objects are merged in a separate script.

```{r, eval = F, include = T}
sf_use_s2(FALSE)
presence_data_all <- readRDS(paste0(out_path, "rds/presence_data_all.rds"))
# pacman::p_load("ncf")

morans_list <- list()
data_list <- list()

morans_list2 <- list()
data_list2 <- list()

morans_list3 <- list()
data_list3 <- list()


for (a in seq_along(atlas_names)){

  dd <- presence_data_all[[a]] %>% 
  ungroup() %>% 
  filter(cell_grouping == 1) %>% 
  select(dataset, tp, verbatim_name, area, area_cropped, cell_lat, cell_long, cell_label)
  
  for (y in seq_along(time_periods)){
    
    dd1 <- dd %>% filter(tp == time_periods[y]) %>% ungroup() %>% distinct() 
    sp_list <- unique(dd1$verbatim_name)
    
    for (s in seq_along(sp_list)){  
      print(paste("atlas =", unique(dd1$dataset), "tp =", unique(dd1$tp), "sp = ", sp_list[s], "N = ", s, "/", length(sp_list)))
      
      # Obtain a df for each species that indicates the presence (1) or absence (0) of the species
      
      data_species <- dd1 %>% 
        distinct(verbatim_name, cell_label, cell_lat, cell_long) %>% 
        ungroup() %>% unique() %>%
        mutate(
          verbatim_name = ifelse(verbatim_name != sp_list[s], NA, verbatim_name)) %>%
        group_by(across(-verbatim_name)) %>%
        slice(which.max(!is.na(verbatim_name))) %>% 
        distinct(verbatim_name, cell_label, .keep_all=T) %>%
        mutate(
          presence = ifelse(!is.na(verbatim_name), 1, 0)) %>% ungroup()
    

      data_reduced <- dd1 %>% 
        filter(verbatim_name == sp_list[s]) %>% 
        select(verbatim_name, dataset, tp, area, area_cropped) %>% 
        distinct() %>% 
        mutate(mean_area = mean(area),
          mean_area_cropped = mean(area_cropped),
          mean_cell_length = sqrt(mean_area)) %>% 
        mutate(
          increment2 = mean_cell_length * 1.75) %>% 
        ungroup() %>% 
        distinct(verbatim_name, .keep_all = T)
      
      data_species$increment <- data_reduced$increment2
          
        
      tryCatch({
        print("Attempting to calculate Moran's I")
        morans_cor <- correlog(x = data_species$cell_long, 
                         y = data_species$cell_lat, 
                         z = data_species$presence, 
                         latlon = TRUE, 
                         increment = unique(data_species$increment), 
                         resamp = 0)
  
        data_reduced$moran <- morans_cor$correlation[1]
        data_reduced$x_intercept <- morans_cor$x.intercept
  
        print("Moran's I calculated successfully")
        }, 
        error = function(e) {
          print("Error occurred while calculating Moran's I")
          print(paste("Error message:", e))
          morans_cor <- NA
          data_reduced$moran <- NA
          data_reduced$x_intercept <- NA
          })
      
      data_list[[s]] <- data_reduced
      morans_list[[s]] <- morans_cor 
      

    } # species loop closing
    
    morans_list2[[y]] <- morans_list
    
    data_df <- plyr::rbind.fill(data_list)
    data_list2[[y]] <- data_df
  
  } # year loop closing
  
    morans_list3[[a]] <- morans_list2
    
    data_df2 <- plyr::rbind.fill(data_list2)
    data_list3[[a]] <- data_df2
    
    } # atlas loop closing

data_df_all <- plyr::rbind.fill(data_list3) 
saveRDS(data_df_all, paste0(out_path, "rds/SAC_final.rds"))

```

## Characterize Geometries

(Function by Dr. Gabriel Ortega: requires terra & tidyverse)

```{r, geometries function from Gabriel, eval = F, include = T}
pacman::p_load(geosphere, geodata, terra, tidyverse, tidyterra)

# Function to get the max elongation per polygon, north-south length or east-west length, circularity, etc...
poly_attr <- function(x, type = NULL) {
  # Convert "sf" to SpatVector
  if (inherits(x, "sf") == T) {
    x <- vect(x)
  }
  # Reproject to WGS84. Currently, "terra" calculate distance in meters when given latitude and longitude points.
  x <- project(x, "epsg:4326")
  # Get East-West distance (longitudinal extension)
  if (type == "ewDist") {
    vert <- crds(as.points(ext(x)), df = T)
    dimNames <- list(c("point"),c("x","y"))
    sw <- matrix(c(min(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    se <- matrix(c(max(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    res <- distance(sw, se, lonlat = T)[[1]]
  }
  # Get South-North distance (latitudinal extension)
  if (type == "nsDist") {
    vert <- crds(as.points(ext(x)), df = T)
    dimNames <- list(c("point"),c("x","y"))
    sw <- matrix(c(min(vert[["x"]]), min(vert[["y"]])), ncol = 2, dimnames = dimNames)
    nw <- matrix(c(min(vert[["x"]]), max(vert[["y"]])), ncol = 2, dimnames = dimNames)
    res <- distance(sw, nw, lonlat = T)[[1]]
  }
  # Get max distance between opposite vertices
  if (type == "maxDist") {
    vert <- crds(as.points(convHull(x)))
    res <- distance(vert, lonlat = T) %>% max()
  }
  # Get elongation ratio along longest axis
  if (type == "elonRatio") {
    convexHull <- convHull(x)
    vert <- crds(as.points(convexHull), df = T)
    dist <- as.data.frame.table(as.matrix(distance(vert, lonlat = T)), responseName = "distance") %>%
      slice_max(., distance)
    axisPoints <- vert[c(dist[[1]][[1]],dist[[2]][[1]]),]
    axisPoints <- arrange(axisPoints, desc(y))
    rotation <- -1*bearing(axisPoints[2,],axisPoints[1,])
    rotHull <- spin(convexHull, rotation)
    ext <- ext(convexHull)
    df <- as.vector(distance(crds(as.points(ext)), lonlat = T))
    df <- sort(df)
    length <- mean(df[[3]], df[[4]])
    width <- mean(df[[1]], df[[2]])
    res <- 1 - (width / length)
    # res <- list()
    # res[["vert"]] <- vert
    # res[["dist"]] <- dist
    # res[["axispoints"]] <- axisPoints
    # res[["bearing"]] <- rotation
    # res[["rotHull"]] <- rotHull
  }
  # Circularity
  if (type == "circ") {
    perimeter <- perim(x)
    area <- expanse(x)
    res <- (perimeter^2) / area
  }
  # Normalized circularity
  if (type == "circNorm") {
    perimeter <- perim(x)
    area <- expanse(x)
    res <- (perimeter^2) / (4 * pi * area)
  }
  # Major length of the minimum rectangle
  if (type == "lengthMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle), df = T), lonlat = T))
    df <- sort(df)
    res <- mean(df[[3]], df[[4]])
  }
  # Width of the minimum rectangle
  if (type == "widthMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle), df = T), lonlat = T))
    df <- sort(df)
    res <- mean(df[[1]], df[[2]])
  }
  # Elongation ratio of minimal encasing rectangle (from here: Dražić, S., Ralević, N., & Žunić, J. (2010). Shape elongation from optimal encasing rectangles. Computers & Mathematics with Applications, 60(7), 2035–2042. https://doi.org/10.1016/j.camwa.2010.07.043)
  if (type == "elonMinRect") {
    minRectangle <- minRect(x)
    df <- as.vector(distance(crds(as.points(minRectangle)), lonlat = T))
    df <- sort(df)
    length <- mean(df[[3]], df[[4]])
    width <- mean(df[[1]], df[[2]])
    res <- 1 - (width / length)
  }
  # Related circumscribing circle
  if (type == "relCirc") {
    circle <- minCircle(x)
    areaCircle <- expanse(circle)
    area <- expanse(x)
    res <- 1-(area/areaCircle)
  }
  # Linearity index
  if (type == "lin") {
    hull <- convHull(x)
    df <- crds(as.points(hull), df = T)
    lm <- lm(y ~ x, data = df)
    res <- summary(lm)$r.squared
  }
  # North bearing of the minimum rectangle
  if (type == "bearingMinRect") {
    minRectangle <- minRect(x)
    df <- crds(as.points(minRectangle), df = T)
    cor <- cor(df[["x"]],df[["y"]])
    point1 <- slice_min(df, y)
    if (cor > 0){
      point2 <-slice_max(df, x)
    } else{
      point2 <-slice_min(df, x)
    }
    res <- bearing(point1, point2)
  }
    # Get bearing along longest axis
  if (type == "bearing") {
    convexHull <- convHull(x)
    vert <- crds(as.points(convexHull), df = T)
    dist <- as.data.frame.table(as.matrix(distance(vert, lonlat = T)), responseName = "distance") %>%
      slice_max(., distance)
    axisPoints <- vert[c(dist[[1]][[1]],dist[[2]][[1]]),]
    axisPoints <- arrange(axisPoints, desc(y))
    res <- bearing(axisPoints[2,],axisPoints[1,])
  }
  res <- as.numeric(res)
  return(res)
}
```

### Calculate Geometries:

This takes quite some time. Better read the objects back in below.

```         
10311.01 sec elapsed 
```

```{r, calculate geometries, message = F, eval = F, include = T}
tictoc::tic()
# Atlas Geometries ==============================================================
geom_ls <- list()

for (i in seq_along(grids)){
  
  Atlas_Geom <- grids[[i]] %>% 
    select(geom, cell_label) %>%
    summarise() %>% 
    terra::vect()
  
  Geom_attributes_atlas <- data_frame(dataset = atlas_names[i],
           atlas_nsDist = poly_attr(Atlas_Geom, "nsDist"),
           atlas_ewDist = poly_attr(Atlas_Geom, "ewDist"),
           atlas_maxDist = poly_attr(Atlas_Geom, "maxDist"),
           atlas_lengthMinRect = poly_attr(Atlas_Geom, "lengthMinRect"),
           atlas_widthMinRect = poly_attr(Atlas_Geom, "widthMinRect"),
           atlas_elonMinRect = poly_attr(Atlas_Geom, "elonMinRect"),
           atlas_elonRatio = poly_attr(Atlas_Geom, "elonRatio"),
           atlas_circ = poly_attr(Atlas_Geom, "circ"),
           atlas_circNorm = poly_attr(Atlas_Geom, "circNorm"),
           atlas_relCirc = poly_attr(Atlas_Geom, "relCirc"),
           atlas_lin = poly_attr(Atlas_Geom, "lin"),
           atlas_bearingMinRect = poly_attr(Atlas_Geom, "bearingMinRect"), 
           atlas_bearing = poly_attr(Atlas_Geom, "bearing"))
           
  ## Southernness/Westernness
  atlas_xmin <- st_bbox(Atlas_Geom)[1]
  atlas_ymin <- st_bbox(Atlas_Geom)[2]
  atlas_xmax <- st_bbox(Atlas_Geom)[3]
  atlas_ymax <- st_bbox(Atlas_Geom)[4]
  atlas_xhalf <- atlas_xmax+(atlas_xmin-atlas_xmax)/2
  atlas_yhalf <- atlas_ymax+(atlas_ymin-atlas_ymax)/2
  
  atlas_bbox <- data.frame(atlas_xmin, atlas_xmax, atlas_xhalf, atlas_ymin, atlas_ymax, atlas_yhalf)
  atlas_bbox$dataset <- atlas_names[i] 
  
  geom_ls[[i]] <- full_join(atlas_bbox, Geom_attributes_atlas)
  
}

countries_geom_attributes <- plyr::rbind.fill(geom_ls) 

# Transform country-borders to lines
lines_l <- list()

for (a in seq_along(grids)){
  lines <- grids[[a]] %>% 
    summarise() %>% 
    vect() %>% 
    as.lines()
  lines_l[[a]] <- lines
}

### For each species separately:

species_geom <- list()
year_species_geom <- list()
atlas_all_sp_geom <-list()
COG_all <- list()
COG_a <- list()

for (a in seq_along(presence_sf_list)){
  atlas <- presence_sf_list[[a]]
  
  for (y in seq_along(time_periods)){
    atlas_y <- atlas %>% filter(tp == time_periods[y])
    sp <- unique(atlas_y$verbatim_name)
    
    # Calculate Center of Gravity of all species per atlas
    COG <- atlas_y %>% st_drop_geometry() %>% summarise(CenterOfGravity_Atlas_long = mean(cell_long),
                                 CenterOfGravity_Atlas_lat = mean(cell_lat),
                                 dataset = unique(dataset))
    COG_all[[y]] <- COG

    points_COG_atlas <- COG %>% 
      dplyr::select(CenterOfGravity_Atlas_long, CenterOfGravity_Atlas_lat, dataset) %>%
      rename("x" = "CenterOfGravity_Atlas_long", "y" = "CenterOfGravity_Atlas_lat") %>% 
      na.omit() %>% 
      distinct()
    
    points_atlas <- points_COG_atlas %>% vect(geom = c("x", "y"), crs = "epsg:4326")
    
    for (s in seq_along(sp)){
      print(paste(atlas_names[a], time_periods[y], sp[s]))
      atlas_sp <- atlas_y %>% filter(verbatim_name == sp[s])
      
      ## Maybe I have to summarize here ! Not sure - let's try this and compare.
      COG_sp <- atlas_sp %>% 
        select(cell_long, cell_lat, verbatim_name, dataset, tp) %>%
        mutate(sp_COG_long = mean(cell_long), 
               sp_COG_lat = mean(cell_lat)) %>% 
        st_drop_geometry() %>% 
        select(-cell_long, -cell_lat) %>% 
        unique()
      
      points_COG_sp <- COG_sp %>%
        group_by(dataset, tp, verbatim_name) %>% 
        dplyr::select(sp_COG_long, sp_COG_lat, dataset, tp, verbatim_name) %>%
        rename("x" = "sp_COG_long", "y" = "sp_COG_lat") %>% na.omit() %>% ungroup()

      points2 <- points_COG_sp %>%
        vect(geom = c("x", "y"), crs = "epsg:4326")
            
      test <- atlas_sp %>% 
        select(geom, cell_label)%>% 
        summarise() %>% 
        vect() 
    
      ## Calculate distance 
      atlas_lines <- lines_l[[a]]
      Dist_toCOG <- terra::distance(crds(points2), crds(points_atlas), lonlat = T)
      minDist_toBorder_centr <- min(distance(crds(points2), crds(atlas_lines), lonlat=T))
      maxDist_toBorder_centr <- max(distance(crds(points2), crds(atlas_lines), lonlat=T))
      minDist_toBorder <- min(distance(crds(test), crds(atlas_lines), lonlat=T))
      maxDist_toBorder <- max(distance(crds(test), crds(atlas_lines), lonlat=T))
    
      Geom_attributes <- data_frame(dataset = atlas_names[a],
                                    tp = time_periods[y],
                                    verbatim_name = sp[s],
                                    nsDist = poly_attr(test, "nsDist"),
                                    ewDist = poly_attr(test, "ewDist"),
                                    maxDist = poly_attr(test, "maxDist"),
                                    lengthMinRect = poly_attr(test, "lengthMinRect"),
                                    widthMinRect = poly_attr(test, "widthMinRect"),
                                    elonMinRect = poly_attr(test, "elonMinRect"),
                                    elonRatio = poly_attr(test, "elonRatio"),
                                    circ = poly_attr(test, "circ"),
                                    circNorm = poly_attr(test, "circNorm"),
                                    relCirc = poly_attr(test, "relCirc"),
                                    lin = poly_attr(test, "lin"),
                                    bearingMinRect = poly_attr(test, "bearingMinRect"), 
                                    bearing = poly_attr(test, "bearing"),
                                    Dist_toCOD = Dist_toCOG,
                                    minDist_toBorder = minDist_toBorder,
                                    maxDist_toBorder = maxDist_toBorder,
                                    minDist_toBorder_centr = minDist_toBorder_centr,
                                    maxDist_toBorder_centr = maxDist_toBorder_centr)
        
        Geom_attributes2 <- full_join(Geom_attributes, COG_sp) %>% unique()
        
        species_geom[[s]] <- Geom_attributes2
        }
    
    species_geom_df <- plyr::rbind.fill(species_geom)  
    year_species_geom[[y]] <- species_geom_df  
    }
  COG_a[[a]] <- plyr::rbind.fill(COG_all)
  year_species_geom_df <- plyr::rbind.fill(year_species_geom) 
  atlas_all_sp_geom[[a]] <- year_species_geom_df
  }
COG_df <- plyr::rbind.fill(COG_a)
Species_geom_attributes <- plyr::rbind.fill(atlas_all_sp_geom) 

Atlas_geom <- full_join(countries_geom_attributes, COG_df) %>% group_by(dataset) %>% distinct(dataset, .keep_all=T)
Geometries <- full_join(Species_geom_attributes, Atlas_geom, relationship = "many-to-many") %>% distinct()

# Southerness/Westerness =================================
Southernness_Westernness <- Geometries %>% 
  group_by(dataset, tp, verbatim_name) %>% 
  select(dataset, tp, verbatim_name, sp_COG_long, sp_COG_lat, atlas_xmin, atlas_xmax, atlas_xhalf, atlas_ymin, atlas_ymax, atlas_yhalf) %>% 
  unique() %>%
  summarize(Southernness = 1-((sp_COG_lat - atlas_ymin)/((atlas_ymax -atlas_ymin))),
            Westernness = 1-((sp_COG_long - atlas_xmin)/((atlas_xmax-atlas_xmin)))) %>% ungroup() 

Geometries_final <- left_join(Geometries, Southernness_Westernness, relationship = "many-to-many") %>% distinct(dataset, tp, verbatim_name, .keep_all = T)

saveRDS(Geometries_final, paste0(out_path, "rds/Geometries.rds"))

```

## Co-Occurrence

Takes quite a while..

```{r, eval = F, include = T}
species_data <- pres_dat_final %>% 
  filter(cell_grouping == 1) %>% 
  select(dataset, tp, verbatim_name, cell_label) %>% 
  distinct()

# ----------------------------------------------------------- #
co_occ_list1<- list()
for (a in seq_along(atlas_names)){
  
  # create community dataframe
  species_data_a <- species_data %>% filter(dataset == atlas_names[a])
  comm_dat <- species_data_a %>% 
    group_by(tp) %>% 
    dplyr::select(tp, verbatim_name, cell_label) %>%
    ungroup() %>% 
    distinct()
  comm_dat <- as.data.frame(comm_dat)
  
  # Convert data frame to Species X sites matrix
  comm_matrix_tp1 <- fossil::create.matrix(comm_dat, 
                                           tax.name = "verbatim_name", 
                                           locality = "cell_label", 
                                           time.col = "tp", 
                                           time = "1", 
                                           abund = F)
  comm_matrix_tp2 <- fossil::create.matrix(comm_dat, 
                                           tax.name = "verbatim_name", 
                                           locality = "cell_label", 
                                           time.col = "tp", 
                                           time = "2", 
                                           abund = F)
  
  # Calculate probability of pairwise co-occurrence of species: ----------- #
  co_occurrence_tp1 <- cooccur::cooccur(comm_matrix_tp1, spp_names = T)
  print(length(unique(co_occurrence_tp1$spp.names))) # 206 species 
  co_occurrence_tp2 <- cooccur::cooccur(comm_matrix_tp2, spp_names = T)
  print(length(unique(co_occurrence_tp2$spp.names))) # 213 species
  
  co_occ_list1[[a]] <- list(co_occurrence_tp1, co_occurrence_tp2)
}

co_occ_list2 <-list()
for (a in seq_along(atlas_names)){
  species_data_a <- species_data %>% filter(dataset == atlas_names[a])
  species_data_a1 <- species_data_a %>% select(-cell_label) %>% distinct()

  res1 <- data.frame(co_occ_list1[[a]][[1]]$results) 
  res1 <- res1 %>% group_by(sp1_name) %>%
    mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "1") %>% 
    dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
    distinct()

  res2 <- data.frame(co_occ_list1[[a]][[2]]$results) 
  res2 <- res2 %>% group_by(sp1_name) %>%
    mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "2") %>% 
    dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
    distinct()
  
  results <- full_join(res1,res2)
  species_data_a1_2 <- merge(species_data_a1, results, by.x=c("verbatim_name", "tp"), by.y = c("sp1_name", "tp"), all = T)
  co_occ_list2[[a]] <- species_data_a1_2
}
 
Co_Occ_df_final <- plyr::rbind.fill(co_occ_list2)
saveRDS(Co_Occ_df_final, paste0(out_path, "rds/Coocc_df_final.rds"))

```

## AVONET Traits

```{r}

avonet_final[avonet_final=="<NA>"] <- NA
avonet_final <- avonet_final %>% filter(verbatim_name %in% unique(pres_dat_final$verbatim_name) )
avonet_final 
names(BOTW_RL)

avonet_final2 <- left_join(avonet_final, BOTW_RL)
colSums(is.na(avonet_final2))

avonet_final <- avonet_final2 %>% distinct(verbatim_name, .keep_all=T)
avonet_final %>% filter_all(any_vars(is.na(.))) # 6 Species without range size (and other data); 95 species without red list
avonet_final %>% filter_all(any_vars(!is.na(.))) %>% distinct(verbatim_name) %>% nrow() #774 species have data

saveRDS(avonet_final, paste0(out_path, "rds/AVONET_final_v2.rds"))

```

## Phylogenetic Distinctness

```{r}
FP <- phyloregion::evol_distinct(tree, "fair.proportion") # phylogenetic distinctness (Isaac et al., 2007).
FP <- data.frame(FP)
FP$tip.label <- rownames(FP)
rownames(FP) <- NULL
unique(FP$tip.label) %>% length() # 9993 species 
FP$verbatim_name <- gsub("_", " ", FP$tip.label)

write.csv(FP, paste0(out_path, "csv/EvolDistinctness.csv"))
```

# Merging Predictors together

## Species predictors

```{r}
predictors_df_clean <- predictors_df %>%
  filter(if_any(c(verbatim_name, dataset, tp,
                  log_R2_1, Telfer_1_2,
                  Total_area, Total_Ncells_samp,
                  relative_occupancy_Ncells, D_AOO_a,
                  total_SR_atlas),
                ~ !is.na(.))) %>% filter(!is.na(D_AOO_a))
saveRDS(predictors_df_clean, paste0(out_path, "rds/predictors_df1_clean.rds"))

predictors_df_clean <- readRDS(paste0(out_path, "rds/predictors_df1_clean.rds"))
colSums(is.na(predictors_df_clean))

predictors_df_clean <- predictors_df_clean %>% 
  filter(if_any(c(verbatim_name, dataset, tp, 
                  log_R2_1, Telfer_1_2, 
                  Total_area, Total_Ncells_samp, 
                  relative_occupancy_Ncells, D_AOO_a, 
                  total_SR_atlas), 
                ~ !is.na(.))) %>% filter(!is.na(D_AOO_a))

predictors_df_clean %>% group_by(dataset, tp) %>% summarise(n = n_distinct(verbatim_name))

# Diversity
Diversity_Effort <- readRDS(paste0(out_path, "rds/Diversity_AvgEffort.rds"))
predictors_df2 <- left_join(predictors_df_clean, Diversity_Effort); rm(Diversity_Effort)
colSums(is.na(predictors_df2))
#Geometries
Geometries <- readRDS( paste0(out_path, "rds/Geometries.rds"))
predictors_df3 <- left_join(predictors_df2, Geometries) 
colSums(is.na(predictors_df3))
# Co-Occurrence index
Co_Occ_df_final <- readRDS(paste0(out_path, "rds/Coocc_df_final.rds"))
predictors_df4 <- left_join(predictors_df3,Co_Occ_df_final) 
colSums(is.na(predictors_df4))

# Avonet
avonet_final <- readRDS(paste0(out_path, "rds/AVONET_final_v2.rds"))
predictors_df5 <- left_join(predictors_df4, avonet_final) %>% 
  distinct(verbatim_name, tp, dataset, .keep_all=T) 
colSums(is.na(predictors_df5))

# Evol. distinctness
FP <- read.csv(paste0(out_path, "csv/EvolDistinctness.csv"))
FP2 <- FP %>% filter(tip.label %in% tax_lookup$TipLabel) %>% rename("TipLabel" = "tip.label") %>% select(-verbatim_name)

FP3 <- left_join(FP2, tax_lookup %>% distinct(TipLabel, name_in_data)) %>% rename("verbatim_name" = "name_in_data")
predictors_df6 <- left_join(predictors_df5, FP3 %>% select(verbatim_name, FP)) %>% 
  select(-sp_BirdLife, -sp_BirdTree) %>% distinct(verbatim_name, dataset, tp, .keep_all=T)
colSums(is.na(predictors_df6))

# SAC
SAC_df <- readRDS(paste0(out_path, "rds/SAC_final.rds"))
SAC_df %>% filter(is.na(moran)) #9 rows with NAs in Moran: all in Czechia (both time periods)
SAC_df2 <- SAC_df %>% distinct(verbatim_name, dataset, tp, moran, x_intercept, increment2)
colSums(is.na(SAC_df2))
predictors_df7 <- left_join(predictors_df6, SAC_df2) %>% distinct(dataset, tp, verbatim_name, .keep_all = T)


colSums(is.na(predictors_df6))



```

## Atlas Predictors

```{r}
all_predictors0 <- full_join(predictors_df7, atlas_predictors_df2) 
str(all_predictors0)

rownames(all_predictors0) <- NULL
all_predictors0 <- all_predictors0 %>% 
distinct(verbatim_name, tp, dataset, .keep_all = T) %>%  filter(!is.na(verbatim_name))

saveRDS(all_predictors0, paste0(out_path, "rds/All_predictors.rds"))
save.image(paste0(out_path, "RData/Atlas_predictors_2.RData"))

```
