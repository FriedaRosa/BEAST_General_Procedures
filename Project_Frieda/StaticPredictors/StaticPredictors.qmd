---
title: "0_Data_preparation"
author: "Friederike WÃ¶lke"
format: html
editor: visual
---

# Predicting change from static patterns

In this project I want to look at different static patterns that describe the distribution of a species and could potentially used to predict temporal change

## Structure:

-   Data:

    -   Birds of CZ, Plants of CZ

    -   Birds of Europe, Plants of Europe

    -   IUCN global range maps for co-occurrence patterns, WCVP for Plant co-occurrences OR\
        BirdLife International range maps?

    -   AVONET trait data

        -   e.g. Dispersal: Hand-Wing-Index (HWI) (ref: flight-efficiacy: Weeks et al 2022: https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2435.14056)

    -   BirdTree (Jetz et al. 2012) Phylogeny to calculate a measure of phylogenetic distance/distinctiveness

## Set up libraries:

```{r}
#| message = F

# Spatial data ------------------------------- # 
library(sf)
library(raster)
library(stars)
library(terra)

# Standard data handling --------------------- #
library(readxl)
library(dplyr)
library(ggplot2) # plotting

# Community data ----------------------------- #
library(cooccur)
library(tidyr)
library(tibble)
library(fossil)
# library(vegan)

# Phylogeny handling ------------------------- #
library(ape)
#library(phyloregion)

## Machine Learning models ------------------- #
library(randomForest)
library(randomForestExplainer) # plotting
library(ranger)
library(gbm)
library(xgboost)
library(caret)
library(caretEnsemble)
library(pdp)
```

```{r clean environment}
rm(list=ls())
gc()

```

## Set up Variables:

-   source_path = path to Atlas

-   out_path = path to save output from R

-   data_path = filename of the data

-   grid_path = filename of the grid

-   tree_path = filename of phylogenetic tree to calculate phylo metrics

-   traits_path = filename of AVONET matched to BirdTree

```{r}
#| warning: false
#| message: false
#| label: Variables

# folder path to atlas data
source_path_country <- "c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Processed/Atlases/Replicated/Birds_Atlas_Czechia/"

# folder path to output folder
out_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/Project_Frieda/StaticPredictors/out/"

# folder to raw predictor data
predictors_path <- "~/PhD_Projects/StaticPredictors/Data/"

# create path to read in data and grids from variables
data_path_country <- paste0(source_path_country,"Birds_Atlas_Czechia_beast_data.rds")
grid_path_country <-  paste0(source_path_country,"Birds_Atlas_Czechia_grid.gpkg")

# create paths to read phylogenetic tree and traits for birds (BirdTree, AVONET)
tree_path <- paste0(predictors_path, "Weeks_et_at_2022/singe_bird_phylo.tre")
traits_path <- paste0(predictors_path, "AVONET/ELEData/TraitData/AVONET3_BirdTree.xlsx")
fractal_path <- "c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/Project_Frieda/out/Big_table.csv"
threat_path <- paste0(predictors_path, "European Red List of birds (2021)/EU_red_list_2021.csv")

```

### Read in data

```{r}

# Species distributions  ---------------------------------------------------------------------- #
species_data_country <- readRDS(data_path_country)
species_data_country$cell_grouping <- as.factor(species_data_country$cell_grouping)
species_data_country <- species_data_country %>% filter(cell_grouping == "1")

# Species Fractal Data ------------------------------------------------------------------------ #
fractal_df <- read.csv(fractal_path)

# phylogenetic tree --------------------------------------------------------------------------- #
tree <- ladderize(read.tree(tree_path))

# bird traits --------------------------------------------------------------------------------- #
avonet <- read_excel(traits_path, sheet = 2)
avonet$Range.Size <- as.numeric(avonet$Range.Size)

threat <- read.csv2(threat_path, header=T) %>% rename("IUCN_RL_EU21" = "IUCN.Red.List.category..Europe." , "IUCN_RL_UK21" = "IUCN.Red.List.category..EU27.UK.")
threat$IUCN_RL_EU21 <- as.factor(threat$IUCN_RL_EU21)

traits <- merge(avonet, threat, by.x="Species3", by.y="Scientific.Name", all = T)
str(traits)

# grid data------------------------------------------------------------------------------------ #
grid <- st_read(grid_path_country, layer = "cell1grid")

```

```{r, Subsetting, eval = F}
sp_list <- unique(fractal_df$verbatim_name)
length(sp_list) # 128 species with temporal change data



# ----------------------------------------------------------------- ===   CREATE SUBSET HERE    # 

# Sample subset of species                                                          
# set.seed(123)
# subset <- sample(sp_list, 50)
# species_data <- species_data_country %>% filter(verbatim_name %in% subset)
# fractal_df <- fractal_df %>% filter(verbatim_name %in% subset) %>% select(-X)
# traits <- traits %>% filter(Species3 %in% subset)
```

#### Manipulate the data / Calculate Phylogenetic Distinctness for each species (as fair proportion)

1.  create column in species data that matches the tip-label formating in the tree (here with "\_" between genus name and species epithet)
2.  Calculate evolutionary distinctness (fair proportion metric) (FD)
3.  extract Hand wing index (and range size?) from AVONET
4.  Rename and sort grid-sizes to match grid and data (from small to large grid)
5.  Create column for time periods (1-3 for CZ birds)
6.  Rename the spatial scale to a relative scale, where 1 indicates the largest grid size that covers the whole study 'arena' (in grid and data)
7.  Split the species data into time periods

#### Country Data === Predictors

```{r}

species_data <- species_data_country

# --------------------------------------------------------------------------------------------- #

# adjust species names in data to match those in the tree
species_data$tip.label <- gsub(" ", "_", species_data$verbatim_name)

FP <- evol_distinct(tree, "fair.proportion") # add column with phylogenetic distinctness (Isaac et al., 2007).
FP <- data.frame(FP)

rm(tree) # clean up environment, we don't need the phylogeny anymore
# --------------------------------------------------------------------------------------------- #

traits$tip.label <- gsub(" ", "_", traits$Species3)
traits2 <- traits %>% 
  dplyr::select(tip.label, Family3, Order3, "Hand-Wing.Index", "Range.Size", "IUCN_RL_EU21") %>% 
  filter(tip.label %in% species_data$tip.label)
length(unique(traits2$tip.label)) # trait data for 228 species (all sp in CZ)

traits3 <- merge(traits2, FP, by.x = "tip.label", by.y="row.names", all = T)

species_data3 <- merge(species_data, traits3, by = "tip.label", all.x = T)
length(unique(species_data3$tip.label)) # 237 species
species_data <- species_data3
str(species_data)
# --------------------------------------------------------------------------------------------- #

## add column for time period (tp) - Country
start_times <- sort(unique(species_data$start_year))
end_times <- sort(unique(species_data$end_year))

time_periods <- data.frame(start_year = start_times,
                           end_year = end_times, 
                           tp = seq_along(end_times))

species_data <- merge(species_data, time_periods, 
                       by=c("start_year", "end_year"), 
                       all.x=T)

# --------------------------------------------------------------------------------------------- #

species_data <- species_data %>%
    mutate(scale = 1/64)

# --------------------------------------------------------------------------------------------- #

species_data_merged <- merge(species_data, fractal_df, by = c("verbatim_name", "scale", "tp", "cell_grouping"))
species_data_merged <- unique(species_data_merged)

cell_columns <- c("area", "cell_label", "area_cropped", "cell_long", "cell_lat", "effort", "samp_effort_type")
species_data_merged_short <- species_data_merged %>% dplyr::select(!cell_columns) %>% distinct()

# --------------------------------------------------------------------------------------------- #

sp_dat1 <- species_data_merged %>% filter(tp == 1)
sp_dat2 <- species_data_merged %>% filter(tp == 2)
# sp_dat3 <- species_data_merged %>% filter(tp == 3)

# --------------------------------------------------------------------------------------------- #

# geopackage grid/characteristics of the 'arena':
grid <- grid %>%
    mutate(scale = 1/64,
           total_Ncells = length(unique(cell_label)),
           total_area = sum(area),
           total_area1s = sum(area1s),
           total_area2s = sum(area2s),
           total_area_cropped = sum(area_cropped)) %>%   
    unique()

# --------------------------------------------------------------------------------------------- #

```

##### Environmental predictors

\-- make sure they have the same crs

\-- make sure they are compatible with each other (package-wise)

```{r}
#| eval = FALSE


# Get some more predictors ==========
library(geodata)
library(climenv)

#tidyterra

links <- read.csv("~/PhD_Projects/StaticPredictors/Data/Chelsa_DL_1_2_24.txt", header= F)
links <- as.vector(links)

chelsa_list <- list()
for (i in seq_along(links$V1)){
  current_link <- links$V1[i]
  Chelsa <- rast(current_link)
  chelsa_list[[i]] <- Chelsa
}


# Elevation for CZ
# topography <- geodata::elevation_30s("CZ", predictors_path, mask=TRUE, subs="")
# saveRDS(topography, paste0(predictors_path, "CZ_topography.rds"))
topography <- readRDS(paste0(predictors_path, "CZ_topography.rds"))
plot(topography, main = "topography")

topography2 <- st_transform(topography,  
                             crs = st_crs(grid)) # the same CRS as the CZ_grids layer

# Landcover for CZ
landcover <- st_read(paste0(predictors_path, "CorineLandCover90s/")) #class(vect(landcover))
# plot(landcover, main = "landcover")

st_crs(landcover)
st_crop(landcover, topography)
# Land cover trees (global)
landcover2 <- geodata::landcover(var = "trees", path = paste0(predictors_path, "Corine2/"))


# CHELSA climate data for 1985-1989 and 2001-2003
### Placeholder ######

rastlist <- list.files(path = "~/PhD_Projects/StaticPredictors/Data/CHELSA", pattern='.tif$', all.files=TRUE, full.names=FALSE, recursive = T)

# Load all raster files in folder using rast
library(terra)

allrasters <- rgdal::readOGR(paste0("~/PhD_Projects/StaticPredictors/Data/CHELSA/", rastlist))
CZ_extent <- extend(topography)
CZ_chelsa <- crop(allrasters, topography, mask = T)


plot(CZ_chelsa)


# Convert the SpatRaster object to a stars object
library(stars)
stars <- st_as_stars(CZ_chelsa)

# Convert the stars object to an sf object
sf <- st_as_sf(stars)

plot(sf)
```

##### Co-occurrence as a predictor

```{r make community matrix}ce_extract}

# ----------------------------------------------------------- #

# create community dataframe
comm_dat <- species_data %>% 
  group_by(tp) %>% 
  dplyr::select(tp, verbatim_name, cell_label) %>%
  ungroup() %>% 
  distinct()
comm_dat <- as.data.frame(comm_dat)

# Convert data frame to Species X sites matrix

comm_matrix_tp1 <- fossil::create.matrix(comm_dat, 
                                         tax.name = "verbatim_name", 
                                         locality = "cell_label", 
                                         time.col = "tp", 
                                         time = "1", 
                                         abund = F)
comm_matrix_tp2 <- fossil::create.matrix(comm_dat, 
                                         tax.name = "verbatim_name", 
                                         locality = "cell_label", 
                                         time.col = "tp", 
                                         time = "2", 
                                         abund = F)

# comm_matrix_tp3 <- fossil::create.matrix(comm_dat, 
#                                          tax.name = "verbatim_name", 
#                                          locality = "cell_label", 
#                                          time.col = "tp", 
#                                          time = "3", 
#                                          abund = F)

# Calculate probability of pairwise co-occurrence of species: ----------- #

co_occurrence_tp1 <- cooccur(comm_matrix_tp1, spp_names = T)
length(unique(co_occurrence_tp1$spp.names)) # 206 species 
co_occurrence_tp2 <- cooccur(comm_matrix_tp2, spp_names = T)
length(unique(co_occurrence_tp2$spp.names)) # 213 species


# co_occurrence_tp3 <- cooccur(comm_matrix_tp3, spp_names = T, thresh = T)

# co_occ_list <- list(co_occurrence_tp1, co_occurrence_tp2)
# saveRDS(co_occ_list, paste0(out_path, "co_occurrence_matrices.rds"))


# Some summaries -------------------------------------------------------- #

summary(co_occurrence_tp1)
prob.table(co_occurrence_tp1)
plot(co_occurrence_tp1, cex.axis = 0.5)
pair.profile(co_occurrence_tp1)
obs.v.exp(co_occurrence_tp1)


str(co_occurrence_tp1)

res1 <- data.frame(co_occurrence_tp1$results) #205 species
res1 <- res1 %>% group_by(sp1_name) %>%
  mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "1") %>% 
  dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
  distinct()

sp_dat1_2 <- merge(sp_dat1, res1, by.x=c("verbatim_name", "tp"), by.y = c("sp1_name", "tp")) # 128 species

res2 <- data.frame(co_occurrence_tp2$results) #212 species
res2 <- res2 %>% group_by(sp1_name) %>%
  mutate(mean_prob_cooccur = mean(prob_cooccur), tp = "2") %>% 
  dplyr::select(sp1_name, mean_prob_cooccur, tp) %>% 
  distinct()
sp_dat2_2 <- merge(sp_dat2, res2, by.x=c("verbatim_name", "tp"), by.y = c("sp1_name", "tp")) # 127 species
```

##### IUCN Rangemaps + Threat status download

\-- requires API token (website did not work)

```{r}
# install.packages("rredlist")
# library(rredlist)
# 
# rl_search(name = sp_list[[1]])
```

##### Continental Data

```{r, Continent data}

# species_data_continent <- readRDS(data_path_continent)
# layers_continent <- st_layers(grid_path_continent)$name

# grid_list_continent <- sapply(layers_continent, function(i) {
#   st_read(grid_path_continent, paste(i), quiet = TRUE)
# }, simplify = FALSE)
# species_data_continent <- merge(species_data_continent, FP, by.x = "tip.label", by.y="row.names", all.x=T)
# species_data_continent <- merge(species_data_continent, avonet, by = "tip.label", all.x=T)
# layers_continent <- unique(species_data_continent$cell_grouping)
# desired_levels_data_continent <- factor(layers_continent, 
#                          ordered = T, 
#                          levels = c("cell1grid", "cell2grid", 
#                                     "cell4grid", "cell8grid", 
#                                     "cell16grid", "cell32grid", 
#                                     "cell64grid", "cellfullgrid")) 
# 
# species_data_continent <- species_data_continent %>%
#   mutate(cell_grouping = factor(cell_grouping, 
#                                 levels = desired_levels_data_continent))
# ## add column for time period (tp) - Continent
# start_times <- sort(unique(species_data_continent$start_year))
# end_times <- sort(unique(species_data_continent$end_year))
# 
# time_periods <- data.frame(start_year = start_times,
#                            end_year = end_times, 
#                            tp = seq_along(end_times))
# 
# species_data_continent <- merge(species_data_continent, time_periods, 
#                        by=c("start_year", "end_year"), 
#                        all.x=T)
# species_data_continent <- species_data_continent %>% mutate(
#       scale = case_when(
#         cell_grouping == as.character(desired_levels_data[1]) ~ 1/128,        
#         cell_grouping == as.character(desired_levels_data[2]) ~ 1/64,
#         cell_grouping == as.character(desired_levels_data[3]) ~ 1/32,
#         cell_grouping == as.character(desired_levels_data[4]) ~ 1/16,
#         cell_grouping == as.character(desired_levels_data[5]) ~ 1/8,
#         cell_grouping == as.character(desired_levels_data[6]) ~ 1/4 ,
#         cell_grouping == as.character(desired_levels_data[7]) ~ 1/2,
#         cell_grouping == as.character(desired_levels_data[8]) ~ 1)) %>% 
#   unique()

# # CONTINENT
# 
# layers_continent <- st_layers(grid_path_continent)$name
# 
# desired_levels_grid_continent <- factor(layers, 
#                          ordered = T, 
#                          levels = c("cell1grid", "cell2grid", 
#                                     "cell4grid", "cell8grid", 
#                                     "cell16grid", "cell32grid", 
#                                     "cell64grid", "cell128grid")) 
# 
# # grid data
# grid_list_continent <- sapply(layers_continent, function(i) {
#   st_read(grid_path_continent, paste(i), quiet = TRUE)
# }, simplify = FALSE)
# 
# # add scale column to the grid
# for (i in seq_along(grid_list_continent)) {
#   grid_list_continent[[i]] <- grid_list_continent[[i]] %>% mutate(
#       scale = case_when(
#         cell_grouping == as.character(desired_levels_grid_continent[1]) ~ 1/64,
#         cell_grouping == as.character(desired_levels_grid_continent[2]) ~ 1/32,
#         cell_grouping == as.character(desired_levels_grid_continent[3]) ~ 1/16,
#         cell_grouping == as.character(desired_levels_grid_continent[4]) ~ 1/8,
#         cell_grouping == as.character(desired_levels_grid_continent[5]) ~ 1/4 ,
#         cell_grouping == as.character(desired_levels_grid_continent[6]) ~ 1/2,
#         cell_grouping == as.character(desired_levels_grid_continent[7]) ~ 1)) %>% 
#   unique()
# }

```

##### Drop Species from Tree ?

```{r, drop tips from tree}
# # for each time period separately:
# # a) extract species lists for each time period
# sp_list_df1 <- sp_dat1  %>% distinct(tip.label)
# sp_list_df2 <- sp_dat2  %>% distinct(tip.label)
# sp_list_df3 <- sp_dat3  %>% distinct(tip.label)
# 
# # b) create list of species not in the data (to drop them from the tree)
# sp.drop.tree1 <- setdiff(tree$tip.label, sp_list_df1$tip.label)
# sp.drop.tree2 <- setdiff(tree$tip.label, sp_list_df2$tip.label)
# sp.drop.tree3 <- setdiff(tree$tip.label, sp_list_df3$tip.label)
# 
# # c) create list of species not in the tree
# sp.drop.data1 <- setdiff(sp_list_df1$tip.label, tree$tip.label) 
# sp.drop.data2 <- setdiff(sp_list_df2$tip.label, tree$tip.label) 
# sp.drop.data3 <- setdiff(sp_list_df3$tip.label, tree$tip.label) 
# 
# 
# # --------------------------------------------------------------------------------------------- #
# # drop species from tree (not in data):
# # -- time period 1 -- #
# tree1 <- drop.tip(tree, sp.drop.tree1)
# tree1 <- ladderize(tree1)
# # -- time period 2 -- #
# tree2 <- drop.tip(tree, sp.drop.tree2)
# tree2 <- ladderize(tree2)
# # -- time period 3 -- #
# tree3 <- drop.tip(tree, sp.drop.tree3)
# tree3 <- ladderize(tree3)
# 
# 
# # --------------------------------------------------------------------------------------------- #
# # drop species from data (not in tree)
# # -- time period 1 -- #
# sp_dat1 <- sp_dat1 %>% filter(verbatim_name %in% sp.drop.data1)
# # -- time period 2 -- #
# sp_dat2 <- sp_dat2 %>% filter(verbatim_name %in% sp.drop.data2)
# # -- time period 3 -- #
# sp_dat3 <- sp_dat3 %>% filter(verbatim_name %in% sp.drop.data3)

```

## Random Forest models

-   Explanation minimum depth =\
    In a **random forest model**, the **minimum depth** refers to the minimum number of nodes that a decision tree must have before it is considered for splitting. [This parameter is used to control the complexity of the decision trees in the forest and prevent overfitting ^1^](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).

-   The `randomForestSRC` package in R provides a variable selection approach based on a tree-based concept called **minimal depth**. [This approach captures the essence of variable importance measures, but because it involves no randomization, and is simpler to calculate, it can be used as a theoretical basis for variable selection and for speedier calculations for large data ^2^](https://www.randomforestsrc.org/articles/minidep.html).

```{r, make model dfs}

# Create model dataframe --------------------------------------------------------------------- #
model_df <- sp_dat1_2 %>% 
  group_by(verbatim_name) %>% 
  dplyr::select(-cell_grouping, -start_year, -end_year, -tip.label, -dataset, -license, -taxa, -scale, 
                -tp, -X, -Telfer_1_2, -Telfer_2_3, -Telfer_1_3, 
                -log_R3_2, -log_R3_1, -samp_effort_type, -D) %>%
  mutate(mean_area = mean(area),
            mean_area_cropped = mean(area_cropped),
            mean_cell_long = mean(cell_long),
            mean_cell_lat = mean(cell_lat),
         mean_effort = mean(effort)) %>% 
  dplyr::select(-area, -area_cropped, -cell_label, -cell_long, -cell_lat, -effort) %>% 
  ungroup() %>%
  distinct(.)



model_df <- model_df %>% rename("HWI" = "Hand-Wing.Index") 

model_df$Family3 <- as.factor(model_df$Family3)
model_df$Order3 <- as.factor(model_df$Order3)
model_df$Range.Size <- as.numeric(model_df$Range.Size)



# --------------------------------------------------------------------------------- #
# Data partitioning =====
set.seed(123)

samp <- sample(nrow(model_df), 0.8 * nrow(model_df))
train <- model_df[samp, ]; dim(train) # 102 species
test <- model_df[-samp, ]; dim(test) # 26 species


```

```{r, randomForest package}
# --------------------------------------------------------------------------------- #
# Model 1 using randomForest package ====
sp.rf <- readRDS(paste0(out_path, "randomForest_model.rds"))

## mtry
## number of observations in the terminal group = number of splits (check default: 5-10) Do not get finer

sp.rf <- randomForest(log_R2_1 ~ ., data=train, ntree=50000, mtry=8, importance=TRUE, proximity=TRUE, na.action = na.omit, localImp = TRUE) 

sp.rf 
# saveRDS(sp.rf, paste0(out_path, "randomForest_model.rds"))

min_depth_frame <- min_depth_distribution(sp.rf)
plot_min_depth_distribution(min_depth_frame)

# Variable importance =====
round(sp.rf$importance,3)
varImpPlot(sp.rf)

impt_frame <- measure_importance(sp.rf)
plot_multi_way_importance(impt_frame)

# Prediction ====
prediction <- predict(sp.rf, newdata = test)
# table(prediction, test$log_R2_1)
# prediction
# ---------------------------------------------------------------------------- #
data_mod <- data.frame(Predicted = predict(sp.rf, newdata = test),  # Create data for ggplot2
                       Observed = test$log_R2_1)

ggplot(data_mod, aes(x = Predicted, y = Observed)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1,
              color = "red",
              lwd = 0.7)

```

```{r, ranger package}
# ----------------------------------- #
train <- train %>% na.omit(); dim(train)
test <- test %>% na.omit(); dim(test)

# Model 2 using ranger package ====
#install.packages("ranger")
library(ranger)

rf2 <- ranger(log_R2_1 ~ ., data=train, importance = "permutation", tuneGrid = data.frame(mtry = ceiling((ncol(test)-1)/3), splitrule = "variance", min.node.size = 5))
pred <- predict(rf2, data = test)
# table(test$log_R2_1, pred$predictions)

rf2
rf2$variable.importance
data_mod2 <- data.frame(prediction = predict(rf2, data = test),  # Create data for ggplot2
                       Observed = test$log_R2_1)
library(ggplot2)
ggplot(data_mod2, aes(x = prediction, y = Observed)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1,
              color = "red",
              lwd = 0.7)


```

##### Different rf model approach

```{r}
library(caret)
library(caretEnsemble)
library(ranger)
library(vip)
library(lmerTest)


names_v <- names(train)
names_v <- names_v[-21]



#traindata <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

train$RS_scaled <- scales::rescale(train$Range.Size, to = c(0, 1))
train$AOO_scaled <- scales::rescale(train$AOO, to = c(0, 1))
train$occu_Ncells_scaled <- scales::rescale(train$occupancy_Ncells, to = c(0, 1))
train$mean_area_scaled <- scales::rescale(train$mean_area, to = c(0, 1))
train$mean_area_cropped_scaled <- scales::rescale(train$mean_area_cropped, to = c(0, 1))
train$mean_effort_scaled <- scales::rescale(train$mean_effort, to = c(0, 1))




lmer_model <- lmerTest::lmer(log_R2_1 ~ HWI + FP + b_AOO + AOO_scaled + IUCN_RL_EU21 + RS_scaled +
                           occu_Ncells_scaled + relative_occupancy_Ncells + mean_prob_cooccur * 
                           mean_area_scaled * mean_area_cropped_scaled * mean_effort_scaled + 
                           (1 | Order3 / Family3), 
                         data = train)

summary(lmer_model)

round(summary(lmer_model)$coefficient,3)


# ------------------------------------------------------------ #

model_list_tp1 <-
  caretList(
    log_R2_1 ~ ., 
    data = train,
    #trControl = traindata,
    metric = "RMSE",
    tuneList = list(
      rf =  caretModelSpec(method = "ranger", 
                           importance = "permutation",
                           tuneGrid = data.frame(mtry = ceiling((ncol(model_df)-1)/3),
                                                                    splitrule = "variance",
                                                                    min.node.size = 5)),
      gbm = caretModelSpec(method = "gbm",
                           distribution = "gaussian",
                           # keep.data = TRUE,
                           tuneGrid = data.frame(n.trees = 500,
                                                 interaction.depth = 1,
                                                 shrinkage = 0.1,
                                                 n.minobsinnode = 5)),
      xgboost = caretModelSpec(method = "xgbTree",
                               tuneGrid = expand.grid(nrounds = 500,
                                                     max_depth = 5,
                                                     eta = 0.1,
                                                     gamma = 0,
                                                     colsample_bytree = 1,
                                                     min_child_weight = 1,
                                                     subsample = 1))
    )
  )


vip(model_list_tp1[[1]], geom = "point", num_features = 25)
vip(model_list_tp1[[3]], geom = "point", num_features = 25)
saveRDS(model_list_tp1, paste0(out_path, "model_list_tp1.rds"))


```

```{r}

library(pdp)


# Figure 2 (right)
model_list_tp1[[1]] %>% # the %>% operator is read as "and then"
partial(pred.var = "m_AOO") %>%
plotPartial(smooth = TRUE, lwd = 2, ylab = "average predicted temporal change")


model_list_tp1[[3]] %>% # the %>% operator is read as "and then"
partial(pred.var = "FP") %>%
plotPartial(smooth = TRUE, lwd = 2, ylab = "average predicted temporal change")

pp1 <- partial(model_list_tp1[[1]], pred.var = c(names_v[1:3]), plot=F)
pp2 <- partial(model_list_tp1[[1]], pred.var = c(names_v[4:6]), plot=F)
pp3 <- partial(model_list_tp1[[1]], pred.var = c(names_v[7:9]), plot=F)
pp4 <- partial(model_list_tp1[[1]], pred.var = c(names_v[10:12]), plot=F)
pp5 <- partial(model_list_tp1[[1]], pred.var = c(names_v[13:15]), plot=F)
pp6 <- partial(model_list_tp1[[1]], pred.var = c(names_v[16:18]), plot=F)
pp7 <- partial(model_list_tp1[[1]], pred.var = c(names_v[19:21]), plot=F)

partialPlotlist <- list(pp1,pp2,pp3,pp4,pp5,pp6,pp7)

```

```{r}
autoplot(model_list_tp1)
```
