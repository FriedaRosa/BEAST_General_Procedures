---
title: "0_2_Climate_Niche_prep"
date: "2024-03-15"
output:
  html_document:
    code_folding: hide
format:
  html:
    toc: true
    number-sections: true
    colorlinks: true
---

## Libraries

```{r, message = F}
rm(list=ls())
gc()
library(sf)
sf_use_s2(FALSE)
library(terra)
library(dplyr)
library(ggplot2)
library(ggfortify)



### require dependencies to be installed (see GitHub of these packages):
pacman::p_load(rasterSp, climateNiche) 

```

## Variables

```{r}

source_Git <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/GitHub/BEAST_General_Procedures/Project_Frieda/StaticPredictors/")

# folder path to output folder
out_path <- c(paste0(source_Git, "out/"))
source_predictors <- c("c:/Users/wolke/OneDrive - CZU v Praze/Dokumenty/PhD_Projects/StaticPredictors/Data/")
CHELSA_path <- paste0(source_predictors, "Chelsa_Bio_PET/")
# CGIAR_path <- paste0(source_predictors, "CGIAR_PET/")

name_vector <- read.csv2(paste0(out_path, "csv/AVONET_Final.csv"))[,2] %>% unique()

# List all the .tif files in the directory
tif_files <- list.files(path=CHELSA_path, pattern = ".tif$")
# The input file geodatabase from BirdLife International
fgdb <-"c:/Users/wolke/OneDrive - CZU v Praze/Datasets/Raw/Distributions/Birds_of_the_world/BOTW.gdb"

Tax <- st_read(fgdb, layer = "Taxonomic_checklist") %>% 
  select(Order_, FamilyName, ScientificName, RL_Category, Synonyms) %>% 
  rename("Order" = "Order_") %>%
  mutate(Order = stringr::str_to_sentence(Order))

write.csv(Tax, paste0(out_path, "csv/BOTW_TaxChecklist.csv"))
rm(Tax)

```

## Read + Aggregate CHELSA

```{r}
sf_use_s2(FALSE)
climate_stack <- rast(paste0(CHELSA_path, tif_files))
# Define the target resolution in meters
target_resolution <- c(110)  # 10x10km
  
# Aggregate the raster stack to the target resolution
climate_stack_agg <- aggregate(climate_stack, ## This takes a couple of minutes.
                               fact = target_resolution, 
                               fun = mean)
saveRDS(climate_stack_agg, paste0(out_path, "rds/climate_stack_agg.rds"))
```

## BirdLife International Range maps

Reduce range maps to

-   species in the data

-   columns needed for the analysis

Merge with taxonomic information

```{r, eval = F, include = T}
# Read BirdLife RangeMaps for all species in the geodatabase: Takes ~ 30 minutes to read in

# All_sp <- st_read(fgdb, layer = "All_Species") 
# saveRDS(All_sp, paste0(out_path, "rds/BOTW_All_species.rds")) # save this as rds which is faster to read in.

All_sp <- readRDS(paste0(out_path, "rds/BOTW_All_species.rds"))
# unique(All_sp$sci_name) %>% write.csv(paste0(out_path, "csv/BOTW_all_sp_names.csv"))

intersect(All_sp$sci_name, name_vector) #738 species of 839 total

BirdLife <- All_sp %>% 
  #filter(sci_name %in% name_vector) %>% 
  select(sci_name, presence, origin, seasonal, Shape_Length, Shape_Area, Shape) %>%
  filter(seasonal %in% c(1,2) & # Resident & Breeding Season (not non-breeding or passage)
           origin %in% c(1,2) & # Native or reintroduced (not introduced or vagrant)
           presence %in% c(1,2,3))  # Extant, probably extant, possibly extant (not possibly extinct or extinct)

# Calculate global range size for each species
sp <- unique(BirdLife$sci_name)
RangeSizeList <- list()
for (s in seq_along(sp)){
  temp <- BirdLife %>% filter(sci_name == sp[s]) %>% select(sci_name)
  
  temp$GlobRangeSize_m2 <- as.numeric(st_area(temp))
  temp$GlobRangeSize_km2 <- temp$GlobRangeSize_m2/1000
  temp2 <- temp %>% st_drop_geometry()
  temp2 <- temp2 %>% 
    group_by(sci_name) %>% 
    mutate(
      GlobRangeSize_m2 = case_when(
        nrow(temp2) > 1 ~ sum(GlobRangeSize_m2),
        nrow(temp) == 1 ~ GlobRangeSize_m2),
      GlobRangeSize_km2 = case_when(
        nrow(temp2) > 1 ~ sum(GlobRangeSize_km2),
        nrow(temp) == 1 ~ GlobRangeSize_km2))
  
  RangeSizeList[[s]] <- temp2[1,]
  
}

RangeSizeBOTW <- plyr::rbind.fill(RangeSizeList)
saveRDS(RangeSizeBOTW, paste0(out_path, "rds/RangeSizeBOTW_df.rds"))


tax_lookup2 <- read.csv2(out_path, paste0("csv/Tax_lookup_BirdLife_eBird_BirdTree_AtlasBOTW.csv"))
BirdLife %>% filter(sci_name %in% Tax_lookup$sp_atlas_adapted) %>% st_drop_geometry() %>% distinct(sci_name) %>% nrow() #738
BirdLife %>% filter(sci_name %in% unique(Tax_lookup$verbatim_name)) %>% st_drop_geometry() %>% distinct(sci_name) %>% nrow() #733
BirdLife %>% filter(sci_name %in%unique(Tax_lookup$sp_BirdTree)) %>% st_drop_geometry() %>% distinct(sci_name) %>% nrow() #657
BirdLife %>% filter(sci_name %in% unique(Tax_lookup$sp_BirdLife)) %>% st_drop_geometry() %>% distinct(sci_name) %>% nrow() #827

name_vector <- tax_lookup %>% distinct(sp_BirdLife) %>% na.omit() %>% as.vector()
BirdLife %>% filter(sci_name %in% unique(Tax_lookup$sp_BOTW)) %>% st_drop_geometry() %>% distinct(sci_name) %>% nrow()#738

BL_reduced <- BirdLife %>% filter(sci_name %in% unique(Tax_lookup$sp_BirdLife)) 


saveRDS(BL_reduced, paste0(out_path, "rds/BirdLife_reduced.rds"))
st_write(BL_reduced, paste0(out_path, "SpeciesData_climateNiche/BirdLife.shp"), append=F)

```

# Species Niches via PCA

```{r}

climate_stack_agg <- readRDS(paste0(out_path, "rds/climate_stack_agg.rds"))
range(climate_stack_agg)
pca_res <- prcomp(climate_stack_agg, scale. = T)
summary(pca_res)
# pca_res$rotation %>% write.csv(paste0(out_path, "csv/PCA_loadings_climNiche.csv"))


# Rasterize species range polygons  ======================================================
# Takes about 29 minutes for 827 species
# r_birds <- rasterizeRange(dsn=paste0(out_path, "SpeciesData_climateNiche/BirdLife.shp"),
#                           id="sci_nam", touches=TRUE, save = TRUE,
#                           path = paste0(out_path, "SpeciesData_climateNiche/sp_rasters/"))



## Read bird shapefiles back in ===========================================================
sp_v <- stringr::str_split(list.files(paste0(out_path, "SpeciesData_climateNiche/sp_rasters/")), 
                           pattern = "_0.5.tif")
sp_v <- do.call(rbind, sp_v)[,1] 
sp_v <- gsub("_", " ", sp_v)
name_vector <- name_vector$sp_BirdLife
setdiff(name_vector, sp_v)

r_birds <- rast(paste0(out_path, "SpeciesData_climateNiche/sp_rasters/", 
                       list.files(paste0(out_path, "SpeciesData_climateNiche/sp_rasters/"), 
                                  pattern =".tif")))
names(r_birds) <- sp_v

# Extract species coordinates ===========================================================
try({
coords_sp <- list()
for(i in seq_along(sp_v)){
  r_b <- r_birds[[i]]

  # Match resolution, extent, and projection of climate raster to species raster
  r_b_matched <- project(r_b, climate_stack_agg,  method = "average")
  
  r_b2 <- as.data.frame(r_b_matched, xy=T)
  r_b2$species <- sp_v[i]
  r_b3 <- r_b2 %>% rename("Presence" = sp_v[i])
  coords_sp[[i]] <- r_b3
}
})

coords_df <- do.call(rbind,coords_sp)


# Loop through species to extract climate values  ======================================
sp_v <- unique(coords_df$species)
clim_vals_list <- list()
pca_all <- list()
for (i in seq_along(sp_v)){
  
  sp <- coords_df %>% filter(species == sp_v[i]) %>% select(-species, -Presence)
  clim_vals <- extract(climate_stack_agg, sp, xy=T, df=T) %>% data.frame()
  clim_vals$species = sp_v[i]
  clim_vals_list[[i]] <- clim_vals
  
  # PCA predictions:  ===========================================================
  sp_pca <- predict(pca_res, clim_vals[,2:14])[,1:2] %>% data.frame() %>% mutate(species = sp_v[i])

  pca_all[[i]] <- sp_pca
  
}


clim_vals_all <- do.call(rbind, clim_vals_list) 

# Checking NAs #
clim_vals_all %>% filter_all(any_vars(!is.na(.))) %>% distinct(species) %>% nrow() # non-NAs for 827 species
clim_vals_all %>% filter_all(any_vars(is.na(.))) %>% distinct(species) %>% nrow() # NAs for 89 species

# Save Objects #
saveRDS(clim_vals_all, paste0(out_path, "rds/species_climate_df.rds"))
saveRDS(pca_all, paste0(out_path, "rds/pca_all.rds"))

# Plot Climate Space for a couple of species # 
library(ggplot2); library(ggfortify)
ggplot()+
  geom_point(aes(x=PC1, y=PC2), col = "black", data= pca_res)+
    geom_point(aes(x=PC1, y=PC2), col = "#fde725", alpha = 0.6, data = pca_all[[1]])+
    geom_point(aes(x=PC1, y=PC2), col = "#5ec962", alpha = 0.4, data = pca_all[[2]])+
    geom_point(aes(x=PC1, y=PC2), col = "#21918c", alpha = 0.3, data = pca_all[[3]])+
    geom_point(aes(x=PC1, y=PC2), col = "#3b528b", alpha = 0.2, data = pca_all[[4]])+
    geom_point(aes(x=PC1, y=PC2), col = "#440154", alpha = 0.3, data = pca_all[[5]])+
  theme_bw()
  

```

### Extract Niche Breadths (PC1, PC2) per species

```{r}


pca_all <-  readRDS(paste0(out_path, "rds/pca_all.rds")) # Predicted values in PCA for species
all_niches <- list()
# Calculate niche breadth
for (i in seq_along(pca_all)){
  niche_breadth2 <- apply(pca_all[[i]][,1:2], 2, sd, na.rm=T) 
  # Create a data frame with species and corresponding variance and standard deviation
  niche_breadth <- data.frame(
    species = unique(pca_all[[i]]$species),
    sd_PC1 = niche_breadth2[1],
    sd_PC2 = niche_breadth2[2])
  all_niches[[i]] <- niche_breadth
}


Niches_df<-  plyr::rbind.fill(all_niches)[,1:3]%>% rename("verbatim_name" = "species") 

Niches_df$verbatim_name = gsub("_", " ",Niches_df$verbatim_name)
saveRDS(Niches_df, paste0(out_path, "rds/Niches_df.rds"))

ggplot()+
  geom_point(data = Niches_df, aes(x = sd_PC1, y = sd_PC2, col = verbatim_name), show.legend = F) +
  theme_bw()
 
```
