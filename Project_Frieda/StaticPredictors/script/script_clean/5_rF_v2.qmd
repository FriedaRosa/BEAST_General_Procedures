---
title: "Random Forest Models"
author: "Friederike WÃ¶lke"
date: "2024-04-25"
output:
  html_document:
    code_folding: hide
format:
  html:
    toc: true
    number-sections: true
    colorlinks: true
---

# Clean Environment

```{r}
rm(list=ls())
gc()
```

# Libraries

```{r}
pacman::p_load("caret", "caretEnsemble", "ranger", "dplyr")
```

# Data

```{r}
dat <- readRDS("../../out/rds/Final_data.rds")
names(dat)
```

## Pre-Processing

```{r}
## Exclude columns:
exclude_vars <- c("m_AOO_a", "Total_area", "Total_Ncells", "rel_occ_Ncells", "Gamma", "Range.Size", "GlobRangeSize_m2", "mean_cell_length", "increment2", "RL_Category", "atlas_xmax", "area", "b_AOO_a", "mean_relAOO", "occ_Ncells", "mean_prob_cooccur")

atlas_vars <- c("Total_area_samp", "GammaSR", "mean_area", "atlas_lengthMinRect", "atlas_widthMinRect", "atlas_elonMinRect", "atlas_circ", "atlas_bearingMinRect", "atlas_bearing")

df2 <- dat %>% select(!all_of(c(exclude_vars, atlas_vars))) %>% distinct(dataset, tp, verbatim_name, .keep_all = T)
names(df2)

df3 <- df2 %>% 
group_by(dataset, tp, verbatim_name) %>% 
mutate(
    D_AOO_a = case_when(is.na(D_AOO_a) ~ 2,
    .default = D_AOO_a),
    IUCN = case_when(is.na(IUCN) ~ "DD", 
    .default = IUCN))

df3
table(df3$IUCN)
colSums(is.na(df3))

# Dropping NAs as they are few
model_df <- df3 %>% na.omit()
```

```{r}
# Create grouping variables for modelling in loop:
cols <- names(model_df) # 47 vars (incl. 2x response + verbatim_name)

# Response:
cols_logR <- cols[-which(cols == "Telfer_1_2")]
cols_telfer <- cols[-which(cols == "log_R2_1")]

# Group for predictor columns:
# Geometry
cols_g1 <- c("D_AOO_a", # Fractal dimension
            "Total_Ncells_samp",
             "rel_nsDist", "rel_maxDist", "rel_ewDist",
             "rel_elonRatio", "rel_circNorm", "rel_relCirc", "rel_lin",  # Species distribution geometric features
            "AtlasCOG_long", "AtlasCOG_lat",
             "minDist_toBorder_border", "minDist_toBorder_centr", # Distances
             "maxDist_toBorder_border", "maxDist_toBorder_centr",
             "bearingMinRect", "bearing", "elonMinRect","circ",
             "lengthMinRect","widthMinRect",
             "Southernness", "Westernness", 
             "moran", "x_intercept", # Spatial autocorrelation
             # "atlas_circNorm", "atlas_relCirc", # Atlas predictors
             "dataset") # captures most of the geometry of the atlases (highly correlated)

# Traits
cols_g2 <- c("rel_AOO", # Occupancy 
             "AOO",
             "IUCN", # Global red list categories
             "FP", # Evolutionary relationships
             "HWI", # Dispersal
             "Mass", 
             "Habitat", "Habitat.Density", "Migration", "Trophic.Level", "Trophic.Niche", "Primary.Lifestyle", # Life history traits
             "GlobRangeSize_km2", # Global range size (Breeding & Resident)
             "sd_PC1", "sd_PC2") # Climatic Niche Breadth

# Diversity
cols_g3 <- c("AlphaSR_sp", "BetaSR_sp", #Alpha and beta diversity
             "Dist_centroid_to_COG",  # Distance from species centroid to center of gravity of the atlas
             # "CenterOfGravity_Atlas_lat", # latitude of center of gravity of the atlas
             "sp_centr_lon","sp_centr_lat") # species distribution centroid coordinates) # Distance from species centroid to center of gravity of the atlas


# Which columns are not assigned yet?
cols2 <- setdiff(cols, cols_g1)
cols3 <- setdiff(cols2, cols_g2)
cols_not_used <- setdiff(cols3, cols_g3)
```

```{r}
# Log Ratio df
df_log_R <-  model_df %>% 
  select(all_of(cols_logR)) %>%
  distinct(tp, dataset, verbatim_name, .keep_all = T) %>%
  filter(!is.na(log_R2_1)) %>% ungroup()

df_log_R1 <- df_log_R %>% filter(tp == 1) %>% select(-tp, -verbatim_name) # Future Change
df_log_R2 <- df_log_R %>% filter(tp == 2) %>% select(-tp, -verbatim_name) # Past Change

# Telfer df
df_telfer <- model_df %>% 
  select(all_of(cols_telfer)) %>%
  distinct(tp, dataset, verbatim_name, .keep_all = T) %>%
  filter(!is.na(Telfer_1_2))  %>% ungroup()

df_telfer1 <- df_telfer %>% filter(tp == 1) %>% select(-tp, -verbatim_name) # Future Change
df_telfer2 <- df_telfer %>% filter(tp == 2) %>% select(-tp, -verbatim_name) # Past Change


# Create list of data frame:
dfs_list <- list(df_log_R1, df_log_R2, df_telfer1, df_telfer2)
names(dfs_list) <- c("df_log_R1", "df_log_R2", "df_telfer1", "df_telfer2")
```

# Model

## Baseline models for comparison

```{r}
m0_1 <- ranger(log_R2_1 ~ ., df_log_R1, num.trees = 1000)

m1_1 <- ranger(log_R2_1 ~ ., df_log_R1, num.trees = 1000, importance = "permutation", splitrule = "variance", oob.error = T)

importance(m0) %>% round(2) %>% sort() %>% tail()
treeInfo(m0)
```

## functions

```{r}
# function to calculate RMSE 
RMSE <- function(error){
    sqrt(mean(error^2))
} 

# function to calculate R2 
R2 <- function(actual, predicted){
  1 - sum((actual-predicted)^2)/sum((actual-mean(actual))^2)
}

```

## tuning hyperparameters

```{r}
# create empty lists
model_list <- list()
PredPerformance_list <- list()

# loop through list of model dataframes
for (dd in seq_along(dfs_list)){
  model_df <- dfs_list[[dd]]
  
  # split into test and train
  set.seed(42)
  samp <- sample(nrow(model_df), 0.8 * nrow(model_df))
  train <- model_df[samp, ]; dim(train) 
  test <- model_df[-samp, ]; dim(test) 

  # create response variable
  response_var <- if ("log_R2_1" %in% names(train)) "log_R2_1" else if ("Telfer_1_2" %in% names(train)) "Telfer_1_2" 
  
  # Model code
  my_control <- trainControl(
                    method = "repeatedcv", #repeated cv
                    number = 3, 
                    repeats = 3,
                    verboseIter = T)
  
  model <- train(as.formula(paste(response_var, "~ .")), 
                train, 
                importance = "permutation", 
                method =  "ranger", 
                tuneGrid = expand.grid(mtry = c(3,5, 8, 10, 12, 16),
                                       splitrule = c("variance"),
                                       min.node.size = 5),
                preProcess = c("medianImpute"),
                trControl = my_control)
  model_list[[dd]] <- model

  ## Predictive performance:

    predicted <- predict(model, train)
    names(predicted) <- NULL
    actual <- train[,response_var]
    error <- c(predicted-actual) %>% as.data.frame() %>% pull(response_var)
    in_sample_err <- RMSE(error)
    in_sample_R2 <- R2(predicted, actual)

    # Out-of-Sample error: # predicting 
    predicted <- predict(model, test)
    actual <- test[,response_var]
    error <- c(predicted-actual) %>% as.data.frame() %>% pull(response_var)
    out_of_sample_err <- RMSE(error)
    out_of_sample_R2 <- R2(predicted, actual)

    PredPerformance <- data.frame(response = response_var,
               inBagErr = in_sample_err,
               inBagR2 = in_sample_R2,
               outBagErr = out_of_sample_err,
               outBagR2 = out_of_sample_R2)

    PredPerformance_list[[dd]] <- PredPerformance
    
    
}

model_list[[1]]$finalModel
model$perfNames
model$yLimits
plot(varImp(model_list[[1]], scale = F))


```

```{r}

```

# To dos:

-   https://www.randomforestsrc.org/articles/speedup.html try this

```{r}
library(randomForestSRC)
df_log_R1 <- as.data.frame(df_log_R1)
str(df_log_R2)

df_log_R1$IUCN <- as.factor(df_log_R1$IUCN)
df_log_R1$log_R2_1 <- as.numeric(df_log_R1$log_R2_1)




o <- tune(log_R2_1 ~ ., df_log_R1,
          mtryStart = 1,
          nodesizeTry = c(1:9, seq(10, 100, by = 5)),
          ntreeTry = 1000,
          doBest = T)



m0_2 <- rfsrc.fast(log_R2_1 ~.,data = df_log_R1, ntree=1000, forest = T)
m0_1;m0_2
vimp(m0_2)
str(df_log_R1)


vimp(m0_2)$importance %>% sort() 


CI_Vimp <- subsample(m0_2)

# take a delete-d-jackknife procedure for example
vimpCI <- extract.subsample(CI_Vimp)$var.jk.sel.Z
cols_v <- vimpCI %>% filter(mean > 10 & signif == TRUE) %>% row.names()


# Confidence Intervals for VIMP
plot.subsample(CI_Vimp, xvar.names = cols_v, standardize = T, alpha = 0.01)
# take the variable "IUCN" for example for partial plot
plot.variable(m0_2, xvar.names = cols_v[1:3], partial = TRUE)

```
